<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="xjw924">


    <meta name="subtitle" content="Hi, there~">


    <meta name="description" content="统计|数据分析|机器学习|大数据">



<title>林轩田《机器学习基石》Note——Part4：How Can Machines Learn Better? | 小徐小徐不断学习</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">HOME</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/MachineLearning">▶Machine Learning</a>
                
                    <a class="menu-item" href="/DataAnalysis">▶Data Analysis</a>
                
                    <a class="menu-item" href="/Spark">▶Spark</a>
                
                    <a class="menu-item" href="/archives">▶Posts</a>
                
                    <a class="menu-item" href="/category">▶Category</a>
                
                    <a class="menu-item" href="/tag">▶Tag</a>
                
                    <a class="menu-item" href="/about">▶About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">HOME</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/MachineLearning">▶Machine Learning</a>
                
                    <a class="menu-item" href="/DataAnalysis">▶Data Analysis</a>
                
                    <a class="menu-item" href="/Spark">▶Spark</a>
                
                    <a class="menu-item" href="/archives">▶Posts</a>
                
                    <a class="menu-item" href="/category">▶Category</a>
                
                    <a class="menu-item" href="/tag">▶Tag</a>
                
                    <a class="menu-item" href="/about">▶About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">林轩田《机器学习基石》Note——Part4：How Can Machines Learn Better?</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">xjw924</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">March 17, 2020&nbsp;&nbsp;11:54:17</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Notes/">Notes</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <blockquote>
<p>课程：</p>
<ul>
<li><a href="https://www.bilibili.com/video/av12463015" target="_blank" rel="noopener">https://www.bilibili.com/video/av12463015</a></li>
</ul>
<p>参考笔记：</p>
<ul>
<li><a href="http://redstonewill.com/" target="_blank" rel="noopener">http://redstonewill.com/</a></li>
<li><a href="https://beader.me/mlnotebook/index.html" target="_blank" rel="noopener">https://beader.me/mlnotebook/index.html</a></li>
<li><a href="https://me.csdn.net/github_36324732" target="_blank" rel="noopener">https://me.csdn.net/github_36324732</a></li>
<li><a href="https://zhuanlan.zhihu.com/ml-note" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/ml-note</a></li>
</ul>
</blockquote>
<h1 id="How-Can-Machines-Learn-Better"><a href="#How-Can-Machines-Learn-Better" class="headerlink" title="How Can Machines Learn Better?"></a>How Can Machines Learn Better?</h1><h2 id="L13-Hazard-of-Overfitting"><a href="#L13-Hazard-of-Overfitting" class="headerlink" title="L13 Hazard of Overfitting"></a>L13 Hazard of Overfitting</h2><h3 id="What-is-Overfitting"><a href="#What-is-Overfitting" class="headerlink" title="What is Overfitting?"></a>What is Overfitting?</h3><p>假设平面上有5个点，目标函数是2阶多项式：</p>
<ul>
<li>如果hypothesis是2阶多项式，那么这5个点很靠近这个hypothesis，$E_{in}$很小。</li>
<li>如果hypothesis是4阶多项式，那么这5点会完全落在hypothesis上，$E_{in}=0$，但是$E_{out}$很大。</li>
<li>根据VC Bound理论，阶数越大，即VC Dimension越大，就会让模型复杂度更高，$E_{out}$更大。</li>
</ul>
<p><img src="https://i.bmp.ovh/imgs/2020/03/655d3663a730bb9e.png" style="zoom: 67%;"></p>
<p>VC曲线：</p>
<p><img src="https://i.bmp.ovh/imgs/2020/03/b222e9809f91a19b.png" style="zoom:67%;"></p>
<ul>
<li>在$d_{VC} = d_{VC}^*$的时候， $E_{out}$取到最小值；</li>
<li>当$d_{VC} &gt; d_{VC}^<em>$，也就是向右移动时，$E_{in} \downarrow ,E_{out} \uparrow$，这就是<em>*过拟合</em></em>（overfitting）；</li>
<li><p>当$d_{VC} &lt; d_{VC}^<em>$，也就是向左移动时，$E_{in} \uparrow ,E_{out} \uparrow$，这就是<em>*欠拟合</em></em>（underfitting）。</p>
</li>
<li><p><strong>overfitting是VC dimension过大的过程</strong>；<strong>bad generalization是VC dimension过大的结果</strong></p>
</li>
</ul>
<p>造成overfitting的原因是什么（把overfit比喻为出车祸）：</p>
<ul>
<li>使用过大的$d_{VC}$（车开太快）</li>
<li>有noise（路面颠簸）</li>
<li>数据量N不足（对路况的观察不够）</li>
</ul>
<p>也就是说，<strong>VC Dimension、noise、N这三个因素是影响过拟合现象的关键</strong>。</p>
<h3 id="The-Role-of-Noise-and-Data-Size"><a href="#The-Role-of-Noise-and-Data-Size" class="headerlink" title="The Role of Noise and Data Size"></a>The Role of Noise and Data Size</h3><p>我们看这样一个在二维平面上的例子，离散的圆圈是数据集，目标函数是蓝色的曲线——</p>
<p><img src="https://i.bmp.ovh/imgs/2020/03/0c2d07c942e574c0.png" alt></p>
<p>左图：目标函数是x的10阶多项式。数据没有完全落在曲线上，是因为加入了noise。<br>右图：目标函数是x的50阶多项式。没有noise的情况下，数据就全部落在曲线上。</p>
<p>现在我们分别用二阶多项式和十阶多项式来对两个问题进行拟合，得到下面的结果——</p>
<p><img src="https://i.bmp.ovh/imgs/2020/03/67389ba96094d800.png" alt></p>
<p>我们能看到在两个问题中$g_{10}$都发生了过拟合，反而$g_2$却表现得相对不错。</p>
<p>这种现象产生的原因，从哲学上来说，就是“<strong>以退为进</strong>”。有时候，简单的学习模型反而能表现的更好。</p>
<p>下面我们来看看发生这样现象的具体原因：</p>
<p><img src="https://i.loli.net/2018/07/24/5b572f1d8cda6.png" alt="img"></p>
<p>以上是用Learning Curves来看两个模型在有noise的情况，具体可以复习笔记：基石Lecture 9 - Linear Regression。$E_{in}$和$E_{out}$可以表示为：</p>
<script type="math/tex; mode=display">
E_{in}=\text{noise level}\ast (1-\frac{d+1}N)\\
E_{out}=\text{noise level}\ast (1+\frac{d+1}N)</script><p>本节的实验问题中，数据量N不大，即对应于上图中的灰色区域。</p>
<ul>
<li>左图的灰色区域中，因为d=2，$E_{in}$和$E_{out}$比较接近；右图中的灰色区域中，d=10，$E_{in}$很小，而$E_{out}$很大；</li>
<li>这就解释了之前2阶多项式模型的总是更接近，泛化能力更好。</li>
</ul>
<p>值得一提的是，如果数据量N很大的时候，上面两图中$E_{in}$和$E_{out}$都比较接近，但是对于高阶模型，z域中的特征很多的时候，需要的样本数量N很大，且容易发生维度灾难。</p>
<p>在第二个noiseless的问题中，我们发现仍然是2阶的模型拟合的效果更好一些，明明没有noise，为什么是这样的结果呢？ </p>
<p>其实，<strong>当模型很复杂的时候，这种复杂度本身就会引入一种‘noise’</strong>。所以，这种高阶无noise的问题，也可以类似于10阶多项式的目标函数加上noise的情况，只是二者的noise有所不同，下面将会详细解释。</p>
<h3 id="Deterministic-Noise"><a href="#Deterministic-Noise" class="headerlink" title="Deterministic Noise"></a>Deterministic Noise</h3><p>下面我们介绍一个更细节的实验来说明什么时候小心overfit会发生。</p>
<p>假设我们产生的数据分布由两部分组成：第一部分是目标函数$f(x)$，$Q_f$阶多项式；第二部分是噪声$\epsilon$，服从Gaussian分布。接下来我们分析的是noise强度不同对overfitting有什么样的影响。总共的数据量是N。</p>
<p><img src="https://i.loli.net/2018/07/24/5b572f49ac10c.png" alt="img"></p>
<ul>
<li>$Q_f$：$f(x)$的复杂度</li>
<li>$\sigma^2$：噪音的复杂程度</li>
</ul>
<p>那么下面我们分析不同的$(N,\sigma^2)$和$(N,Q_f)$对overfit的影响。overfit可以量化为$E_{out}-E_{in}$。结果如下：</p>
<p><img src="https://i.loli.net/2018/07/24/5b572f5b5fc76.png" alt="img"></p>
<p>上图中红色越深，代表overfit程度越高。</p>
<p>左图中阶数$Q_f$固定为20，横坐标代表样本数量$N$，纵坐标代表噪声水平$\sigma^2$。红色区域集中在$N$很小或者$\sigma^2$很大的时候，也就是说$N$越小，$\sigma^2$越大，越容易发生overfit。</p>
<p>右边图中$\sigma^2=0.1$，横坐标代表样本数量$N$，纵坐标代表目标函数阶数$Q_f$。红色区域集中在$N$很小或者$Q_f$很大的时候，也就是说$N$越大，$Q_f$越大，越容易发生overfit。这部分两图基本相似。</p>
<p>从上面的分析，我们发现：</p>
<ul>
<li>$\sigma^2$对overfit是有很大的影响的，我们把这种noise称之为<strong>stochastic noise</strong>。</li>
<li>$Q_f$即模型复杂度也对overfit有很大影响，而且二者影响是相似的，所以我们把这种称之为<strong>deterministic noise</strong>。之所以把它称为noise，是因为模型高复杂度带来的影响。</li>
</ul>
<p>总结，有四个因素会导致发生overfitting：</p>
<ul>
<li><strong>data size $N \downarrow$</strong></li>
<li><strong>stochastic noise $\sigma^2\uparrow$</strong></li>
<li><strong>deterministic noise $Q_f\uparrow$</strong></li>
<li><strong>excessive power $\uparrow$</strong>（右图左下角部分）</li>
</ul>
<p>我们刚才解释了如果目标函数$f(x)$的复杂度很高的时候，那么跟有noise也没有什么两样。<strong>因为目标函数很复杂，那么再好的hypothesis都会跟它有一些差距，我们把这种差距称之为deterministic noise。</strong>deterministic noise与stochastic noise不同，但是<strong>效果一样</strong>。其实<strong>deterministic noise类似于一个伪随机数发生器</strong>，它不会产生真正的随机数，而只产生伪随机数。它的值与hypothesis有关，且固定点x的deterministic noise值是固定的。</p>
<h3 id="Dealing-with-Overfitting"><a href="#Dealing-with-Overfitting" class="headerlink" title="Dealing with Overfitting"></a>Dealing with Overfitting</h3><p>现在我们知道了什么是overfitting，和overfitting产生的原因，那么如何避免overfitting呢？避免overfitting的方法主要包括：</p>
<ul>
<li><p><strong>start from simple model</strong></p>
</li>
<li><p><strong>data cleaning/pruning</strong></p>
</li>
<li><p><strong>data hinting</strong></p>
</li>
<li><p><strong>regularization</strong></p>
</li>
<li><p><strong>validataion</strong></p>
</li>
</ul>
<p>介绍简单的data cleaning/pruning和data hinting两种方法：</p>
<ul>
<li><p>data cleaning/pruning：</p>
<ul>
<li>对训练数据集里label明显错误的样本进行修正（data cleaning）</li>
<li>或者对错误的样本看成是noise，进行剔除（data pruning）。</li>
<li>data cleaning/pruning关键在于如何准确寻找label错误的点或者是noise的点，而且如果这些点相比训练样本N很小的话，这种处理效果不太明显（不一定有用）。</li>
</ul>
</li>
<li><p>data hinting</p>
<p>针对N不够大的情况，如果没有办法获得更多的训练集，那么data hinting就可以对已知的样本进行简单的处理、变换，从而获得更多的（虚拟）样本。</p>
<p>举个例子，数字分类问题，可以对已知的数字图片进行轻微的平移或者旋转，从而让N丰富起来，达到扩大训练集的目的。这种额外获得的例子称之为virtual examples。但是要注意一点的就是，<strong>新获取的virtual examples可能不再是iid某个distribution（分布改变）</strong>。所以新构建的virtual examples要尽量合理，且是独立同分布的。</p>
</li>
</ul>
<h2 id="L14-Regularization"><a href="#L14-Regularization" class="headerlink" title="L14 Regularization"></a>L14 Regularization</h2><h3 id="Regularized-Hypothesis-Set"><a href="#Regularized-Hypothesis-Set" class="headerlink" title="Regularized Hypothesis Set"></a>Regularized Hypothesis Set</h3><p>那么如何对过拟合现象进行修正，使hypothesis更接近于target function呢？一种方法就是regularized fit。</p>
<p><img src="https://i.loli.net/2018/07/24/5b57423e5693a.png" alt="img"></p>
<p>这种方法得到的红色fit曲线，更接近目标函数，它的阶数要更低一些。那么问题就变成了我们要把高阶（10阶）的hypothesis sets转换为低阶（2阶）的hypothesis sets。</p>
<p>不同阶数的hypothesis存在如下包含关系：</p>
<p><img src="https://i.loli.net/2018/07/24/5b57424cddae5.png" alt="img"></p>
<p>我们发现10阶多项式hypothesis sets里包含了2阶多项式hypothesis sets的所有项，那么在$H_{10}$中加入一些限定条件，使它近似为$H_2$即可。这种函数近似曾被称之为<strong>不适定问题（ill-posed problem）</strong>。</p>
<p>如何从10阶转换为2阶呢？首先，$H_{10}$可表示为：</p>
<script type="math/tex; mode=display">
H_{10}=w_0+w_1x+w_2x^2+w_3x^3+\cdots+w_{10}x^{10}</script><p>而H_2可表示为：</p>
<script type="math/tex; mode=display">
H_2=w_0+w_1x+w_2x^2</script><p>所以，如果限定条件是$w_3=w_4=\cdots=w_{10}=0$，那么就有$H_2=H_{10}$。也就是说，<strong>对于高阶的hypothesis，为了防止过拟合，我们可以将其高阶部分的权重w限制为0，这样，就相当于从高阶的形式转换为低阶，fit波形更加平滑，不容易发生过拟合。</strong></p>
<p><a href="https://i.loli.net/2018/07/24/5b5742587fdec.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/07/24/5b5742587fdec.png" alt="img"></a></p>
<p>那有一个问题，令$H_{10}$高阶权重$w$为0，为什么不直接使用$H_2$呢？这样做的目的是拓展我们的视野，为即将讨论的问题做准备。</p>
<p>刚刚我们讨论的限制是$H_{10}$高阶部分的权重$w$限制为0，这是比较苛刻的一种限制。下面，我们把这个限制条件变得更宽松一点，即令任意8个权重$w$为0，并不非要限定$w_3=w_4=\cdots=w_{10}=0$，这个Looser Constraint可以写成：</p>
<script type="math/tex; mode=display">
\sum_{q=0}^{10}[[w_q\neq0]]\leq3</script><p>也就只是限定了$w$不为0的个数，并不限定必须是高阶的w。这种hypothesis记为$H_2^′$，称为<strong>sparse hypothesis set</strong>，它与$H_2$和$H_{10}$的关系为：</p>
<script type="math/tex; mode=display">
H_2\subset H_2’\subset H_{10}</script><p>Looser Constraint对应的hypothesis应该更好解一些，但事实是sparse hypothesis set $H_2^′$被证明也是NP-hard，求解非常困难。所以，还要转换为另一种易于求解的限定条件。</p>
<p>那么，我们寻找一种更容易求解的宽松的限定条件Softer Constraint，即：</p>
<script type="math/tex; mode=display">
\sum_{q=0}^{10}w_q^2=||w||^2\leq C</script><p>其中，$C$是常数，也就是说，所有的权重$w$的平方和的大小不超过$C$，我们把这种hypothesis sets记为$H(C)$。</p>
<p>$H_2^′$与$H(C)$的关系是，它们之间有重叠，有交集的部分，但是没有完全包含的关系，也不一定相等。对应$H(C)$，$C$值越大，限定的范围越大，即越宽松：</p>
<script type="math/tex; mode=display">
H(0)\subset H(1.126)\subset \cdots \subset H(1126)\subset \cdots \subset H(\infty)=H_{10}</script><p>当$C$无限大的时候，即限定条件非常宽松，相当于没有加上任何限制，就与$H_{10}$没有什么两样。$H(C)$<strong>称为regularized hypothesis set</strong>，这种形式的限定条件是可以进行求解的，我们把求解的满足限定条件的权重$w$记为$w_{REG}$。接下来就要探讨如何求解$w_{REG}$。</p>
<h3 id="Weight-Decay-Regularization"><a href="#Weight-Decay-Regularization" class="headerlink" title="Weight Decay Regularization"></a>Weight Decay Regularization</h3><p>现在，针对H(c)，即加上限定条件，我们的问题变成：</p>
<p><img src="https://i.loli.net/2018/07/24/5b574276c5ab2.png" alt="img"></p>
<p>我们的目的是计算$E_{in}(w)$的最小值，限定条件是$||w^2||\leq C$。这个限定条件从几何角度上的意思是，权重$w$被限定在半径为$\sqrt C$的圆内，而球外的$w$都不符合要求。</p>
<p>用矩阵来表达：</p>
<p><img src="https://i.loli.net/2018/07/24/5b5742869f669.png" alt="img"></p>
<p>下面用一张图来解释在限定条件下，最小化$E_{in}(w)$的过程：</p>
<p><a href="https://i.loli.net/2018/07/24/5b57429140f3c.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/07/24/5b57429140f3c.png" alt="img"></a></p>
<p>如上图所示，假设在空间中的一点$w$，根据梯度下降算法，$w$会朝着$-\nabla E_{in}$的方向移动（图中蓝色箭头指示的方向），在没有限定条件的情况下，$w$最终会取得最小值$w_{lin}$，即“谷底”的位置。</p>
<p>现在，加上限定条件，即$w$被限定在半径为$\sqrt C$的圆内，如图中红色圆圈所示$w^Tw=C$。那么，这种情况下，$w$不能到达$w_{lin}$的位置，最大只能位于圆上，沿着圆的切线方向移动（图中绿色箭头指示的方向）。</p>
<p>与绿色向量垂直的向量（图中红色箭头指示的方向）是圆切线的法向量，即$w$的方向。</p>
<p><strong>那么随着迭代优化过程，只要$-\nabla E_{in}$与$w$方向不平行，那么根据向量知识，$-\nabla E_{in}$一定在$w$点切线方向上有不为零的分量，即$w$点会继续移动</strong>。只有当$-\nabla E_{in}$与红色法向量平行的时候，$-\nabla E_{in}$在切线方向上没有不为零的分量了，也就表示这时$w$达到了最优解的位置。</p>
<p>有了这个平行的概念，我们就得到了获得最优解需要满足的性质：</p>
<script type="math/tex; mode=display">
\nabla E_{in}(w_{REG})+\frac{2\lambda}{N}w_{REG}=0</script><p>上面公式中的$\lambda$<strong>称为Lagrange multiplier，是用来解有条件的最佳化问题常用的数学工具</strong>，$\frac2N$是方便后面公式推导。那么我们的目标就变成了求解满足上面公式的$w_{REG}$。</p>
<p>之前我们推导过，线性回归的$E_{in}$的表达式为：</p>
<script type="math/tex; mode=display">
E_{in}=\frac1N\sum_{n=1}^N(x_n^Tw-y_n)^2</script><p>计算$E_{in}$梯度，并代入到平行条件中，得到：</p>
<script type="math/tex; mode=display">
\frac2N(Z^TZw_{REG}-Z^Ty)+\frac{2\lambda}Nw_{REG}=0</script><p>这是一个线性方程式，直接得到$w_{REG}$为：</p>
<script type="math/tex; mode=display">
w_{REG}=(Z^TZ+\lambda I)^{-1}Z^Ty</script><p>上式中包含了求逆矩阵的过程，因为$Z^TZ$是半正定矩阵，如果$\lambda$大于零，那么$Z^TZ+\lambda I$一定是正定矩阵，即一定可逆。统计学上把这叫做<strong>ridge regression</strong>，可以看成是linear regression的进阶版。</p>
<p>如果对于更一般的情况，例如逻辑回归问题中，$\nabla E_{in}$不是线性的，那么将其代入平行条件中得到的就不是一个线性方程式，$w_{REG}$不易求解。下面我们从另一个角度来看一下平行等式：</p>
<script type="math/tex; mode=display">
\nabla E_{in}(w_{REG})+\frac{2\lambda}{N}w_{REG}=0</script><p>已知$\nabla E_{in}$是$E_{in}$对$w_{REG}$的导数，而$\frac{2\lambda}{N}w_{REG}$也可以看成是$\frac{\lambda}Nw_{REG}^2$的导数。那么平行等式左边可以看成一个函数的导数，导数为零，即求该函数的最小值。也就是说，问题转换为最小化该函数：</p>
<script type="math/tex; mode=display">
E_{aug}(w)=E_{in}(w)+\frac{\lambda}Nw^Tw</script><p>该函数中第二项就是限定条件regularizer，也称为weight-decay regularization。我们把这个函数称为<strong>Augmented Error</strong>，即$E_{aug}(w)$。</p>
<p>如果$\lambda$不为零，对应于加上了限定条件，若$\lambda$等于零，则对应于没有任何限定条件，问题转换成之前的最小化$E_{in}(w)$。</p>
<p>下面给出一个曲线拟合的例子，$\lambda$取不同的值时，得到的曲线也不相同：</p>
<p><img src="https://i.loli.net/2018/07/24/5b5742b7058e4.png" alt="img"></p>
<p>从图中可以看出，当$\lambda=0$时，发生了过拟合；当$\lambda=0.0001$时，拟合的效果很好；当$\lambda=0.01$和$\lambda=1$时，发生了欠拟合。我们可以把$\lambda$看成是一种penality，即对hypothesis复杂度的惩罚，<strong>$\lambda$越大，$w$就越小，对应于$C$值越小，即这种惩罚越大，拟合曲线就会越平滑，高阶项就会削弱，容易发生欠拟合。</strong>$\lambda$一般取比较小的值就能达到良好的拟合效果，过大过小都有问题，但究竟取什么值，要根据具体训练数据和模型进行分析与调试。</p>
<p><img src="https://i.loli.net/2018/07/24/5b5742c5c7df3.png" alt="img"></p>
<p>事实上，这种regularization不仅可以用在多项式的hypothesis中，还可以应用在logistic regression等其他hypothesis中，都可以达到防止过拟合的效果。</p>
<p>我们目前讨论的多项式是形如$x,x^2,x^3,\cdots,x^n$的形式，若x的范围限定在[-1,1]之间，那么可能导致$x^n$相对于低阶的值要小得多，则其对于的$w$非常大，相当于要给高阶项设置很大的惩罚。为了避免出现这种数据大小差别很大的情况，可以使用<strong>Legendre Polynomials</strong>代替$x,x^2,x^3,\cdots,x^n$这种形式，Legendre Polynomials各项之间是正交的，用它进行多项式拟合的效果更好。关于Legendre Polynomials的概念这里不详细介绍。</p>
<h3 id="Regularization-and-VC-Theory"><a href="#Regularization-and-VC-Theory" class="headerlink" title="Regularization and VC Theory"></a>Regularization and VC Theory</h3><p>下面我们研究一下Regularization与VC理论之间的关系。Augmented Error表达式如下：</p>
<script type="math/tex; mode=display">
E_{aug}(w)=E_{in}(w)+\frac{\lambda}Nw^Tw</script><p>VC Bound表示为：</p>
<script type="math/tex; mode=display">
E_{out}(w)\leq E_{in}(w)+\Omega(H)</script><p><strong>其中$w^Tw$表示的是单个hypothesis的复杂度，记为$\Omega(w)$；而$\Omega(H)$表示整个hypothesis set的复杂度。</strong></p>
<p><strong>根据Augmented Error和VC Bound的表达式，$\Omega(w)$包含于$\Omega(H)$之内，所以，$E_{aug}(w)$比$E_{in}$更接近于$E_{out}$，即更好地代表$E_{out}$，$E_{aug}(w$)与$E_{out}$之间的误差更小。</strong></p>
<p><img src="https://i.loli.net/2018/07/24/5b5742dfcb9c4.png" alt="img"></p>
<p>根据VC Dimension理论，整个hypothesis set的$d_{VC}=\breve d+1$，这是因为所有的$w$都考虑了，没有任何限制条件。而引入限定条件的$d_{VC}(H(C))=d_{EFF}(H,A)$，即有效的VC dimension。也就是说，$d_{VC}(H)$比较大，因为它代表了整个hypothesis set，但是$d_{EFF}(H,A)$比较小，因为由于regularized的影响，<strong>限定了$w$只取一小部分</strong>。其中A表示regularized算法。当$\lambda \gt 0$时，有：</p>
<script type="math/tex; mode=display">
d_{EFF}(H,A)\leq d_{VC}</script><p>这些与实际情况是相符的，比如对多项式拟合模型，<strong>当$\lambda=0$时，所有的$w$都给予考虑，相应的$d_{VC}$很大，容易发生过拟合。当$\lambda$&gt;0且越来越大时，很多$w$将被舍弃，$d_{EFF}(H,A)$减小，拟合曲线越来越平滑，容易发生欠拟合。</strong></p>
<h3 id="General-Regularizers"><a href="#General-Regularizers" class="headerlink" title="General Regularizers"></a>General Regularizers</h3><p>那么通用的Regularizers，即$\Omega(w)$，应该选择什么样的形式呢？一般地，我们会朝着目标函数的方向进行选取。有三种方式：</p>
<ul>
<li><p><strong>target-dependent</strong>：依据目标函数设定</p>
</li>
<li><p><strong>plausible</strong>：平滑</p>
</li>
<li><p><strong>friendly</strong>：方便优化</p>
</li>
</ul>
<p><img src="https://i.loli.net/2018/07/24/5b5742fb6b430.png" alt="img"></p>
<p>其实这三种方法跟之前error measure类似，其也有三种方法：</p>
<ul>
<li><p><strong>user-dependent</strong></p>
</li>
<li><p><strong>plausible</strong></p>
</li>
<li><p><strong>friendly</strong></p>
</li>
</ul>
<p>regularizer与error measure是机器学习模型设计中的重要步骤。</p>
<p>接下来，介绍两种Regularizer：L2和L1。</p>
<p>L2 Regularizer一般比较通用，其形式如下：</p>
<script type="math/tex; mode=display">
\Omega(w)=\sum_{q=0}^Qw_q^2=||w||_2^2</script><p>这种形式的regularizer计算的是$w$的平方和，是凸函数，比较平滑，易于微分，容易进行最优化计算。</p>
<p>L1 Regularizer的表达式如下：</p>
<script type="math/tex; mode=display">
\Omega(w)=\sum_{q=0}^Q|w_q|=||w||_1</script><p>L1计算的不是w的平方和，而是绝对值和，即长度和，也是凸函数。已知$w^Tw=C$围成的是圆形，而$||w||_1=C$围成的是正方形，那么在正方形的四个顶点处，是<strong>不可微分</strong>的（不像圆形，处处可微分）。根据之前介绍的平行等式推导过程，对应这种正方形，<strong>它的解大都位于四个顶点处</strong>，若$-\nabla E_{in}$不与其平行，那么$w$就会向顶点处移动，顶点处的许多$w$分量为零，所以，L1 Regularizer的解是稀疏的，称为sparsity。优点是计算速度快。</p>
<p><img src="https://i.loli.net/2018/07/24/5b57432c1e60a.png" alt="img"></p>
<p>下面来看一下$\lambda$如何取值，首先，若stochastic noise不同，那么一般情况下，$\lambda$取值有如下特点：</p>
<p><img src="https://i.loli.net/2018/07/24/5b57433f1809c.png" alt="img"></p>
<p>从图中可以看出，stochastic noise越大，$\lambda$越大。</p>
<p>另一种情况，不同的deterministic noise，$\lambda$取值有如下特点：</p>
<p><img src="https://i.loli.net/2018/07/24/5b5743534e379.png" alt="img"></p>
<p>从图中可以看出，deterministic noise越大，$\lambda$越大。</p>
<p>以上两种noise的情况下，都是noise越大，相应的$\lambda$也就越大。这也很好理解，如果在开车的情况下，路况也不好，即noise越多，那么就越会踩刹车，这里踩刹车指的就是regularization。但是大多数情况下，noise是不可知的，这种情况下如何选择$\lambda$？这部分内容，我们下节课将会讨论。</p>
<h2 id="L15-Validation"><a href="#L15-Validation" class="headerlink" title="L15 Validation"></a>L15 Validation</h2><p>如何保证训练的模型具有良好的泛化能力？</p>
<h3 id="Model-Selection-Problem"><a href="#Model-Selection-Problem" class="headerlink" title="Model Selection Problem"></a>Model Selection Problem</h3><p>机器学习模型建立的过程中有许多选择，不同的选择搭配，有不同的机器学习效果。我们的目标就是找到最合适的选择搭配，构建最佳的机器学习模型。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/1-4.png" alt="img"></p>
<p>假设有$M$个模型，对应有$H_1,H_2,\cdots,H_M$，即有$M$个hypothesis set，演算法为$A_1,A_2,\cdots,A_M$，共$M$个。我们的目标是从这$M$个hypothesis set中选择一个模型$H_{m^<em>}$，通过演算法$A_{m^</em>}$对样本集$D$的训练，得到一个最好的矩$g_{m^<em>}$，使其$E_{out}(g_{m^</em>})$最小。所以，问题的关键就是机器学习中<strong>如何选择到最好的矩$g_{m^*}$。</strong></p>
<ul>
<li><p>方法一：对$M$个模型分别计算使$E_{in}$最小的矩$g$，再横向比较，取其中<strong>能使$E_{in}$最小</strong>的模型的矩$g_{m^*}$：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-3.png" alt="img"></p>
<p>但是$E_{in}$足够小并不能表示模型好，反而<strong>可能表示训练的矩$g_{m^*}$发生了过拟合</strong>，泛化能力很差。而且这种“模型选择+学习训练”的过程，它的VC Dimension是$d_{VC}(H_1\cup H_2)$，模型复杂度增加。总的来说，泛化能力差，用$E_{in}$来选择模型是不好的。</p>
</li>
<li><p>方法二：如果有这样一个独立于训练样本的测试集，将$M$个模型在测试集上进行测试，选取$E_{test}$<strong>最小</strong>的模型作为最佳模型：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-3.png" alt="img"></p>
<p>这种测试集验证的方法，根据finite-bin Hoffding不等式，可以得到：</p>
<script type="math/tex; mode=display">
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O(\sqrt \frac{log M}{N_{test}})</script><p>由上式可以看出，模型个数$M$越少，测试集数目越大，那么$O(\sqrt \frac{log M}{N_{test}})$越小，即$E_{test}(g_{m^<em>})$越接近于$E_{out}(g_{m^</em>})$。</p>
</li>
</ul>
<p>比较这两种方法：</p>
<ul>
<li><p>第一种方法使用$E_{in}$作为判断基准，使用的数据集就是训练集$D$本身；不仅使用$D$来训练不同的$g_m$，而且又使用$D$来选择最好的$g_{m^<em>}$，那么$g_{m^</em>}$对未知数据并不一定泛化能力好。举个例子，这相当于老师用学生做过的练习题再来对学生进行考试，那么即使学生得到高分，也不能说明他的学习能力强。所以最小化$E_{in}$的方法并不科学。</p>
</li>
<li><p>第二种方法使用$E_{test}$作为判断基准，使用的是独立于训练集$D$之外的测试集。相当于新的考试题能更好地反映学生的真实水平，所以最小化$E_{test}$更加理想。</p>
</li>
<li><p>但是，我们拿到的都是训练集$D$，测试集是拿不到的。所以，寻找一种折中的办法，<strong>我们可以使用已有的训练集$D$来创造一个验证集validation set，即从$D$中划出一部分$D_{val}$作为验证集</strong>。$D$另外的部分作为训练集，$D_{val}$独立开来，用来测试各个模型的好坏，最小化$E_{val}$，从而选择最佳的$g_{m^*}$。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/4-1.png" alt="img"></p>
</li>
</ul>
<h3 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h3><p>从训练集$D$中抽出一部分$K$个数据作为验证集$D_{val}$，前提是保证$D_{val}$独立同分布(iid)于$P(x,y)$，也就是说$D_{val}$的选择是从$D$中平均随机抽样得到的。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/5-1.png" alt="img"></p>
<p>$D$中去除$D_{val}$后的数据就是供模型选择的训练数据$D_{train}$，其大小为$N-k$。</p>
<p>使用$D_{train}$训练模型，得到$g_m^-$，使用$g_m^-$对$D_{val}$进行验证，得到如下Hoffding不等式：</p>
<script type="math/tex; mode=display">
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O(\sqrt \frac{log M}{K})</script><p>假设有$M$种模型hypothesis set，$D_{val}$的数量为$K$，那么从每种模型$m$中得到一个在$D_{val}$上表现最好的矩，再横向比较，从$M$个矩中选择一个最好的$m^*$作为我们最终得到的模型。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/6-1.png" alt="img"></p>
<p>现在由于数量为$N$的总样本$D$的一部分$K$作为验证集，那么只有$N-k$个样本可供训练。从$D_{train}$中得到最好的$g_{m^<em>}^-$，而总样本$D$对应的最好的矩为$g_{m^</em>}$。根据之前的leraning curve很容易知道，<strong>训练样本越多，得到的模型越准确，其hypothesis越接近target function</strong>，即$D$的$E_{out}$比$D_{train}$的$E_{out}$要小：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/7-2.png" alt="img"></p>
<p>所以，我们通常的做法是通过$D_{val}$来选择最好的矩$g_{m^<em>}^-$对应的模型$m^</em>$，再<strong>对整体样本集$D$使用该模型进行训练</strong>，最终得到最好的矩$g_{m^*}$。</p>
<p>总结使用验证集进行模型选择的整个过程：</p>
<ul>
<li>先将$D$分成两个部分，一个是训练样本$D_{train}$，一个是验证集$D_{val}$</li>
<li>若有$M$个模型，那么分别对每个模型在$D_{train}$上进行训练，得到矩$g_{m}^-$</li>
<li>再用$D_{val}$对每个$g_{m}^-$进行验证，选择表现最好的矩记为$g_{m^*}^-$</li>
<li>最后使用该模型对整个$D$进行训练，得到最终的$g_{m^*}$。</li>
</ul>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/9-2.png" alt="img"></p>
<p>不等式关系满足：</p>
<script type="math/tex; mode=display">
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O(\sqrt \frac{log M}{K})</script><p>下面我们举个例子来解释这种模型选择的方法的优越性：</p>
<p>假设有两个模型：一个是5阶多项式$H_{\Phi_5}$，一个是10阶多项式$H_{\Phi_{10}}$。通过不使用验证集和使用验证集两种方法对模型选择结果进行比较：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/10-2.png" alt="img"></p>
<p>图中，横坐标表示验证集的样本数量$K$，纵坐标表示$E_{out}$大小。</p>
<ul>
<li>黑色水平线表示没有验证集，完全使用$E_{in}$进行判断基准。这种方法的$E_{out}$较大，而且与$K$无关。</li>
<li>黑色虚线表示测试集非常接近实际数据，这是一种理想的情况，$E_{out}$很小，与$K$无关，实际中很难得到这条虚线。</li>
<li>红色曲线表示使用验证集，但是最终选取的矩是$g_{m^<em>}^-$，其趋势是随着$K$的增加，它对应的$E_{out}$先减小再增大，当$K$大于一定值的时候，甚至会超过黑色水平线。这是因为随着$K$的增大，$D_{val}$增大，但可供模型训练的$D_{train}$在减小，那得到的$g_{m^</em>}^-$不具有很好的泛化能力。</li>
<li>蓝色曲线表示也使用验证集，最终选取的矩是$g_{m^*}$，其趋势是随着$K$的增加，它对应的$E_{out}$先缓慢减小再缓慢增大，且一直位于红色曲线和黑色直线之下。从此可见，蓝色曲线对应的方法最好，符合我们之前讨论的使用验证集进行模型选择效果最好。</li>
</ul>
<p>那么，如何设置验证集K值的大小呢？</p>
<ul>
<li>当$K$值很大时，$E_{val}\approx E_{out}$，但是$g_{m}^-$与$g_m$相差很大；</li>
<li>当$K$值很小时，$g_m^-\approx g_m$，但是$E_{val}$与$E_{out}$可能相差很大。</li>
</ul>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/11-1.png" alt="img"></p>
<p>所以有个折中的办法，通常设置$k=\frac N5$。值得一提的是，划分验证集，通常并不会增加整体时间复杂度，反而会减少，因为$D_{train}$减少了。</p>
<h3 id="Leave-One-Out-Cross-Validation"><a href="#Leave-One-Out-Cross-Validation" class="headerlink" title="Leave-One-Out Cross Validation"></a>Leave-One-Out Cross Validation</h3><p>假如考虑一个极端的例子，$K=1$，也就是说验证集大小为1，每次只用一组数据对$g_m$进行验证。这样做的优点是$g_m^-\approx g_m$，但是$E_{val}$与$E_{out}$可能相差很大。</p>
<p>为了避免$E_{val}$与$E_{out}$相差很大，<strong>每次从$D$中取一组作为验证集，直到所有样本都作过验证集</strong>，共计算$N$次，最后对验证误差求平均，得到$E_{loocv}(H,A)$，这种方法称之为<strong>留一法交叉验证</strong>，表达式为：</p>
<script type="math/tex; mode=display">
E_{loocv}(H,A)=\frac1N\sum_{n=1}^Ne_n=\frac1N\sum_{n=1}^Nerr(g_n^-(x_n),y_n)</script><p>这样求平均的目的是为了让$E_{loocv}(H,A)$尽可能地接近$E_{out}(g)$。</p>
<p>下面用一个例子图解留一法的过程：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/12-2.png" alt="img"></p>
<p>如上图所示，要对二维平面上的三个点做拟合，上面三个图表示的是线性模型，下面三个图表示的是常数模型。对于两种模型，分别使用留一交叉验证法来计算$E_{loocv}$，<strong>计算过程都是每次将一个点作为验证集，其他两个点作为训练集，最终将得到的验证误差求平均值</strong>，就得到了$E_{loocv}(linear)$和$E_{loocv}(constant)$，比较两个值的大小，取值小对应的模型即为最佳模型。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/13-1.png" alt="img"></p>
<p>接下来，我们从理论上分析<strong>Leave-One-Out方法的可行性</strong>，即$E_{loocv}(H,A)$是否能保证$E_{out}$的矩足够好？</p>
<p>假设有不同的数据集$D$，它的期望分布记为$\varepsilon_D$，则其$E_{loocv}(H,A)$可以通过推导，等于$E_{out}(N-1)$的平均值。由于$N-1$近似为$N$，$E_{out}(N-1)$的平均值也近似等于$E_{out}(N)$的平均值。具体推导过程如下：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/14-2.png" alt="img"></p>
<p>最终我们得到的结论是$E_{loocv}(H,A)$的期望值和$E_{out}(g^-)$的期望值是相近的，这代表得到了比较理想的$E_{out}(g)$，Leave-One-Out方法是可行的。</p>
<p>举一个例子，使用两个特征：Average Intensity和Symmetry加上这两个特征的非线性变换（例如高阶项）来进行手写数字识别。平面特征分布如下图所示：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/15-1.png" alt="img"></p>
<p>Error与特征数量的关系如下图所示：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/16-1.png" alt="img"></p>
<p>从图中我们看出，随着特征数量的增加，$E_{in}$不断减小，$E_{out}$先减小再增大，虽然$E_{in}$是不断减小的，但是它与的差距$E_{out}$越来越大，发生了过拟合，泛化能力太差。</p>
<p>而$E_{cv}$与$E_{out}$的分布基本一致，能较好地反映$E_{out}$的变化。所以，我们只要使用Leave-One-Out方法得到使$E_{cv}$最小的模型，就能保证其$E_{out}$足够小。</p>
<h3 id="V-Fold-Cross-Validation"><a href="#V-Fold-Cross-Validation" class="headerlink" title="V-Fold Cross Validation"></a>V-Fold Cross Validation</h3><p>Leave-One-Out可能的问题：</p>
<ul>
<li>计算量，假设$N=1000$，那么就需要计算1000次的$E_{loocv}$，再计算其平均值。当$N$很大的时候，计算量是巨大的，很耗费时间。</li>
<li>稳定性，例如对于二分类问题，取值只有0和1两种，预测本身存在不稳定的因素，那么对所有的$E_{loocv}$计算平均值可能会带来很大的数值跳动，稳定性不好。</li>
</ul>
<p>所以，这两个因素决定了Leave-One-Out方法在实际中并不常用。</p>
<p>针对Leave-One-Out的缺点，我们对其作出了改进。将$N$个数据分成$V$份（例如V=10），计算过程与Leave-One-Out相似。这样可以减少总的计算量，又能进行交叉验证，得到最好的矩，这种方法称为<strong>V-折交叉验证</strong>。其实Leave-One-Out就是V-折交叉验证的一个极端例子。</p>
<script type="math/tex; mode=display">
E_{cv}(H,A)=\frac1V\sum_{v=1}^VE_{val}^{(V)}(g_V^-)</script><p>所以，<strong>一般的Validation使用V-折交叉验证来选择最佳的模型</strong>。</p>
<p>值得一提的是Validation的数据来源也是样本集中的，所以并不能保证交叉验证的效果好，它的模型一定好。只有样本数据越多，越广泛，那么Validation的结果越可信，其选择的模型泛化能力越强。</p>
<h2 id="L16-Three-Learning-Principles"><a href="#L16-Three-Learning-Principles" class="headerlink" title="L16 Three Learning Principles"></a>L16 Three Learning Principles</h2><h3 id="Occam’s-Razor"><a href="#Occam’s-Razor" class="headerlink" title="Occam’s Razor"></a>Occam’s Razor</h3><p>奥卡姆剃刀定律（Occam’s Razor）：“切勿浪费较多东西去做用较少的东西同样可以做好的事情。” “如无必要，勿增实体”，就像剃刀一样，将不必要的部分去除掉。</p>
<p>Occam’s Razor反映到机器学习领域中，指的是在所有可能选择的模型中，我们应该<strong>选择能够很好地解释已知数据并且十分简单的模型</strong>。</p>
<p>问题：什么模型称得上是简单的？为什么简单模型比复杂模型要好？</p>
<ul>
<li><p><strong>什么模型称得上是简单的？</strong></p>
<ul>
<li><p><strong>简单的hypothesis $h$</strong>，简单的hypothesis就是指<strong>模型使用的特征比较少</strong>，例如多项式阶数比较少。</p>
</li>
<li><p><strong>模型$H$包含的hypothesis数目有限</strong>，不会太多，这也是简单模型包含的内容。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-4.png" alt="img"></p>
</li>
</ul>
<p>simple hypothesis $h$和simple model $H$是紧密联系的。如果hypothesis的特征个数是$l$，那么$H$中包含的hypothesis个数就是$2^l$，也就是说，hypothesis特征数目越少，$H$中hypothesis数目也就越少。</p>
<p>所以，为了让模型简单化，我们可以<strong>一开始就选择简单的model，或者用regularization，让hypothesis中参数个数减少</strong>，都能降低模型复杂度。</p>
</li>
<li><p>为什么简单模型比复杂模型要好？</p>
<p>机器学习的目的是“找规律”，即分析数据的特征，总结出规律性的东西出来。</p>
<p>假设现在有一堆没有规律的杂乱的数据需要分类，要找到一个模型，让它的$E_{in}=0$是很难的。但是如果是很复杂的模型，也有可能将其分开。如果使用某种简单的模型就可以将数据分开，那表明数据本身应该符合某种规律性。相反地，<strong>如果用很复杂的模型将数据分开，并不能保证数据本身有规律性存在，也有可能是杂乱的数据，因为无论是有规律数据还是杂乱数据，复杂模型都能分开。</strong>这就不是机器学习模型解决的内容了。所以，模型选择中，我们应该尽量先选择简单模型，例如最简单的线性模型。</p>
</li>
</ul>
<h3 id="Sampling-Bias"><a href="#Sampling-Bias" class="headerlink" title="Sampling Bias"></a>Sampling Bias</h3><p>抽样的样本会影响到结果。如果抽样有偏差的话，那么学习的结果也产生了偏差，这种情形称之为抽样偏差Sampling Bias。</p>
<p>从技术上来说，就是训练数据和验证数据要服从同一个分布，最好都是独立同分布的，这样训练得到的模型才能更好地具有代表性。</p>
<h3 id="Data-Snooping"><a href="#Data-Snooping" class="headerlink" title="Data Snooping"></a>Data Snooping</h3><p>之前的课程，我们介绍过在模型选择时应该尽量避免偷窥数据，因为这样会使我们人为地倾向于某种模型，而不是根据数据进行随机选择。所以，$\Phi$应该自由选取，最好不要偷窥到原始数据，这会影响我们的判断。</p>
<p>事实上，数据偷窥发生的情况有很多，不仅仅指我们看到了原始数据。什么意思呢？其实，当你在使用这些数据的任何过程，都是间接地偷看到了数据本身，然后你会进行一些模型的选择或者决策，这就增加了许多的model complexity，也就是引入了污染。</p>
<p>下面举个例子来说明。假如我们有8年的货比交易数据，我们希望从这些数据中找出规律，来预测货比的走势。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/3-2.png" alt="img"></p>
<p>现在有两种训练模型的方法：</p>
<ul>
<li>一种是使用前6年数据进行模型训练，后2年数据作为测试，图中蓝色曲线表示后2年的预测收益；</li>
<li>另一种是直接使用8年数据进行模型训练，图中红色曲线表示后2年的预测收益情况。</li>
</ul>
<p>很明显，使用8年数据进行训练的模型对后2年的预测的收益更大，似乎效果更好。但是这是一种自欺欺人的做法，<strong>因为训练的时候已经拿到了后2年的数据，用这样的模型再来预测后2年的走势是不科学的</strong>。这种做法也属于间接偷窥数据的行为。直接偷窥和间接偷窥数据的行为都是不科学的做法，并不能表示训练的模型有多好。</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/4-2.png" alt="img"></p>
<p>还有一个偷窥数据的例子，比如对于某个基准数据集$D$，某人对它建立了一个模型$H_1$，并发表了论文。第二个人看到这篇论文后，又会对$D$，建立一个新的好的模型$H_2$。这样，不断地有人看过前人的论文后，建立新的模型。其实，后面人选择模型时，已经被前人影响了，这也是偷窥数据的一种情况。也许你能对$D$训练很好的模型，但是<strong>可能你仅仅只根据前人的模型，成功避开了一些错误，甚至可能发生了overfitting或者bad generalization</strong>。所以，机器学习领域有这样一句有意思的话“If you torture the data long enough, it will confess.”所以，我们不能太“折磨”我们的数据了，否则它只能“妥协”了。</p>
<p>在机器学习过程中，避免“偷窥数据”非常重要，但实际上，完全避免也很困难。实际操作中，有一些方法可以帮助我们尽量避免偷窥数据：</p>
<ul>
<li>第一个方法是“看不见”数据。就是说当我们在选择模型的时候，尽量用我们的经验和知识来做判断选择，而不是通过数据来选择。先选模型，再看数据。</li>
<li>第二个方法是保持怀疑。就是说时刻保持对别人的论文或者研究成果保持警惕与怀疑，要通过自己的研究与测试来进行模型选择，这样才能得到比较正确的结论。</li>
</ul>
<h3 id="Power-of-Three"><a href="#Power-of-Three" class="headerlink" title="Power of Three"></a>Power of Three</h3><p>对16节课做个简单的总结</p>
<p>首先，我们介绍了跟机器学习相关的三个领域：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/6-2.png" alt="img"></p>
<p>我们还介绍了三个理论保证：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/7-3.png" alt="img"></p>
<p>然后，我们又介绍了三种线性模型：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/8-3.png" alt="img"></p>
<p>同时，我们介绍了三种重要的工具：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/9-3.png" alt="img"></p>
<p>还有我们本节课介绍的三个锦囊妙计：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/10-3.png" alt="img"></p>
<p>最后，我们未来机器学习的方向也分为三种：</p>
<p><img src="http://47.94.229.135/wp-content/uploads/2018/07/11-2.png" alt="img"></p>
<p>完结~</p>

        </div>

        
            <section class="post-copyright">
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://xjw924.github.io/2020/03/17/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part4/">http://xjw924.github.io/2020/03/17/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part4/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>如有错误，还望指正，谢谢！</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/MachineLearning/"># MachineLearning</a>
                    
                        <a href="/tags/Notes/"># Notes</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/03/17/jing-yi-shu-ju-fen-xi-note/">精益数据分析Note</a>
            
            
            <a class="next" rel="next" href="/2020/03/12/latex-xiang-guan/">LaTeX相关</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© xjw924 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
