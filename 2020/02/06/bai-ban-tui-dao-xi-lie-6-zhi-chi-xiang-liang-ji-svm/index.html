<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="xjw924">


    <meta name="subtitle" content="Hi, there~">


    <meta name="description" content="统计|数据分析|机器学习|大数据">



<title>白板推导系列6——支持向量机SVM | 小徐小徐不断学习</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">HOME</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/MachineLearning">Machine Learning</a>
                
                    <a class="menu-item" href="/DataAnalysis">Data Analysis</a>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Category</a>
                
                    <a class="menu-item" href="/tag">Tag</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">HOME</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/MachineLearning">Machine Learning</a>
                
                    <a class="menu-item" href="/DataAnalysis">Data Analysis</a>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Category</a>
                
                    <a class="menu-item" href="/tag">Tag</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">白板推导系列6——支持向量机SVM</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">xjw924</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">February 6, 2020&nbsp;&nbsp;11:50:08</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Notes/">Notes</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <blockquote>
<p>b站up主： <strong>shuhuai008</strong> </p>
<p><a href="https://www.bilibili.com/video/av70839977" target="_blank" rel="noopener">机器学习-白板推导系列-合集</a> 学习笔记</p>
</blockquote>
<p>SVM有三宝：间隔，对偶，核技巧~</p>
<ul>
<li>hard-margin SVM</li>
<li>soft-margin SVM</li>
<li>kernel SVM</li>
</ul>
<h1 id="硬间隔SVM"><a href="#硬间隔SVM" class="headerlink" title="硬间隔SVM"></a>硬间隔SVM</h1><h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><p>找到一个超平面$w^Tx+b=0$，使得两类能够完全分开，且间隔最大。</p>
<p>Data：$\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in \{+1,-1\}$</p>
<p>最大间隔分类器</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\max margin(w,b)\\
s.t.y_i(w^Tx+b)>0,\forall i=1,…,N
\end{array} 
\right.</script><p>其中定义$N$个样本点到直线的最小距离为</p>
<script type="math/tex; mode=display">
margin(w,b)
=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}distance
=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}\frac{1}{||w||}|w^Tx_i+b|
=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}\frac{1}{||w||}y_i(w^Tx_i+b)</script><blockquote>
<p>上式用到了点到直线的距离公式</p>
<script type="math/tex; mode=display">
distance=\frac{1}{||w||}|w^Tx_i+b|</script></blockquote>
<p>因此最大间隔分类器可以表达为</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\max\limits_{w,b} \mathop{\min}\limits_{x_i,i=1,\cdots,N}\frac{1}{||w||}y_i(w^Tx_i+b) \\
s.t.y_i(w^Tx+b)>0,\forall i=1,…,N
\end{array} 
\right.</script><p>可以转化为</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\max\limits_{w,b} \frac{1}{||w||}\mathop{\min}\limits_{x_i,i=1,\cdots,N}y_i(w^Tx_i+b)\\
\exists \gamma>0,s.t.\mathop{\min}\limits_{x_i,y_i,i=1,\cdots,N}y_i(w^Tx_i+b)=\gamma
\end{array} 
\right.</script><p>可以令$\gamma=1$（无论$\gamma$为多少都可以进行缩放至1）</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{w,b} \frac{1}{2}w^Tw\\
s.t.y_i(w^Tx_i+b)\ge1,\forall i=1,…,N
\end{array} 
\right.</script><p>（使用$\frac{1}{2}$作为系数仅为了求导方便）</p>
<p>可以看出该模型是凸二次规划问题，有$N$个约束。</p>
<h2 id="模型求解"><a href="#模型求解" class="headerlink" title="模型求解"></a>模型求解</h2><h3 id="原问题primal-problem"><a href="#原问题primal-problem" class="headerlink" title="原问题primal problem"></a>原问题primal problem</h3><script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{w,b} \frac{1}{2}w^Tw\\
s.t. 1-y_i(w^Tx_i+b)\le0,\forall i=1,…,N
\end{array} 
\right.</script><p>使用拉格朗日乘子法，定义拉格朗日函数为</p>
<script type="math/tex; mode=display">
L(w,b,\lambda)=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b))</script><p>其中$\lambda_i\ge0$，将求解问题转化为</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)\\
s.t. \lambda_i\ge0
\end{array} 
\right.</script><p>从而将带约束的问题转化成无约束的（对$w,b$无约束）</p>
<blockquote>
<p><strong>Q：如何证明带约束的和无约束的是等价的？</strong></p>
<p>如果$1-y_i(w^Tx_i+b)&gt;0$，则$\max\limits_{\lambda } L(w,b,\lambda)=\frac{1}{2}w^Tw+\infty=\infty$</p>
<p>如果$1-y_i(w^Tx_i+b)\le0$，则$\max\limits_{\lambda } L(w,b,\lambda)=\frac{1}{2}w^Tw+0=\frac{1}{2}w^Tw$，$\min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)=\min\limits_{w,b}\frac{1}{2}w^Tw$</p>
<p>因此$\min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)=\min\limits_{w,b}\{\infty,\frac{1}{2}w^Tw\}=\min\limits_{w,b}\frac{1}{2}w^Tw $</p>
<p>且去除了$1-y_i(w^Tx_i+b)&gt;0$部分，即最优解一定满足$1-y_i(w^Tx_i+b)\le0$</p>
<p>（奇妙！！）</p>
</blockquote>
<h3 id="对偶问题dual-problem"><a href="#对偶问题dual-problem" class="headerlink" title="对偶问题dual problem"></a>对偶问题dual problem</h3><script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\max\limits_{\lambda }\min\limits_{w,b}  L(w,b,\lambda)\\
s.t. \lambda_i\ge0
\end{array} 
\right.</script><p>经过某种神秘的证明再结合本身成立的“凤尾$\ge$鸡头”弱对偶关系（$\min\max L\ge\max\min L$），可以证明该情况下（凸优化二次问题）满足强对偶关系，即弱对偶关系“$\ge$”等价于强对偶关系“$=$”（$\min\max L=\max\min L$），因此原问题等价于对偶问题。</p>
<p>对$b$求偏导</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial b}
=\frac{\partial }{\partial b}[\sum_{i=1}^{N}\lambda_i-\sum_{i=1}^{N}\lambda_iy_i(w^Tx_i+b)]=-\sum_{i=1}^{N}\lambda_iy_i=0\\
\Rightarrow\sum_{i=1}^{N}\lambda_iy_i=0</script><p>代入到拉格朗日函数中，从而转化为</p>
<script type="math/tex; mode=display">
L(w,b,\lambda)=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b))=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)</script><p>再对$w$求偏导</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial w}=\frac{\partial }{\partial w}[\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)]
=w-\sum_{i=1}^{N}\lambda_iy_ix_i=0\\
\Rightarrow w=\sum_{i=1}^{N}\lambda_iy_ix_i</script><p>再代入到拉格朗日函数中，从而转化为</p>
<script type="math/tex; mode=display">
\begin{align}
L(w,b,\lambda)
&=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)\\
&=\frac{1}{2}(\sum_{i=1}^{N}\lambda_iy_ix_i)^T(\sum_{j=1}^{N}\lambda_jy_jx_j)+\sum_{i=1}^{N}\lambda_i-\sum_{i=1}^{N}\lambda_iy_i(\sum_{i=1}^{N}\lambda_iy_ix_i)^Tx_i\\
&=-\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\lambda_i\lambda_jy_iy_jx_i^Tx_j+\sum_{i=1}^{N}\lambda_i
\end{align}</script><p>最终的优化问题可以表达为</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{\lambda } \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\lambda_i\lambda_jy_iy_jx_i^Tx_j-\sum_{i=1}^{N}\lambda_i\\
s.t. \lambda_i\ge0,\sum_{i=1}^{N}\lambda_iy_i=0
\end{array} 
\right.</script><h3 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h3><script type="math/tex; mode=display">
\left\{\begin{array}{**lr**}  
\frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0,\frac{\partial L}{\partial \lambda}=0\\
\lambda_i(1-y_i(w^Tx_i+b))=0\\
\lambda_i \ge 0\\
1-y_i(w^Tx_i+b)\le0
\end{array} 
\right.</script><p>原对偶问题具有强对偶关系（默认情况下满足弱对偶关系且是凸二次规划问题且约束是线性的）$\Longleftrightarrow$满足KKT条件</p>
<blockquote>
<p>KKT条件（后有详细）</p>
<p>第一行：梯度条件</p>
<p>第二行$\lambda_i(1-y_i(w^Tx_i+b))=0$：松弛互补条件</p>
<p>第三四行：可行条件</p>
</blockquote>
<p>已经求出最优的$w$解为</p>
<script type="math/tex; mode=display">
w^*=\sum_{i=1}^{N}\lambda_iy_ix_i</script><p>又因为松弛互补条件，一定存在一个样本点$(x_k,y_k)$使得$1-y_k(w^Tx_k+b)=0$</p>
<blockquote>
<p>若不存在，则只能所有$\lambda_i=0$，则目标函数$L(w,b,\lambda)=\frac{1}{2}w^Tw$，没有任何限制</p>
<p>对于少数$\lambda_i\neq 0$的样本称为支持向量 ，实际上只有这些样本在真正起作用</p>
</blockquote>
<p>对其进行化简得到$b^*$</p>
<script type="math/tex; mode=display">
y_k(w^Tx_k+b)=1\\
y_k^2(w^Tx_k+b)=y_k\\
\Rightarrow b^*=y_k-w^Tx_k=y_k-\sum_{i=1}^{N}\lambda_iy_ix_i^Tx_k</script><p>因此决策超平面为</p>
<script type="math/tex; mode=display">
f(x)=sign({w^*}^Tx+b^*)</script><h1 id="软间隔SVM"><a href="#软间隔SVM" class="headerlink" title="软间隔SVM"></a>软间隔SVM</h1><p>数据是不可分的，或数据是可分的但存在一定噪声，此时应使用软间隔SVM</p>
<p>soft：允许一点点错误，用loss来表达，加到损失函数上</p>
<ul>
<li>定义$loss=\sum_{i=1}^{N}I\{y_i(w^Tx_i+b)&lt;1\}$，但缺点在于该loss function不连续，不能求导，因此不使用该loss function</li>
<li>定义loss为距离（合页损失hinge loss），$loss=\sum_{i=1}^{N}\max\{0,1-y_i(w^Tx_i+b)\}$，函数是连续的√<ul>
<li>如果$y_i(w^Tx_i+b)\ge1,loss=0$</li>
<li>如果$y_i(w^Tx_i+b)&lt;1,loss=1-y_i(w^Tx_i+b)$</li>
</ul>
</li>
</ul>
<p>引入$\xi_i=1-y_i(w^Tx_i+b),\xi_i\ge0$，得到软间隔SVM的最终形式</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{\lambda } \frac{1}{2}w^Tw+C\sum_{i=1}^{N}\xi_i\\
s.t. y_i(w^Tx_i+b)\ge1-\xi_i
\end{array} 
\right.</script><h1 id="约束优化问题"><a href="#约束优化问题" class="headerlink" title="约束优化问题"></a>约束优化问题</h1><blockquote>
<p>这一节实际和SVM没有直接关系，是最优化的内容</p>
</blockquote>
<ul>
<li>原问题（Primal Problem）</li>
</ul>
<p>原问题的一般表达形式（原问题的有约束形式）</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{x\in R^p }f(x)\\
s.t. &m_i(x)\le0, i=1,\cdots,M\\
&n_j(x)\le0, j=1,\cdots,N
\end{array} 
\right.</script><p>写成拉格朗日函数的形式</p>
<script type="math/tex; mode=display">
L(x,\lambda,\eta)=f(x)+\sum_{i=1}^{M}\lambda_im_i(x)+\sum_{j=1}^{N}\eta_in_i(x)</script><p>可以将原问题转化为（原问题的无约束形式）</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{x}\max\limits_{\lambda,\eta} L(x,\lambda,\eta)\\
s.t. \lambda_i\ge0
\end{array} 
\right.</script><blockquote>
<p>Q：为何两者是等价的？</p>
<p>如果$x_i$违反约束$m_i(x)\le0$，即$m_i(x)\gt0$，则$\max\limits_{\lambda} L\rightarrow\infty$</p>
<p>如果$x_i$符合约束$m_i(x)\le0$，则$\max\limits_{\lambda} L\nrightarrow\infty$</p>
<p>$\min\limits_{x}\max\limits_{\lambda} L=\min\limits_{x}\{\max\limits_{\lambda} L,\infty\}=\min\limits_{x}\max\limits_{\lambda}  L$</p>
<p>实际上是进行了过滤，其中蕴含了约束$m_i(x)\le0$，自动去掉了$m_i(x)\gt0$的部分</p>
</blockquote>
<ul>
<li>对偶问题（Dual Problem）</li>
</ul>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\max\limits_{\lambda,\eta} \min\limits_{x}L(x,\lambda,\eta)\\
s.t. \lambda_i\ge0
\end{array} 
\right.</script><blockquote>
<p>原问题是关于$x$的函数，对偶问题是关于$\lambda,\eta$的函数</p>
</blockquote>
<h2 id="弱对偶性"><a href="#弱对偶性" class="headerlink" title="弱对偶性"></a>弱对偶性</h2><p>弱对偶性：对偶问题(d)$\le$原问题(p)</p>
<p>之前使用了“凤尾$\ge$鸡头”的比喻来说明，此处在理论上进行证明：</p>
<script type="math/tex; mode=display">
\max\limits_{\lambda,\eta} \min\limits_{x} L(x,\lambda,\eta)\le \min\limits_{x}\max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><p>证：</p>
<p>由于</p>
<script type="math/tex; mode=display">
\min\limits_{x} L(x,\lambda,\eta) \le L(x,\lambda,\eta) \le \max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><blockquote>
<p>可以理解为下面只是变量而已，好比一个多元函数，在某处取最大值还是最小值时，这时你可以只看成关于不同变量的也是可以的，因为函数最大最小值是确定的</p>
</blockquote>
<p>设</p>
<script type="math/tex; mode=display">
A(\lambda,\eta)=\min\limits_{x} L(x,\lambda,\eta) \\
B(x)=\max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><p>则上式转化为</p>
<script type="math/tex; mode=display">
A(\lambda,\eta) \le B(x)\\
\Rightarrow A(\lambda,\eta) \le \min\limits_{x}  B(x)\\
\Rightarrow \max\limits_{\lambda,\eta} A(\lambda,\eta) \le \min\limits_{x}  B(x)\\
\Rightarrow \max\limits_{\lambda,\eta} \min\limits_{x} L(x,\lambda,\eta) \le \min\limits_{x}  \max\limits_{\lambda,\eta} L(x,\lambda,\eta)\\</script><p>从而得证。</p>
<h2 id="对偶性的几何解释"><a href="#对偶性的几何解释" class="headerlink" title="对偶性的几何解释"></a>对偶性的几何解释</h2><p>简化后的优化问题可以表达为</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{**lr**} 
\min\limits_{x\in R^p }f(x)\\
s.t. m_i(x)\le0, i=1,\cdots,M
\end{array} 
\right.</script><p>其中定义域$D=\mathrm{dom}f\cap \mathrm{dom} m_i$</p>
<p>拉格朗日函数定义为</p>
<script type="math/tex; mode=display">
L(x,\lambda)=f(x)+\lambda m_1(x),\lambda\ge0</script><p>原问题最优解定义为</p>
<script type="math/tex; mode=display">
p^*=\min f(x)</script><p>对偶问题最优解定义为</p>
<script type="math/tex; mode=display">
d^*=\max\limits_{\lambda} \min\limits_{x} L(x,\lambda)</script><p>定义区域$G$为（一般化区域$G$认为其为非凸集）</p>
<script type="math/tex; mode=display">
G=\{(m_1(x),f(x))|x\in D\}=\{(u,t)|x\in D\}</script><p>因此$p^*$可以表达为</p>
<script type="math/tex; mode=display">
p^*=\inf\{t|(u,t)\in G,u\le 0\}</script><p>（集合中的下确界相当于集合中的最小值）</p>
<p>$d^*$可以表达为</p>
<script type="math/tex; mode=display">
\begin{align}
d^*
&=\max\limits_{\lambda} \min\limits_{x} L(x,\lambda)\\
&= \max\limits_{\lambda} \min\limits_{x} (t+\lambda u)\\
&= \max\limits_{\lambda} g(\lambda)
\end{align}</script><p>其中$g(\lambda)=\min\limits_{x} (t+\lambda u)=\inf\{t+\lambda u|(u,t)\in G\}$</p>
<p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200207/dEyLlYLvko39.jpg" alt="mark"></p>
<h2 id="slater-condition"><a href="#slater-condition" class="headerlink" title="slater condition"></a>slater condition</h2><p>凸优化 + slater条件 $\Rightarrow$ 强对偶条件</p>
<p>slater condition定义：</p>
<script type="math/tex; mode=display">
\exists \hat{x} \in reliant D\\
s.t. \forall i=1,\cdots,M, m_i(\hat{x})<0</script><p>其中reliant为relative interior（相对内部），去除边界的部分，内点的集合</p>
<ol>
<li>对于大多数凸优化，slater条件成立</li>
<li>放松的slater条件：如果$M$中有$K$个仿射函数，只需要校验剩余的$M-K$个函数是否满足上述条件。（仿射函数：一阶的多项式函数）</li>
</ol>
<p>凸二次规划：目标函数$f$是凸函数，限制条件$m_i$是仿射函数（线性函数一定是仿射函数），$n_j$是仿射函数。</p>
<p><strong>SVM是凸二次规划问题，满足强对偶条件，因此可以使用KKT条件直接求解。</strong></p>
<h2 id="KKT条件-1"><a href="#KKT条件-1" class="headerlink" title="KKT条件"></a>KKT条件</h2><ul>
<li><p><strong>可行条件</strong></p>
<script type="math/tex; mode=display">
m_i(x^{*})\le0, n_j(x^{*})=0, \lambda^{*} \ge0</script></li>
<li><p><strong>互补松弛条件</strong>：$\lambda^*_im_i=0, \forall i=1,\cdots,M$</p>
</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
d^*
&=\max\limits_{\lambda,\eta}g(\lambda,\eta)=g(\lambda^*,\eta^*)\\
&=\min\limits_{x}L(x,\lambda^*,\eta^*)\\
&\le L(x^*,\lambda^*,\eta^*)\\
&=f(x^*)+\sum_{i}\lambda^*_im_i+\sum_{j}\eta^*_jn_j\\
&\le f(x^*)=p^*
\end{align}</script><p>且又因为强对偶关系</p>
<script type="math/tex; mode=display">
d^*=p^*</script><p>因此不等号只能取等号，且$\sum_{j}\eta^*_jn_j=0$，因此由(10)-(11)得</p>
<script type="math/tex; mode=display">
\sum_{i}\lambda^*_im_i=0\\
\Rightarrow \lambda^*_im_i=0, \forall i=1,\cdots,M</script><p>（若存在有一个$\lambda^*_im_i&lt;0$，由于不存在小于0的部分，无法抵消，和无法等于0）</p>
<ul>
<li><strong>梯度为0</strong>：<script type="math/tex; mode=display">
\frac{\partial L(x,\lambda^{*},\eta^{*})}{\partial x}|_{x=x^{*}}=0</script>由(8)-(9)可得<script type="math/tex; mode=display">
\min\limits_{x}L(x,\lambda^*,\eta^*)=L(x^*,\lambda^*,\eta^*)</script>因此<script type="math/tex; mode=display">
\frac{\partial L}{\partial x}|_{x=x^*}=0</script></li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://xjw924.github.io/2020/02/06/bai-ban-tui-dao-xi-lie-6-zhi-chi-xiang-liang-ji-svm/">http://xjw924.github.io/2020/02/06/bai-ban-tui-dao-xi-lie-6-zhi-chi-xiang-liang-ji-svm/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>如有错误，还望指正，谢谢！</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/MachineLearning/"># MachineLearning</a>
                    
                        <a href="/tags/Notes/"># Notes</a>
                    
                        <a href="/tags/Classification/"># Classification</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/02/07/bai-ban-tui-dao-xi-lie-3-xian-xing-hui-gui/">白板推导系列3——线性回归</a>
            
            
            <a class="next" rel="next" href="/2020/02/05/decision-tree-jue-ce-shu-suan-fa-ji-qi-ying-yong/">Decision Tree 决策树算法及其应用</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© xjw924 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
