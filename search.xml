<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PySpark常用操作总结——建模</title>
      <link href="/2020/03/30/pyspark-chang-yong-cao-zuo-zong-jie-mo-xing-ping-gu/"/>
      <url>/2020/03/30/pyspark-chang-yong-cao-zuo-zong-jie-mo-xing-ping-gu/</url>
      
        <content type="html"><![CDATA[<h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><h2 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">lrSummary = lrModel.summary() <span class="comment"># 注：仅lr模型有该接口</span></span><br><span class="line"></span><br><span class="line">AUC = lrSummary.areaUnderROC</span><br><span class="line"></span><br><span class="line">fMeasureDF = lrSummary.fMeasureByThreshold</span><br><span class="line">precisionDF = lrSummary.precisionByThreshold</span><br><span class="line">recallDF = lrSummary.recallByThreshold</span><br><span class="line"></span><br><span class="line">maxFMeasure = fMeasureDF.agg(&#123;<span class="string">"F-Measure"</span>: <span class="string">"max"</span>&#125;).first()[<span class="number">0</span>] <span class="comment"># F-Measure最大值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取F-Measure最大值所对应的threshold/precision/recall</span></span><br><span class="line">curThreshold = fMeasureDF.filter(fMeasureDF[<span class="string">"F-Measure"</span>]&gt;=(maxFMeasure<span class="number">-0.000001</span>))\</span><br><span class="line">                         .filter(fMeasureDF[<span class="string">"F-Measure"</span>]&lt;=(maxFMeasure+<span class="number">0.000001</span>))\</span><br><span class="line">                         .first().threshold <span class="comment"># 由于精度问题不使用等号</span></span><br><span class="line">curPrecision = precisionDF.filter(precisionDF[<span class="string">"threshold"</span>]&gt;=(curThreshold<span class="number">-0.000001</span>))\</span><br><span class="line">                          .filter(precisionDF[<span class="string">"threshold"</span>]&lt;=(curThreshold+<span class="number">0.000001</span>))\</span><br><span class="line">                          .first().precision</span><br><span class="line">curRecall = recallDF.filter(recallDF[<span class="string">"threshold"</span>]&gt;=(curThreshold<span class="number">-0.000001</span>))\</span><br><span class="line">                    .filter(recallDF[<span class="string">"threshold"</span>]&lt;=(curThreshold+<span class="number">0.000001</span>))\</span><br><span class="line">                    .first().recall</span><br><span class="line"></span><br><span class="line">result = &#123;<span class="string">"maxFMeasure"</span>: round(maxFMeasure, <span class="number">3</span>),</span><br><span class="line">          <span class="string">"curThreshold"</span>: round(curThreshold, <span class="number">3</span>),</span><br><span class="line">          <span class="string">"curPrecision"</span>: round(curPrecision, <span class="number">3</span>),</span><br><span class="line">          <span class="string">"curRecall"</span>: round(curRecall, <span class="number">3</span>),</span><br><span class="line">          <span class="string">"AUC"</span>: round(AUC, <span class="number">3</span>)&#125;</span><br></pre></td></tr></table></figure><h2 id="二分类模型"><a href="#二分类模型" class="headerlink" title="二分类模型"></a>二分类模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> BinaryClassificationEvaluator</span><br><span class="line"></span><br><span class="line">evaluator = BinaryClassificationEvaluator(labelCol=<span class="string">"label"</span>, rawPredictionCol=<span class="string">"prediction"</span>) <span class="comment"># 指定标签列和预测列的列名</span></span><br><span class="line"><span class="comment"># resultDF：模型输出的预测结果</span></span><br><span class="line">areaUnderPR = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"areaUnderPR"</span>&#125;)</span><br><span class="line">areaUnderROC = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"areaUnderROC"</span>&#125;)</span><br><span class="line"></span><br><span class="line">truePositiveCount = resultDF.filter(<span class="string">"label == 1 and prediction == 1"</span>).count()</span><br><span class="line">predictedPositiveCount = resultDF.filter(<span class="string">"prediction == 1"</span>).count()</span><br><span class="line">totalPositiveCount = resultDF.filter(<span class="string">"label == 1"</span>).count()</span><br><span class="line"></span><br><span class="line">precision = <span class="number">1.0</span> * truePositiveCount / predictedPositiveCount</span><br><span class="line">recall = <span class="number">1.0</span> * truePositiveCount / totalPositiveCount</span><br><span class="line"></span><br><span class="line">result = &#123;<span class="string">"areaUnderPR"</span>: round(areaUnderPR,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"AUC"</span>: round(areaUnderROC,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"precision"</span>: round(precision,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"recall"</span>: round(recall,<span class="number">3</span>)&#125;</span><br></pre></td></tr></table></figure><h2 id="ROC曲线-PR曲线"><a href="#ROC曲线-PR曲线" class="headerlink" title="ROC曲线/PR曲线"></a>ROC曲线/PR曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对positive_probability降低精度，提高运算效率</span></span><br><span class="line">trimRoundedDF = resultDF.select(<span class="string">"label"</span>,<span class="string">"positive_probability"</span>)\</span><br><span class="line">              .rdd.map(<span class="keyword">lambda</span> row: (row[<span class="string">"label"</span>], round(row[<span class="string">"positive_probability"</span>],<span class="number">4</span>)))\</span><br><span class="line">              .toDF([<span class="string">"label"</span>, <span class="string">"positive_probability"</span>])</span><br><span class="line">trimRoundedDF.cache()</span><br><span class="line"></span><br><span class="line">listOfPRF = []</span><br><span class="line">listOfTpFp = []</span><br><span class="line">steps = <span class="number">200</span> <span class="comment"># 设置threshold的遍历步长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> threshold <span class="keyword">in</span> [<span class="number">1.0</span>/steps*i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,steps,<span class="number">1</span>)]:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"*** Handling Threshold:&#123;threshold&#125; ***"</span>.format(threshold=threshold))</span><br><span class="line">    tmpCalcDF = trimRoundedDF.rdd.map(<span class="keyword">lambda</span> row:(int(row[<span class="string">"label"</span>]),<span class="number">1</span> <span class="keyword">if</span> row[<span class="string">"positive_probability"</span>] &gt;= threshold <span class="keyword">else</span> <span class="number">0</span>)).toDF([<span class="string">"label"</span>,<span class="string">"prediction"</span>])</span><br><span class="line">    tmpResult = tmpCalcDF.selectExpr(</span><br><span class="line">        <span class="string">"sum(case when label = 0 and prediction = 1 then 1 else 0 end) as FP"</span>,</span><br><span class="line">        <span class="string">"sum(case when label = 1 and prediction = 0 then 1 else 0 end) as FN"</span>,</span><br><span class="line">        <span class="string">"sum(case when label = 1 and prediction = 1 then 1 else 0 end) as TP"</span>,</span><br><span class="line">        <span class="string">"sum(case when label = 0 and prediction = 0 then 1 else 0 end) as TN"</span></span><br><span class="line">    ).collect()[<span class="number">0</span>]</span><br><span class="line">    actualPositive = tmpResult.TP + tmpResult.FN</span><br><span class="line">    actualNegative = tmpResult.TN + tmpResult.FP</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        precision = tmpResult.TP / (tmpResult.TP + tmpResult.FP)</span><br><span class="line">        recall = tmpResult.TP / actualPositive</span><br><span class="line">        TPR = recall <span class="comment"># 分到正样本中真实的正样本所占所有正样本的比例</span></span><br><span class="line">        FPR = tmpResult.FP / (tmpResult.FP + tmpResult.TN) <span class="comment"># 分到正样本类别中真实的负样本所占所有负样本总数的比例</span></span><br><span class="line">        fMeasure = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">        listOfPRF.append([precision,recall,fMeasure])</span><br><span class="line">        listOfTpFp.append([TPR,FPR])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># 超过阈值全部预测为0的情况</span></span><br><span class="line">        print(<span class="string">"TP: %s"</span> % tmpResult.TP)</span><br><span class="line">        print(<span class="string">"FN: %s"</span> % tmpResult.FN)</span><br><span class="line">        print(<span class="string">"TN: %s"</span> % tmpResult.TN)</span><br><span class="line">        print(<span class="string">"FP: %s"</span> % tmpResult.FP)</span><br><span class="line">        listOfPRF.append([<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line">        listOfTpFp.append([<span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line">    <span class="comment"># 计算最大的FMeasure</span></span><br><span class="line">    maxFMeasureGroup = sorted(listOfPRF, key=<span class="keyword">lambda</span> x: x[<span class="number">-1</span>], reverse=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算PR曲线面积（PR曲线横坐标为recall，纵坐标为precision）</span></span><br><span class="line">    sortedListOfPRF = sorted(listOfPRF, key=<span class="keyword">lambda</span> x: (x[<span class="number">1</span>],x[<span class="number">0</span>]) ,reverse=<span class="literal">False</span>) <span class="comment"># 保证横纵坐标是增加的（便于计算近似梯形面积）</span></span><br><span class="line">    prArea = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(steps<span class="number">-1</span>):</span><br><span class="line">        prArea += (sortedListOfPRF[i][<span class="number">0</span>] + sortedListOfPRF[i+<span class="number">1</span>][<span class="number">0</span>]) / <span class="number">2</span>*(sortedListOfPRF[i+<span class="number">1</span>][<span class="number">1</span>] - sortedListOfPRF[i][<span class="number">1</span>]) <span class="comment"># 近似为梯形面积</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算ROC曲线面积AUC</span></span><br><span class="line">    AUC = <span class="number">0</span></span><br><span class="line">    sortedListOfTpFp = sorted(listOfTpFp, key=<span class="keyword">lambda</span> x: (x[<span class="number">1</span>],x[<span class="number">0</span>]) ,reverse=<span class="literal">False</span>) <span class="comment"># 保证横纵坐标是增加的（便于计算近似梯形面积）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(steps<span class="number">-1</span>):</span><br><span class="line">        AUC += (sortedListOfTpFp[i][<span class="number">0</span>] + sortedListOfTpFp[i+<span class="number">1</span>][<span class="number">0</span>]) / <span class="number">2</span>*(sortedListOfTpFp[i+<span class="number">1</span>][<span class="number">1</span>] - sortedListOfTpFp[i][<span class="number">1</span>]) <span class="comment"># 近似为梯形面积</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成PR曲线DF</span></span><br><span class="line">    prfData = [tuple(r) <span class="keyword">for</span> r <span class="keyword">in</span> sortedListOfPRF]</span><br><span class="line">    prfDF = spark.createDataFrame(prfData, schema=[<span class="string">'precision'</span>,<span class="string">'recall'</span>,<span class="string">'fMeasure'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成ROC曲线DF</span></span><br><span class="line">    rocData = [tuple(r) <span class="keyword">for</span> r <span class="keyword">in</span> sortedListOfTpFp]</span><br><span class="line">    tpfpDF = spark.createDataFrame(rocData, schema=[<span class="string">'TPR'</span>,<span class="string">'FPR'</span>])</span><br><span class="line">    </span><br><span class="line">    result = &#123;</span><br><span class="line">        <span class="string">"maxFMeasure"</span>: maxFMeasureGroup[<span class="number">-1</span>],</span><br><span class="line">        <span class="string">"precisionAtMaxFMeasure"</span>: maxFMeasureGroup[<span class="number">0</span>],</span><br><span class="line">        <span class="string">"recallAtMaxFMeasure"</span>: maxFMeasureGroup[<span class="number">1</span>],</span><br><span class="line">        <span class="string">"areaUnderPR"</span>: prArea,</span><br><span class="line">        <span class="string">"areaUnderROC"</span>: AUC,</span><br><span class="line">        <span class="string">"prfDF"</span>: prfDF,</span><br><span class="line">        <span class="string">"tpfpDF"</span>: tpfpDF</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="多分类模型"><a href="#多分类模型" class="headerlink" title="多分类模型"></a>多分类模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"label"</span>, rawPredictionCol=<span class="string">"prediction"</span>) <span class="comment"># 指定标签列和预测列的列名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># resultDF：模型输出的预测结果</span></span><br><span class="line">accuracy = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"accuracy"</span>&#125;)</span><br><span class="line">weightedPrecision = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"weightedPrecision"</span>&#125;)</span><br><span class="line">weightedRecall = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"weightedRecall"</span>&#125;)</span><br><span class="line">f1 = evaluator.evaluate(resultDF, &#123;evaluator.metricName:<span class="string">"f1"</span>&#125;)</span><br><span class="line"></span><br><span class="line">result = &#123;<span class="string">"accuracy"</span>: round(accuracy,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"weightedPrecision"</span>: round(weightedPrecision,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"weightedRecall"</span>: round(weightedRecall,<span class="number">3</span>),</span><br><span class="line">          <span class="string">"f1"</span>: round(f1,<span class="number">3</span>)&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Spark建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PySpark常用操作总结——建模</title>
      <link href="/2020/03/30/pyspark-chang-yong-cao-zuo-zong-jie-jian-mo/"/>
      <url>/2020/03/30/pyspark-chang-yong-cao-zuo-zong-jie-jian-mo/</url>
      
        <content type="html"><![CDATA[<h1 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h1><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>将建模所需的字段合并为一列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"></span><br><span class="line"><span class="comment"># featureList: 建模所需要的字段</span></span><br><span class="line">assembler = VectorAssembler(inputCols=featureList, outputCol=<span class="string">"features"</span>)</span><br><span class="line">resultDF = assembler.transform(df)</span><br></pre></td></tr></table></figure><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.write().overwrite().save(modelPath + modelName)</span><br></pre></td></tr></table></figure><h2 id="读取模型"><a href="#读取模型" class="headerlink" title="读取模型"></a>读取模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegressionModel, RandomForestClassificationModel, GBTClassificationModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># LR</span></span><br><span class="line">lrModel = LogisticRegressionModel.load(modelPath + modelName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RF</span></span><br><span class="line">rfModel = RandomForestClassificationModel.load(modelPath + modelName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GBDT</span></span><br><span class="line">gbdtModel = GBTClassificationModel.load(modelPath + modelName)</span><br></pre></td></tr></table></figure><h2 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression, LogisticRegressionModel</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lrModel = lr.fit(df) <span class="comment"># df为特征转换为features一列的DataFrame</span></span><br><span class="line">resultDF = lrModel.transform(df).select(<span class="string">"label"</span>, <span class="string">"prediction"</span>, <span class="string">"probability"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 截距</span></span><br><span class="line">intercept = lrModel.intercept</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分类：因子系数</span></span><br><span class="line">featCoefficients = list(zip(featList, list(lrModel.coefficients)))</span><br><span class="line">featCoefficientDict = &#123;k: round(v,<span class="number">4</span>) <span class="keyword">for</span> (k,v) <span class="keyword">in</span> featCoefficients&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多分类：因子系数矩阵</span></span><br><span class="line">coeMatrix = lrModel.coefficientMatrix.toArray()</span><br><span class="line">zippedFeatCoefficient = [dict(zip(featList, [round(v,<span class="number">4</span>) <span class="keyword">for</span> v <span class="keyword">in</span> r])) <span class="keyword">for</span> r <span class="keyword">in</span> coeMatrix]</span><br><span class="line">labelList = [row[<span class="string">"label"</span>] <span class="keyword">for</span> row <span class="keyword">in</span> resultDF.select(<span class="string">"label"</span>).distinct().collect()]</span><br><span class="line">featCoefficientMatrix = dict(list(zip(labelList, zippedFeatCoefficient)))</span><br></pre></td></tr></table></figure><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> RandomForestClassifier, RandomForestClassificationModel</span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier()</span><br><span class="line">rfModel = rf.fit(df)</span><br><span class="line">resultDF = rfModel.transform(df).select(<span class="string">"label"</span>, <span class="string">"prediction"</span>, <span class="string">"probability"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分预测概率</span></span><br><span class="line">cols = [<span class="string">"label"</span>, <span class="string">"prediction"</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(row)</span>:</span></span><br><span class="line">    newRow = tuple([row[k] <span class="keyword">for</span> k <span class="keyword">in</span> cols]) + tuple(row.probability.toArray().tolist())</span><br><span class="line">    <span class="keyword">return</span> newRow</span><br><span class="line">resultDF = resultDF.rdd.map(extract).toDF(cols+[<span class="string">'negative_probability'</span>,<span class="string">'positive_probability'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">featImportances = rfModel.featureImportances.toArray()</span><br><span class="line">featImportanceDict = &#123;k: round(v,<span class="number">4</span>) <span class="keyword">for</span> k,v <span class="keyword">in</span> list(zip(featList,featImportances))&#125;</span><br></pre></td></tr></table></figure><h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> GBTClassifier, GBTClassificationModel</span><br><span class="line"></span><br><span class="line">gbdt = GBTClassifier()</span><br><span class="line">gbdtModel = gbdt.fit(df)</span><br><span class="line">resultDF = gbdtModel.transform(df).select(<span class="string">"label"</span>, <span class="string">"prediction"</span>, <span class="string">"probability"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">featImportances = gbdtModel.featureImportances.toArray()</span><br><span class="line">featImportanceDict = &#123;k: round(v,<span class="number">4</span>) <span class="keyword">for</span> k,v <span class="keyword">in</span> list(zip(featList,featImportances))&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Spark建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PySpark常用操作总结——增删改查</title>
      <link href="/2020/03/22/pyspark-chang-yong-cao-zuo-zong-jie-zeng-shan-gai-cha/"/>
      <url>/2020/03/22/pyspark-chang-yong-cao-zuo-zong-jie-zeng-shan-gai-cha/</url>
      
        <content type="html"><![CDATA[<h1 id="配置-amp-启动"><a href="#配置-amp-启动" class="headerlink" title="配置&amp;启动"></a>配置&amp;启动</h1><p>测试环境：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pyspark</span><br><span class="line">--master yarn-client</span><br><span class="line">--driver-cores <span class="number">1</span></span><br><span class="line">--driver-memory <span class="number">2</span>g</span><br><span class="line">--num-executors <span class="number">2</span></span><br><span class="line">--executor-cores <span class="number">1</span></span><br><span class="line">--executor-memory <span class="number">3</span>g</span><br><span class="line"><span class="comment">#--queue ...</span></span><br><span class="line"><span class="comment">#--name ...</span></span><br></pre></td></tr></table></figure><p>可适当调大</p><p>建议：executor的cores:memory = 1:3<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext, SparkSession, Row, DataFrame</span><br><span class="line"></span><br><span class="line">sc = SparkContext()</span><br></pre></td></tr></table></figure></p><h1 id="格式转换-amp-保存"><a href="#格式转换-amp-保存" class="headerlink" title="格式转换&amp;保存"></a>格式转换&amp;保存</h1><p>spark dataframe持久化为hive表（若表名重复则替换旧表）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark_df.write.saveAsTable(tableName)</span><br></pre></td></tr></table></figure><p>spark dataframe存成临时表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark_df.registerTempTable(<span class="string">"tableName"</span>) </span><br><span class="line">sql_result = spark.sql(<span class="string">"select * from tableName"</span>) <span class="comment"># 对临时表进行查询，可简化嵌套查询</span></span><br></pre></td></tr></table></figure><blockquote><p>使用registerTempTable注册表是一个临时表，生命周期只在所定义的sqlContext或hiveContext实例之中。换而言之，在一个sqlontext（或hiveContext）中registerTempTable的表不能在另一个sqlContext（或hiveContext）中使用。</p><p>而saveAsTable则是永久的，只要连接存在，spark再启的时候，这个表还是在的。</p></blockquote><p>spark dataframe转化为pandas dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pandas_df = spark_df.toPandas()</span><br></pre></td></tr></table></figure><p>注：数据量大会非常缓慢，数据量小适用</p><p>pandas dataframe转spark dataframe</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark_df = sqlContext.createDataFrame(pandas_df)</span><br></pre></td></tr></table></figure><p>本地csv转spark dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">raw_rdd = sc.text_file(<span class="string">"data.csv"</span>)</span><br><span class="line">df_spark = spark.createDataFrame(raw_rdd)</span><br></pre></td></tr></table></figure><h1 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h1><h2 id="查"><a href="#查" class="headerlink" title="查"></a>查</h2><h3 id="行元素查询操作"><a href="#行元素查询操作" class="headerlink" title="行元素查询操作"></a>行元素查询操作</h3><p>像SQL那样打印列表前20元素<br>show函数内可用int类型指定要打印的行数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line">df.show(<span class="number">30</span>)</span><br></pre></td></tr></table></figure><p>以树的形式打印概要</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure><p>获取头几行到本地：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list = df.head(<span class="number">3</span>)   <span class="comment"># Example: [Row(a=1, b=1), Row(a=2, b=2), ... ...]</span></span><br><span class="line">list = df.take(<span class="number">5</span>)   <span class="comment"># Example: [Row(a=1, b=1), Row(a=2, b=2), ... ...]</span></span><br></pre></td></tr></table></figure></p><p>查询总行数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.count()python</span><br></pre></td></tr></table></figure><p>取别名<br>df.select(df.age.alias(‘age_value’),’name’)<br>1<br>查询某列为null的行：<br>from pyspark.sql.functions import isnull<br>df = df.filter(isnull(“col_a”))<br>1<br>2<br>输出list类型，list中每个元素是Row类：<br>list = df.collect()<br>1<br>注：此方法将所有数据全部导入到本地，返回一个Array对象</p><p>查询概况<br>df.describe().show()<br>1<br>以及查询类型，之前是type，现在是df.printSchema()</p><p>root<br> |— user_pin: string (nullable = true)<br> |— a: string (nullable = true)<br> |— b: string (nullable = true)<br> |— c: string (nullable = true)<br> |— d: string (nullable = true)<br> |— e: string (nullable = true)<br>…<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>如上图所示，只是打印出来。</p><p>去重set操作<br>data.select(‘columns’).distinct().show()<br>1<br>跟py中的set一样，可以distinct()一下去重，同时也可以.count()计算剩余个数</p><p>随机抽样<br>随机抽样有两种方式，一种是在HIVE里面查数随机；另一种是在pyspark之中。</p><p>HIVE里面查数随机</p><p>sql = “select * from data order by rand()  limit 2000”<br>1<br>pyspark之中</p><p>sample = result.sample(False,0.5,0) # randomly select 50% of lines<br>1<br>— 1.2 列元素操作 —<br>获取Row元素的所有列名：<br>r = Row(age=11, name=’Alice’)<br>print r.columns    #  [‘age’, ‘name’]<br>1<br>2<br>选择一列或多列：select<br>df[“age”]<br>df.age<br>df.select(“name”)<br>df.select(df[‘name’], df[‘age’]+1)<br>df.select(df.a, df.b, df.c)    # 选择a、b、c三列<br>df.select(df[“a”], df[“b”], df[“c”])    # 选择a、b、c三列<br>1<br>2<br>3<br>4<br>5<br>6<br>重载的select方法：<br>jdbcDF.select(jdbcDF( “id” ), jdbcDF( “id”) + 1 ).show( false)<br>1<br>会同时显示id列 + id + 1列</p><p>还可以用where按条件选择<br>jdbcDF .where(“id = 1 or c1 = ‘b’” ).show()<br>1<br>— 1.3 排序 —<br>orderBy和sort：按指定字段排序，默认为升序</p><p>train.orderBy(train.Purchase.desc()).show(5)<br>Output:<br>+———-+—————+———+——-+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|<br>+———-+—————+———+——-+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>|1003160| P00052842|     M|26-35|        17|            C|                         3|             0|                10|                15|              null|   23961|<br>|1002272| P00052842|     M|26-35|         0|            C|                         1|             0|                10|                15|              null|   23961|<br>|1001474| P00052842|     M|26-35|         4|            A|                         2|             1|                10|                15|              null|   23961|<br>|1005848| P00119342|     M|51-55|        20|            A|                         0|             1|                10|                13|              null|   23960|<br>|1005596| P00117642|     M|36-45|        12|            B|                         1|             0|                10|                16|              null|   23960|<br>+———-+—————+———+——-+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>only showing top 5 rows<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>按指定字段排序。加个-表示降序排序</p><p>— 1.4 抽样 —<br>sample是抽样函数</p><p>t1 = train.sample(False, 0.2, 42)<br>t2 = train.sample(False, 0.2, 43)<br>t1.count(),t2.count()<br>Output:<br>(109812, 109745)<br>1<br>2<br>3<br>4<br>5<br>withReplacement = True or False代表是否有放回。<br>fraction = x, where x = .5，代表抽取百分比</p><p>— 1.5 按条件筛选when / between —<br>when(condition, value1).otherwise(value2)联合使用：<br>那么：当满足条件condition的指赋值为values1,不满足条件的则赋值为values2.<br>otherwise表示，不满足条件的情况下，应该赋值为啥。</p><p>demo1</p><blockquote><blockquote><blockquote><p>from pyspark.sql import functions as F<br>df.select(df.name, F.when(df.age &gt; 4, 1).when(df.age &lt; 3, -1).otherwise(0)).show()<br>+——-+——————————————————————————————+<br>| name|CASE WHEN (age &gt; 4) THEN 1 WHEN (age &lt; 3) THEN -1 ELSE 0 END|<br>+——-+——————————————————————————————+<br>|Alice|                                                          -1|<br>|  Bob|                                                           1|<br>+——-+——————————————————————————————+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>demo 2:多个when串联</p></blockquote></blockquote></blockquote><p>df = df.withColumn(‘mod_val_test1’,F.when(df[‘rand’] &lt;= 0.35,1).when(df[‘rand’] &lt;= 0.7, 2).otherwise(3))<br>1<br>between(lowerBound, upperBound)<br>筛选出某个范围内的值，返回的是TRUE or FALSE</p><blockquote><blockquote><blockquote><p>df.select(df.name, df.age.between(2, 4)).show()<br>+——-+—————————————-+<br>| name|((age &gt;= 2) AND (age &lt;= 4))|<br>+——-+—————————————-+<br>|Alice|                       true|<br>|  Bob|                      false|<br>+——-+—————————————-+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>选择dataframe中间的特定行数<br>而我使用的dataframe前两种方法都没法解决。特点如下：</p></blockquote></blockquote></blockquote><p>特定列中的内容为字符串，并非数值，不能直接比较大小。<br>所选取数据为中间行，如第10~20行，不能用函数直接选取。<br>最终的解决方法如下：</p><p>首先添加行索引，然后选择特定区间内的行索引，从而选取特定中间行。<br>第一步，添加行索引。</p><p>from pyspark.sql.functions import monotonically_increasing_id</p><p>dfWithIndex = df.withColumn(“id”,monotonically_increasing_id())<br>1<br>2<br>3<br>第二步，筛选特定行。</p><p>dfWithIndex.select(dfWithIndex.name, dfWithIndex.id.between(50, 100)).show()<br>1<br>2、———— 增、改 ————<br>— 2.1 新建数据 —<br>有这么两种常规的新建数据方式：createDataFrame、.toDF()</p><p>sqlContext.createDataFrame(pd.dataframe())<br>1<br>是把pandas的dataframe转化为spark.dataframe格式，所以可以作为两者的格式转化</p><p>from pyspark.sql import Row<br>row = Row(“spe_id”, “InOther”)<br>x = [‘x1’,’x2’]<br>y = [‘y1’,’y2’]<br>new_df = sc.parallelize([row(x[i], y[i]) for i in range(2)]).toDF()<br>1<br>2<br>3<br>4<br>5<br>Row代表的是该数据集的列名。</p><p>— 2.2 新增数据列 withColumn—<br>withColumn是通过添加或替换与现有列有相同的名字的列，返回一个新的DataFrame</p><p>result3.withColumn(‘label’, 0)<br>1<br>或者案例</p><p>train.withColumn(‘Purchase_new’, train.Purchase /2.0).select(‘Purchase’,’Purchase_new’).show(5)<br>Output:<br>+————+——————+<br>|Purchase|Purchase_new|<br>+————+——————+<br>|    8370|      4185.0|<br>|   15200|      7600.0|<br>|    1422|       711.0|<br>|    1057|       528.5|<br>|    7969|      3984.5|<br>+————+——————+<br>only showing top 5 rows<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br><strong>报错：</strong>AssertionError: col should be Column，一定要指定某现有列</p><p>有两种方式可以实现：</p><p>一种方式通过functions<br>from pyspark.sql import functions<br>result3 = result3.withColumn(‘label’,  functions.lit(0))<br>1<br>2<br>但是！！ 如何新增一个特别List??(参考：王强的知乎回复)<br>python中的list不能直接添加到dataframe中，需要先将list转为新的dataframe,然后新的dataframe和老的dataframe进行join操作, 下面的例子会先新建一个dataframe，然后将list转为dataframe，然后将两者join起来。</p><p>from pyspark.sql.functions import lit</p><p>df = sqlContext.createDataFrame(<br>    [(1, “a”, 23.0), (3, “B”, -23.0)], (“x1”, “x2”, “x3”))<br>from pyspark.sql.functions import monotonically_increasing_id<br>df = df.withColumn(“id”, monotonically_increasing_id())<br>df.show()<br>+—-+—-+——-+—-+<br>| x1| x2|   x3| id|<br>+—-+—-+——-+—-+<br>|  1|  a| 23.0|  0|<br>|  3|  B|-23.0|  1|<br>+—-+—-+——-+—-+<br>from pyspark.sql import Row<br>l = [‘jerry’, ‘tom’]<br>row = Row(“pid”, “name”)<br>new_df = sc.parallelize([row(i, l[i]) for i in range(0,len(l))]).toDF()<br>new_df.show()<br>+—-+——-+<br>|pid| name|<br>+—-+——-+<br>|  0|jerry|<br>|  1|  tom|<br>+—-+——-+<br>join_df = df.join(new_df, df.id==new_df.pid)<br>join_df.show()<br>+—-+—-+——-+—-+—-+——-+<br>| x1| x2|   x3| id|pid| name|<br>+—-+—-+——-+—-+—-+——-+<br>|  1|  a| 23.0|  0|  0|jerry|<br>|  3|  B|-23.0|  1|  1|  tom|<br>+—-+—-+——-+—-+—-+——-+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32</p><h5 id="坑啊！！！其中，monotonically-increasing-id-生成的ID保证是单调递增和唯一的，但不是连续的。"><a href="#坑啊！！！其中，monotonically-increasing-id-生成的ID保证是单调递增和唯一的，但不是连续的。" class="headerlink" title="坑啊！！！其中，monotonically_increasing_id()生成的ID保证是单调递增和唯一的，但不是连续的。"></a><strong>坑啊！！！</strong>其中，monotonically_increasing_id()生成的ID保证是单调递增和唯一的，但不是连续的。</h5><p>所以，有可能，单调到1-140000，到了第144848个，就变成一长串：8845648744563，所以千万要注意！！</p><p>另一种方式通过另一个已有变量：<br>result3 = result3.withColumn(‘label’,  df.result*0 )<br>1<br>修改原有df[“xx”]列的所有值：<br>df = df.withColumn(“xx”, 1)<br>1<br>修改列的类型（类型投射）：<br>df = df.withColumn(“year2”, df[“year1”].cast(“Int”))<br>1<br>修改列名<br>jdbcDF.withColumnRenamed( “id” , “idx” )<br>1<br>— 2.3 过滤数据—</p><h5 id="过滤数据（filter和where方法相同）："><a href="#过滤数据（filter和where方法相同）：" class="headerlink" title="过滤数据（filter和where方法相同）："></a>过滤数据（filter和where方法相同）：</h5><p>df = df.filter(df[‘age’]&gt;21)<br>df = df.where(df[‘age’]&gt;21)<br>1<br>2<br>多个条件jdbcDF .filter(“id = 1 or c1 = ‘b’” ).show()</p><h5 id="对null或nan数据进行过滤："><a href="#对null或nan数据进行过滤：" class="headerlink" title="对null或nan数据进行过滤："></a>对null或nan数据进行过滤：</h5><p>from pyspark.sql.functions import isnan, isnull<br>df = df.filter(isnull(“a”))  # 把a列里面数据为null的筛选出来（代表python的None类型）<br>df = df.filter(isnan(“a”))  # 把a列里面数据为nan的筛选出来（Not a Number，非数字数据）<br>1<br>2<br>3<br>3、———— 合并 join / union ————<br>3.1 横向拼接rbind<br>result3 = result1.union(result2)<br>jdbcDF.unionALL(jdbcDF.limit(1)) # unionALL<br>1<br>2<br>— 3.2 Join根据条件 —<br>单字段Join<br>合并2个表的join方法：</p><p> df_join = df_left.join(df_right, df_left.key == df_right.key, “inner”)<br>1<br>其中，方法可以为：inner, outer, left_outer, right_outer, leftsemi.<br>其中注意，一般需要改为：left_outer</p><p>多字段join<br>joinDF1.join(joinDF2, Seq(“id”, “name”)）<br>1<br>混合字段<br>joinDF1.join(joinDF2 , joinDF1(“id” ) === joinDF2( “t1_id”))<br>1<br>跟pandas 里面的left_on,right_on</p><p>— 3.2 求并集、交集 —<br>来看一个例子，先构造两个dataframe：</p><p>sentenceDataFrame = spark.createDataFrame((<br>      (1, “asf”),<br>      (2, “2143”),<br>      (3, “rfds”)<br>    )).toDF(“label”, “sentence”)<br>sentenceDataFrame.show()</p><p>sentenceDataFrame1 = spark.createDataFrame((<br>      (1, “asf”),<br>      (2, “2143”),<br>      (4, “f8934y”)<br>    )).toDF(“label”, “sentence”)<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12</p><h1 id="差集"><a href="#差集" class="headerlink" title="差集"></a>差集</h1><p>newDF = sentenceDataFrame1.select(“sentence”).subtract(sentenceDataFrame.select(“sentence”))<br>newDF.show()</p><p>+————+<br>|sentence|<br>+————+<br>|  f8934y|<br>+————+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9</p><h1 id="交集"><a href="#交集" class="headerlink" title="交集"></a>交集</h1><p>newDF = sentenceDataFrame1.select(“sentence”).intersect(sentenceDataFrame.select(“sentence”))<br>newDF.show()</p><p>+————+<br>|sentence|<br>+————+<br>|     asf|<br>|    2143|<br>+————+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10</p><h1 id="并集"><a href="#并集" class="headerlink" title="并集"></a>并集</h1><p>newDF = sentenceDataFrame1.select(“sentence”).union(sentenceDataFrame.select(“sentence”))<br>newDF.show()</p><p>+————+<br>|sentence|<br>+————+<br>|     asf|<br>|    2143|<br>|  f8934y|<br>|     asf|<br>|    2143|<br>|    rfds|<br>+————+</p><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15</p><h1 id="并集-去重"><a href="#并集-去重" class="headerlink" title="并集 + 去重"></a>并集 + 去重</h1><p>newDF = sentenceDataFrame1.select(“sentence”).union(sentenceDataFrame.select(“sentence”)).distinct()<br>newDF.show()</p><p>+————+<br>|sentence|<br>+————+<br>|    rfds|<br>|     asf|<br>|    2143|<br>|  f8934y|<br>+————+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>— 3.3 分割：行转列 —<br>有时候需要根据某个字段内容进行分割，然后生成多行，这时可以使用explode方法<br>　　下面代码中，根据c3字段中的空格将字段内容进行分割，分割的内容存储在新的字段c3_中，如下所示</p><p>jdbcDF.explode( “c3” , “c3_” ){time: String =&gt; time.split( “ “ )}<br>1</p><p>4 ———— 统计 ————<br>— 4.1 频数统计与筛选 ——<br>jdbcDF.stat.freqItems(Seq (“c1”) , 0.3).show()<br>1<br>根据c4字段，统计该字段值出现频率在30%以上的内容</p><p>— 4.2 分组统计—<br>交叉分析<br>train.crosstab(‘Age’, ‘Gender’).show()<br>Output:<br>+—————+——-+———+<br>|Age_Gender|    F|     M|<br>+—————+——-+———+<br>|      0-17| 5083| 10019|<br>|     46-50|13199| 32502|<br>|     18-25|24628| 75032|<br>|     36-45|27170| 82843|<br>|       55+| 5083| 16421|<br>|     51-55| 9894| 28607|<br>|     26-35|50752|168835|<br>+—————+——-+———+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>groupBy方法整合：<br>train.groupby(‘Age’).agg({‘Purchase’: ‘mean’}).show()<br>Output:<br>+——-+————————-+<br>|  Age|    avg(Purchase)|<br>+——-+————————-+<br>|51-55|9534.808030960236|<br>|46-50|9208.625697468327|<br>| 0-17|8933.464640444974|<br>|36-45|9331.350694917874|<br>|26-35|9252.690632869888|<br>|  55+|9336.280459449405|<br>|18-25|9169.663606261289|<br>+——-+————————-+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>另外一些demo：</p><p>df[‘x1’].groupby(df[‘x2’]).count().reset_index(name=’x1’)<br>1<br>分组汇总</p><p>train.groupby(‘Age’).count().show()<br>Output:<br>+——-+———+<br>|  Age| count|<br>+——-+———+<br>|51-55| 38501|<br>|46-50| 45701|<br>| 0-17| 15102|<br>|36-45|110013|<br>|26-35|219587|<br>|  55+| 21504|<br>|18-25| 99660|<br>+——-+———+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>应用多个函数：</p><p>from pyspark.sql import functions<br>df.groupBy(“A”).agg(functions.avg(“B”), functions.min(“B”), functions.max(“B”)).show()<br>1<br>2<br>整合后GroupedData类型可用的方法（均返回DataFrame类型）：<br>avg(<em>cols)     ——   计算每组中一列或多列的平均值<br>count()          ——   计算每组中一共有多少行，返回DataFrame有2列，一列为分组的组名，另一列为行总数<br>max(</em>cols)    ——   计算每组中一列或多列的最大值<br>mean(<em>cols)  ——  计算每组中一列或多列的平均值<br>min(</em>cols)     ——  计算每组中一列或多列的最小值<br>sum(*cols)    ——   计算每组中一列或多列的总和<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>— 4.3 apply 函数 —<br>将df的每一列应用函数f：</p><p>df.foreach(f) 或者 df.rdd.foreach(f)<br>1<br>将df的每一块应用函数f：</p><p>df.foreachPartition(f) 或者 df.rdd.foreachPartition(f)<br>1<br>—— 4.4 【Map和Reduce应用】返回类型seqRDDs ——<br>map函数应用<br>可以参考：Spark Python API函数学习：pyspark API(1)</p><p>train.select(‘User_ID’).rdd.map(lambda x:(x,1)).take(5)<br>Output:<br>[(Row(User_ID=1000001), 1),<br> (Row(User_ID=1000001), 1),<br> (Row(User_ID=1000001), 1),<br> (Row(User_ID=1000001), 1),<br> (Row(User_ID=1000002), 1)]<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>其中map在spark2.0就移除了，所以只能由rdd.调用。</p><p>data.select(‘col’).rdd.map(lambda l: 1 if l in [‘a’,’b’] else 0 ).collect()</p><p>print(x.collect())<br>print(y.collect())</p><p>[1, 2, 3]<br>[(1, 1), (2, 4), (3, 9)]<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>还有一种方式mapPartitions：</p><p>def _map_to_pandas(rdds):<br>    “”” Needs to be here due to pickling issues “””<br>    return [pd.DataFrame(list(rdds))]</p><p>data.rdd.mapPartitions(_map_to_pandas).collect()<br>1<br>2<br>3<br>4<br>5<br>返回的是list。</p><p>udf 函数应用</p><p>from pyspark.sql.functions import udf<br>from pyspark.sql.types import StringType<br>import datetime</p><h1 id="定义一个-udf-函数"><a href="#定义一个-udf-函数" class="headerlink" title="定义一个 udf 函数"></a>定义一个 udf 函数</h1><p>def today(day):<br>    if day==None:<br>        return datetime.datetime.fromtimestamp(int(time.time())).strftime(‘%Y-%m-%d’)<br>    else:<br>        return day</p><h1 id="返回类型为字符串类型"><a href="#返回类型为字符串类型" class="headerlink" title="返回类型为字符串类型"></a>返回类型为字符串类型</h1><p>udfday = udf(today, StringType())</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>df.withColumn(‘day’, udfday(df.day))</p><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>有点类似apply,定义一个 udf 方法, 用来返回今天的日期(yyyy-MM-dd):</p><p>———— 5、删除 ————<br>df.drop(‘age’).collect()<br>df.drop(df.age).collect()<br>1<br>2<br>dropna函数：</p><p>df = df.na.drop()  # 扔掉任何列包含na的行<br>df = df.dropna(subset=[‘col_name1’, ‘col_name2’])  # 扔掉col1或col2中任一一列包含na的行</p><p>1<br>2<br>3<br>ex:</p><p>train.dropna().count()<br>Output:<br>166821<br>1<br>2<br>3<br>填充NA包括fillna</p><p>train.fillna(-1).show(2)<br>Output:<br>+———-+—————+———+——+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|<br>+———-+—————+———+——+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                -1|                -1|    8370|<br>|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|<br>+———-+—————+———+——+—————+——————-+—————————————+———————+—————————+—————————+—————————+————+<br>only showing top 2 rows<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>———— 6、去重 ————<br>6.1 distinct：返回一个不包含重复记录的DataFrame<br>返回当前DataFrame中不重复的Row记录。该方法和接下来的dropDuplicates()方法不传入指定字段时的结果相同。<br>　　示例：</p><p>jdbcDF.distinct()<br>1<br>6.2 dropDuplicates：根据指定字段去重<br>根据指定字段去重。类似于select distinct a, b操作<br>示例：</p><p>train.select(‘Age’,’Gender’).dropDuplicates().show()<br>Output:<br>+——-+———+<br>|  Age|Gender|<br>+——-+———+<br>|51-55|     F|<br>|51-55|     M|<br>|26-35|     F|<br>|26-35|     M|<br>|36-45|     F|<br>|36-45|     M|<br>|46-50|     F|<br>|46-50|     M|<br>|  55+|     F|<br>|  55+|     M|<br>|18-25|     F|<br>| 0-17|     F|<br>|18-25|     M|<br>| 0-17|     M|<br>+——-+———+<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>———— 7、 格式转换 ————<br>pandas-spark.dataframe互转<br>Pandas和Spark的DataFrame两者互相转换：</p><p>pandas_df = spark_df.toPandas()<br>spark_df = sqlContext.createDataFrame(pandas_df)<br>1<br>2<br>转化为pandas，但是该数据要读入内存，如果数据量大的话，很难跑得动</p><p>两者的异同：</p><p>Pyspark DataFrame是在分布式节点上运行一些数据操作，而pandas是不可能的；<br>Pyspark DataFrame的数据反映比较缓慢，没有Pandas那么及时反映；<br>Pyspark DataFrame的数据框是不可变的，不能任意添加列，只能通过合并进行；<br>pandas比Pyspark DataFrame有更多方便的操作以及很强大<br>转化为RDD<br>与Spark RDD的相互转换：</p><p>rdd_df = df.rdd<br>df = rdd_df.toDF()<br>1<br>2<br>———— 8、SQL操作 ————<br>DataFrame注册成SQL的表：</p><p>df.createOrReplaceTempView(“TBL1”)<br>1<br>进行SQL查询（返回DataFrame）：</p><p>conf = SparkConf()<br>ss = SparkSession.builder.appName(“APP_NAME”).config(conf=conf).getOrCreate()</p><p>df = ss.sql(“SELECT name, age FROM TBL1 WHERE age &gt;= 13 AND age &lt;= 19″)<br>1<br>2<br>3<br>4<br>———— 9、读写csv ————<br>在Python中，我们也可以使用SQLContext类中 load/save函数来读取和保存CSV文件：</p><p>from pyspark.sql import SQLContext<br>sqlContext = SQLContext(sc)<br>df = sqlContext.load(source=”com.databricks.spark.csv”, header=”true”, path = “cars.csv”)<br>df.select(“year”, “model”).save(“newcars.csv”, “com.databricks.spark.csv”,header=”true”)<br>1<br>2<br>3<br>4<br>其中，header代表是否显示表头。<br>其中主函数：</p><p>save(path=None, format=None, mode=None, partitionBy=None, **options)[source]<br>1<br>Parameters:</p><p>path – the path in a Hadoop supported file system</p><p>format – the format used to save</p><p>mode –</p><p>specifies the behavior of the save operation when data already<br>exists.</p><p>append: Append contents of this DataFrame to existing data.</p><p>overwrite: Overwrite existing data.</p><p>ignore: Silently ignore this operation if data already exists.</p><p>error (default case): Throw an exception if data already exists.</p><p>partitionBy – names of partitioning columns</p><p>options – all other string options</p><p>延伸一：去除两个表重复的内容<br>场景是要，依据B表与A表共有的内容，需要去除这部分共有的。<br>使用的逻辑是merge两张表，然后把匹配到的删除即可。</p><p>from pyspark.sql import functions<br>def LeftDeleteRight(test_left,test_right,left_col = ‘user_pin’,right_col = ‘user_pin’):<br>    print(‘right data process …’)<br>    columns_right = test_right.columns<br>    test_right = test_right.withColumn(‘user_pin_right’, test_right[right_col])<br>    test_right = test_right.withColumn(‘notDelete’,  functions.lit(0))</p><pre><code># 删除其余的for col in columns_right:    test_right = test_right.drop(col)# 合并print(&#39;rbind left and right data ...&#39;)test_left = test_left.join(test_right, test_left[left_col] == test_right[&#39;user_pin_right&#39;], &quot;left&quot;)test_left = test_left.fillna(1)test_left = test_left.where(&#39;notDelete =1&#39;)# 去掉多余的字段for col in [&#39;user_pin_right&#39;,&#39;notDelete&#39;]:    test_left = test_left.drop(col)return test_left</code></pre><p>%time  test_left = LeftDeleteRight(test_b,test_a,left_col = ‘user_pin’,right_col = ‘user_pin’)<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>延伸二：报错<br>Job aborted due to stage failure: Task 3 in stage 0.0 failed 4 times, most recent failure: Lost task 3.3 in</p><p>1<br>2<br>解决方案</p><p>这里遇到的问题主要是因为数据源数据量过大，而机器的内存无法满足需求，导致长时间执行超时断开的情况，数据无法有效进行交互计算，因此有必要增加内存</p><p>参考：Spark常见问题汇总：<a href="https://my.oschina.net/tearsky/blog/629201" target="_blank" rel="noopener">https://my.oschina.net/tearsky/blog/629201</a><br>————————————————<br>版权声明：本文为CSDN博主「悟乙己」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/sinat_26917383/article/details/80500349" target="_blank" rel="noopener">https://blog.csdn.net/sinat_26917383/article/details/80500349</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PySpark常用操作总结——预处理</title>
      <link href="/2020/03/22/pyspark-chang-yong-cao-zuo-zong-jie-yu-chu-li/"/>
      <url>/2020/03/22/pyspark-chang-yong-cao-zuo-zong-jie-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> DoubleType, IntegerType, StringType, NullType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换原始列</span></span><br><span class="line">df = df.withColumn(col+<span class="string">'_tmp'</span>, df[col].cast(DoubleType())).drop(col).withColumnRenamed(col+<span class="string">'_tmp'</span>, col)</span><br><span class="line"><span class="comment"># 类型有：DoubleType(), IntegerType(), StringType()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留原始列</span></span><br><span class="line">df = df.withColumn(col+<span class="string">'_new'</span>, df[col].cast(DoubleType()))</span><br></pre></td></tr></table></figure><h2 id="缺失值填充"><a href="#缺失值填充" class="headerlink" title="缺失值填充"></a>缺失值填充</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.fillna(&#123;key: DoubleFillValue <span class="keyword">for</span> key <span class="keyword">in</span> DoubleFeatureList&#125;) \</span><br><span class="line">       .fillna(&#123;key: IntFillValue <span class="keyword">for</span> key <span class="keyword">in</span> intFeatureList&#125;) \</span><br><span class="line">       .fillna(&#123;key: StringFillValue <span class="keyword">for</span> key <span class="keyword">in</span> StringFeatureList&#125;)</span><br><span class="line"><span class="comment"># fillna()函数可以使用常数或字典类型</span></span><br><span class="line"><span class="comment"># 比如fillna(0)代表全部用0填充</span></span><br><span class="line"><span class="comment"># 比如fillna(&#123;'age':20, 'sex':-1&#125;) 表示'age'字段空值采用20填充，'sex'字段空值采用-1填充</span></span><br></pre></td></tr></table></figure><p>str型字段的空值填充</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stringNaValue = <span class="string">'null'</span> <span class="comment"># 缺失值非空时的取值（缺失值有空值''和非空值）</span></span><br><span class="line">stringFillValue = <span class="number">-1</span> <span class="comment"># 填充值</span></span><br><span class="line">df = df.replace(<span class="string">''</span>, stringFillValue, subset=StringFeatureList).na.fill(stringFillValue, subset=StringFeatureList)</span><br></pre></td></tr></table></figure><h2 id="计算字段饱和度、值的个数"><a href="#计算字段饱和度、值的个数" class="headerlink" title="计算字段饱和度、值的个数"></a>计算字段饱和度、值的个数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n_sample = df.count() <span class="comment"># 样本数量</span></span><br><span class="line">featureQualityDict = &#123;feat:<span class="literal">None</span> <span class="keyword">for</span> feat <span class="keyword">in</span> featureList&#125; <span class="comment"># 初始化</span></span><br><span class="line"></span><br><span class="line">notNullCountSql = [<span class="string">"sum(case when &#123;f&#125; is not null then 1 else 0 end) as not_null_count_&#123;f&#125;"</span>.format(f=feat) <span class="keyword">for</span> feat <span class="keyword">in</span> featureList]</span><br><span class="line">distinctCountSql = [<span class="string">"count(distinct &#123;f&#125;) as distinct_count_&#123;f&#125;"</span>.format(f=feat) <span class="keyword">for</span> feat <span class="keyword">in</span> featureList]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用selectExpr接口进行并行计算</span></span><br><span class="line">countResultDF = df.selectExpr(*(notNullCountSql+distinctCountSql))</span><br><span class="line">countResult = countResultDF.collect()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> featureList:</span><br><span class="line">    notNullCount = countResult[<span class="string">"not_null_count_&#123;f&#125;"</span>.format(f=feat)]</span><br><span class="line">    distinctCount = countResult[<span class="string">"distinct_count_&#123;f&#125;"</span>.format(f=feat)]</span><br><span class="line">    notNullRate = round(<span class="number">1.0</span> * notNullCount / n_sample, <span class="number">3</span>)</span><br><span class="line">    featureQualityDict[feat] = &#123;<span class="string">"notNullRate"</span>: notNullRate, <span class="string">"distinctCount"</span>: distinctCount&#125;</span><br></pre></td></tr></table></figure><h2 id="计算统计指标"><a href="#计算统计指标" class="headerlink" title="计算统计指标"></a>计算统计指标</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">statisticDict = &#123;&#125;</span><br><span class="line">dataDescribeDF = df.describe(numFeatureList) <span class="comment"># 对数值型变量计算统计指标</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> numFeatureList:</span><br><span class="line">    statisticDict[feat] = &#123;&#125; <span class="comment"># 嵌套dict</span></span><br><span class="line">    median = df.approxQuantile(feat, (<span class="number">0.5</span>,), <span class="number">0</span>)[<span class="number">0</span>] <span class="comment"># 计算中位数(0.5分位数)</span></span><br><span class="line">    statisticDict[<span class="string">'feat'</span>][<span class="string">'median'</span>] = round(median, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> dataDescribeDF.collect():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(numFeatureList)):</span><br><span class="line">        featName = numFeatureList[i]</span><br><span class="line">        statName = row[<span class="number">0</span>].encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        statValue = round(eval(row[i+<span class="number">1</span>]), <span class="number">3</span>) </span><br><span class="line">        <span class="comment"># eval()函数将去掉字符串的两个引号,将其解释为一个变量。单/双引号eval()函数都将其解释为int类型</span></span><br><span class="line">        statisticDict[featName][statName] = statValue</span><br></pre></td></tr></table></figure><h2 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 固定数量采样</span></span><br><span class="line">sampleAmount = <span class="number">100</span> <span class="comment"># 抽取样本数量(int)</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> rand</span><br><span class="line">sample = df.withColumn(<span class="string">"rand"</span>,rand).orderBy(<span class="string">"rand"</span>).limit(sampleAmount).drop(<span class="string">"rand"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按比例采样</span></span><br><span class="line">fraction = <span class="number">0.1</span> <span class="comment"># 采样比例(double in (0,1))</span></span><br><span class="line">withReplacement = <span class="literal">False</span> <span class="comment"># 是否可放回，默认不可放回</span></span><br><span class="line">sample = df.sample(fraction = fraction, withReplacement = withReplacement, seed = <span class="number">123</span>)</span><br></pre></td></tr></table></figure><blockquote><p><strong>pyspark.sql.functions.rand</strong>(<em>seed=None</em>)<a href="http://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/functions.html#rand" target="_blank" rel="noopener">[source]</a></p><p>Generates a random column with independent and identically distributed (i.i.d.) samples from <strong>U[0.0, 1.0]</strong>.</p><p><strong>pyspark.sql.functions.randn</strong>(<em>seed=None</em>)<a href="http://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/functions.html#randn" target="_blank" rel="noopener">[source]</a></p><p>Generates a column with independent and identically distributed (i.i.d.) samples from <strong>the standard normal distribution.</strong></p></blockquote><h2 id="划分样本"><a href="#划分样本" class="headerlink" title="划分样本"></a>划分样本</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">splitRatio = <span class="number">0.8</span> <span class="comment"># 训练集占80%</span></span><br><span class="line">trainDF, testDF = df.randomSplit([splitRatio, <span class="number">1</span>-splitRatio], seed = <span class="number">123</span>)</span><br></pre></td></tr></table></figure><h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler, MinMaxScaler</span><br><span class="line"></span><br><span class="line">features = df.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先使用VectorAssembler将需要归一化的变量合并为一列，输出新的变量"inputFeatures"</span></span><br><span class="line">inputAssembler = VectorAssembler(inputCols=normFeatureList, outputCol=<span class="string">"inputFeatures"</span>)</span><br><span class="line"><span class="comment"># normFeatureList: 需要归一化的变量</span></span><br><span class="line">df = inputAssembler.transform(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其次使用MinMaxScaler进行归一化</span></span><br><span class="line">scaler = MinMaxScaler(inputCol=<span class="string">"inputFeatures"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line">scalerModel = scaler.fit(df)</span><br><span class="line">scaledData = scalerModel.transform(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后将归一化后的合并变量列"scaledFeatures"分开</span></span><br><span class="line">scaledRDD = scaledData.select(features+[<span class="string">"scaledFeatures"</span>]).rdd.map(<span class="keyword">lambda</span> row: tuple([i <span class="keyword">for</span> i <span class="keyword">in</span> row[:<span class="number">-1</span>]]+[float(i) <span class="keyword">for</span> i <span class="keyword">in</span> row[<span class="number">-1</span>]]))</span><br><span class="line">newDF = scaledRDD.toDF(features + [(<span class="string">"normalized_"</span>+feat) <span class="keyword">for</span> feat <span class="keyword">in</span> normFeatureList])</span><br><span class="line"></span><br><span class="line"><span class="comment">#可选：替换原字段</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> normFeatureList:</span><br><span class="line">    newDF = newDF.drop(feat).withColumnRenamed(<span class="string">"normalized_"</span>+feat, feat)</span><br></pre></td></tr></table></figure><h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler, StandardScaler</span><br><span class="line"></span><br><span class="line">features = df.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先使用VectorAssembler将需要标准化的变量合并为一列，输出新的变量"inputFeatures"</span></span><br><span class="line">inputAssembler = VectorAssembler(inputCols=standardFeatureList, outputCol=<span class="string">"inputFeatures"</span>)</span><br><span class="line"><span class="comment"># standardFeatureList: 需要标准化的变量</span></span><br><span class="line">df = inputAssembler.transform(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其次使用StandardScaler进行标准化</span></span><br><span class="line">scaler = StandardScaler(inputCol=<span class="string">"inputFeatures"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line">scalerModel = scaler.fit(df)</span><br><span class="line">scaledData = scalerModel.transform(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后将归一化后的合并变量列"scaledFeatures"分开</span></span><br><span class="line">scaledRDD = scaledData.select(features+[<span class="string">"scaledFeatures"</span>]).rdd.map(<span class="keyword">lambda</span> row: tuple([i <span class="keyword">for</span> i <span class="keyword">in</span> row[:<span class="number">-1</span>]]+[float(i) <span class="keyword">for</span> i <span class="keyword">in</span> row[<span class="number">-1</span>]]))</span><br><span class="line">newDF = scaledRDD.toDF(features + [(<span class="string">"stdized_"</span>+feat) <span class="keyword">for</span> feat <span class="keyword">in</span> standardFeatureList])</span><br><span class="line"></span><br><span class="line"><span class="comment">#可选：替换原字段</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> standardFeatureList:</span><br><span class="line">    newDF = newDF.drop(feat).withColumnRenamed(<span class="string">"stdized_"</span>+feat, feat)</span><br></pre></td></tr></table></figure><h2 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.function <span class="keyword">import</span> log10, log2, log, sqrt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选方法如下（可增加）</span></span><br><span class="line">scaleFuncDict = &#123;</span><br><span class="line">    <span class="string">"log2"</span>: (<span class="keyword">lambda</span> x: log2(x)),</span><br><span class="line">    <span class="string">"log10"</span>: (<span class="keyword">lambda</span> x: log10(x)),</span><br><span class="line">    <span class="string">"ln"</span>: (<span class="keyword">lambda</span> x: log(x)),</span><br><span class="line">    <span class="string">"abs"</span>: (<span class="keyword">lambda</span> x: abs(x)),</span><br><span class="line">    <span class="string">"sqrt"</span>: (<span class="keyword">lambda</span> x: sqrt(x)),</span><br><span class="line">    <span class="string">"square"</span>: (<span class="keyword">lambda</span> x: x**<span class="number">2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 所选的特征缩放方法</span></span><br><span class="line">scaleMethod = <span class="string">"log2"</span></span><br><span class="line"></span><br><span class="line">newDF = df</span><br><span class="line"><span class="comment"># scaleFeatureList: 需要特征缩放的变量</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> scaleFeatureList:</span><br><span class="line">    newDF = newDF.withColumn(<span class="string">"scaled_"</span>+feat, scaleFuncDict[scaleMethod](newDF[feat]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#可选：替换原字段</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> scaleFeatureList:</span><br><span class="line">    newDF = newDF.drop(feat).withColumnRenamed(<span class="string">"scaled_"</span>+feat, feat)</span><br></pre></td></tr></table></figure><h2 id="异常特征平滑"><a href="#异常特征平滑" class="headerlink" title="异常特征平滑"></a>异常特征平滑</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">newDF = df.copy()</span><br><span class="line">featureThreshMap = &#123;feat:&#123;&#125; <span class="keyword">for</span> feat <span class="keyword">in</span> softenFeatureList&#125;</span><br><span class="line"><span class="comment"># softenFeatureList: 需要进行异常特征平滑的变量</span></span><br><span class="line">softenMethod = <span class="string">"zScore"</span> <span class="comment"># or "minMaxThresh" / "minMaxPercent" </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算统计指标</span></span><br><span class="line">statisticDict = &#123;&#125;</span><br><span class="line">dataDescribeDF = df.describe(softenFeatureList) <span class="comment"># 对数值型变量计算统计指标</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> dataDescribeDF.collect():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(softenFeatureList)):</span><br><span class="line">        featName = softenFeatureList[i]</span><br><span class="line">        statName = row[<span class="number">0</span>].encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        statValue = round(eval(row[i+<span class="number">1</span>]), <span class="number">3</span>) </span><br><span class="line">        <span class="comment"># eval()函数将去掉字符串的两个引号,将其解释为一个变量。单/双引号eval()函数都将其解释为int类型</span></span><br><span class="line">        statisticDict[featName][statName] = statValue</span><br><span class="line">       </span><br><span class="line"><span class="comment"># 1. softenMethod = "zScore"</span></span><br><span class="line">zValue = <span class="number">1.96</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> featureThreshMap:</span><br><span class="line">    mean, stddev = statisticDict[feat][<span class="string">"mean"</span>], statisticDict[feat][<span class="string">"stddev"</span>]</span><br><span class="line">    featureThreshMap[feat][<span class="string">"minThresh"</span>] = mean - zValue * stddev</span><br><span class="line">    featureThreshMap[feat][<span class="string">"maxThresh"</span>] = mean + zValue * stddev</span><br><span class="line">    <span class="comment"># 进行类型转换（转为Double类型）</span></span><br><span class="line">    newDF = newDF.withColumn(feat+<span class="string">"_tmp"</span>, df[feat].cast(DoubleType())).drop(feat).withColumnRenamed(feat+<span class="string">"_tmp"</span>, feat)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 2. softenMethod = "minMaxPercent" </span></span><br><span class="line">minPercent = <span class="number">0.25</span></span><br><span class="line">maxPercent = <span class="number">0.75</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> featureThreshMap:</span><br><span class="line">    featureThreshMap[feat][<span class="string">"minThresh"</span>], featureThreshMap[feat][<span class="string">"maxThresh"</span>] = df.approxQuantile(feat, [minPercent, maxPercent], <span class="number">0.01</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 3. softenMethod = "minMaxThresh" </span></span><br><span class="line">minThresh = <span class="number">0</span></span><br><span class="line">maxThresh = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> featureThreshMap:</span><br><span class="line">    featureThreshMap[feat][<span class="string">"minThresh"</span>], featureThreshMap[feat][<span class="string">"maxThresh"</span>] = minThresh, maxThresh</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 创建平滑UDF</span></span><br><span class="line">featureTypeMap = &#123;k:v <span class="keyword">for</span> k,v <span class="keyword">in</span> df.dtypes&#125; <span class="comment"># 需要对bigint/double类型进行转换，转换为int/float</span></span><br><span class="line">minV, maxV = featureThreshMap[feat][<span class="string">"minThresh"</span>], featureThreshMap[feat][<span class="string">"maxThresh"</span>]</span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> featureThreshMap:</span><br><span class="line">    <span class="keyword">if</span> featureTypeMap[feat] == <span class="string">"bigint"</span>:</span><br><span class="line">        featureType = IntegerType()</span><br><span class="line">        minV, maxV = int(minV), int(maxV)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        featureType = FloatType()</span><br><span class="line">        minV, maxV = float(minV), float(maxV)</span><br><span class="line">    compare = <span class="keyword">lambda</span> x: minV <span class="keyword">if</span> x &lt; minV <span class="keyword">else</span> (maxV <span class="keyword">if</span> x&gt;maxV <span class="keyword">else</span> x)</span><br><span class="line">    compareUDF = udf(compare, featureType)</span><br><span class="line">    newDF = newDF.withColumn(<span class="string">"soft_"</span>+feat, compareUDF(newDF[feat]))</span><br><span class="line">    <span class="comment"># 可选：替换原始变量</span></span><br><span class="line">    newDF = newDF.drop(feat).withColumnRenamed(<span class="string">"soft_"</span>+feat, feat)</span><br></pre></td></tr></table></figure><h2 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer, OneHotEncoder</span><br><span class="line"></span><br><span class="line">newDF = df.select(oneHotFeatList)</span><br><span class="line">colList = newDF.columns</span><br><span class="line">colAmount = len(colList)</span><br><span class="line"></span><br><span class="line"><span class="comment"># oneHotFeatList: 要进行one-hot编码的变量</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> oneHotFeatList:</span><br><span class="line">    <span class="comment"># 先对变量进行数值化编码</span></span><br><span class="line">    stringIndexer = StringIndexer(inputCol=feat, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">    model = stringIndexer.fit(newDF)</span><br><span class="line">    indexed = model.transform(newDF)</span><br><span class="line">    <span class="comment"># 一个变量名生成多个变量名</span></span><br><span class="line">    categoryList = [feat+<span class="string">"_"</span>+str(cat) <span class="keyword">for</span> cat,index <span class="keyword">in</span> indexed.select(feat,<span class="string">"categoryIndex"</span>).distinct().orderBy(<span class="string">"categoryIndex"</span>).collect()]</span><br><span class="line">    <span class="comment"># 然后进行one-hot编码</span></span><br><span class="line">    encoder = OneHotEncoder(inputCol=<span class="string">"categoryIndex"</span>,outputCol=<span class="string">"categoryVec"</span>,dropLast=<span class="literal">False</span>)</span><br><span class="line">    encoded = encoder.transform(indexed)</span><br><span class="line">    newDF = encoded.select(colList+[<span class="string">"categoryVec"</span>]).rdd\</span><br><span class="line">           .map(<span class="keyword">lambda</span> row: tuple(list(row[<span class="number">0</span>:colAmount])+[float(x) <span class="keyword">for</span> x <span class="keyword">in</span> row[<span class="number">-1</span>].toArray()]))\</span><br><span class="line">           .toDF(colList+categoryList)</span><br><span class="line">    colList = colList+categoryList</span><br><span class="line">    colAmount = len(colList)</span><br></pre></td></tr></table></figure><blockquote><p>OneHotEncoder中的dropLast含义：</p><p><a href="https://stackoverflow.com/questions/39500213/why-does-sparks-onehotencoder-drop-the-last-category-by-default" target="_blank" rel="noopener">https://stackoverflow.com/questions/39500213/why-does-sparks-onehotencoder-drop-the-last-category-by-default</a></p><p><a href="https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/ml/feature/OneHotEncoder.html" target="_blank" rel="noopener">https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/ml/feature/OneHotEncoder.html</a></p></blockquote><h2 id="分箱"><a href="#分箱" class="headerlink" title="分箱"></a>分箱</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Bucketizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitRangeIntoFloatList</span><span class="params">(start, end, numOfSplits)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回下界start到上界end之间的等分点。</span></span><br><span class="line"><span class="string">    例：(start=1, end=5, numOfSplits=2) -&gt; [1.0,3.0,5.0]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    stepsize = (float(end)-float(start))/numOfSplits <span class="comment"># 间隔长度</span></span><br><span class="line">    resultList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numOfSplits):</span><br><span class="line">        resultList.append(round(start+stepsize*i), <span class="number">3</span>)</span><br><span class="line">    resultList.append(float(end))</span><br><span class="line">    <span class="keyword">return</span> resultList</span><br><span class="line"></span><br><span class="line">newDF = df.copy()</span><br><span class="line">numOfSplits = <span class="number">5</span> <span class="comment"># 分箱的个数</span></span><br><span class="line"><span class="comment"># bucketizedFeatureList: list, 要进行分箱的字段列表</span></span><br><span class="line">featureSplitDict = &#123;feat:[] <span class="keyword">for</span> feat <span class="keyword">in</span> bucketizedFeatureList&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> bucketizedFeatureList:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"*** Handling %s ***"</span> % feat) <span class="comment"># 每次循环可能耗时较长</span></span><br><span class="line">    <span class="comment"># 等频分箱</span></span><br><span class="line">    featSplits = newDF.approxQuantile(<span class="string">"typed_"</span>+feat, splitRangeIntoFloatList(<span class="number">0</span>,<span class="number">1</span>,numOfSplits),<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 等距分箱</span></span><br><span class="line">    <span class="comment"># featSplits = splitRangeIntoFloatList(newDF[feat].min(),newDF[feat].max(),numOfSplits)</span></span><br><span class="line">    featSplits[<span class="number">0</span>] = float(<span class="string">"-inf"</span>)</span><br><span class="line">    featSplits[<span class="number">-1</span>] = float(<span class="string">"inf"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(featSplits))[::<span class="number">-1</span>][<span class="number">1</span>:]:</span><br><span class="line">        <span class="keyword">while</span> featSplits[i] &gt;= featSplits[i+<span class="number">1</span>]:</span><br><span class="line">            featSplits[i] -= <span class="number">0.00001</span> <span class="comment"># 避免数据倾斜</span></span><br><span class="line">    featureSplitDict[feat] = featSplits</span><br><span class="line">    bucketizer = Bucketizer(splits=featSplits, inputCol=<span class="string">"typed_"</span>+feat, outputCol=<span class="string">"discreate_"</span>+feat, handleInvalid=<span class="string">"keep"</span>)</span><br><span class="line">    newDF = bucketizer.transform(newDF)</span><br><span class="line">    newDF = newDF.drop(<span class="string">"typed_"</span>+feat)</span><br><span class="line">    <span class="comment"># 删除原始变量</span></span><br><span class="line">    newDF = newDF.drop(feat).withColumnRenamed(<span class="string">"discreate_"</span>+feat, feat)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商数据分析与数据化运营Note——Part4：数据分析实战</title>
      <link href="/2020/03/20/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part4/"/>
      <url>/2020/03/20/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part4/</url>
      
        <content type="html"><![CDATA[<h1 id="Ch4-向双11进军，数据分析实战开始"><a href="#Ch4-向双11进军，数据分析实战开始" class="headerlink" title="Ch4 向双11进军，数据分析实战开始"></a>Ch4 向双11进军，数据分析实战开始</h1><h2 id="L11-店铺的诊断分析方法"><a href="#L11-店铺的诊断分析方法" class="headerlink" title="L11　店铺的诊断分析方法"></a>L11　店铺的诊断分析方法</h2><p>三基分析法——<strong>“用户数”、“平均销售金额”、“复购率”</strong></p><ol><li><p>用户数</p><p>用户数是指成交后的买家数。通过买家数的多少，以及买家数的年均增长情况，来判断店铺当前所处的运营状态，并且是否保持增长的态势。</p></li><li><p>平均消费金额</p><p>指<strong>人均消费金额</strong>。通过人均消费金额，可以评估品牌的消费人群定位，以及盈利期望是否合理。</p></li><li><p>复购率</p><p>以服装为例，复购率高的品牌，其用户忠诚度非常高。品牌调性、产品，以及服务质量都得到用户的认同；对“付费流量”的依赖相对较低，因此可以节省更多的市场推广费用。这部分资金便可以使用到其他方面去，比如提升售后服务质量、改良产品质量等，这样便可以形成一个有益的经营循环。</p></li></ol><p>某店铺最近三年的“三基分析”数据：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/816cd7304d645951.png" alt></p><ol><li>2014年的用户数中没有三年老客，间接证明这是一家成立于2013年的店。</li><li>2014年、2015年两年期间，店铺花费了相当大的精力用于“新客引流”，并且取得了30%的用户数增长。 </li><li>从2016年开始，店铺的新老客占比接近5:5，店铺已经不再完全依赖于“新客引流”，间接证明店铺的流量结构已经趋于合理；同时复购率的增加也直接证明店铺近两年在“老客维护”方面取得不小的进步。 </li></ol><h2 id="L12-店铺的流量分析"><a href="#L12-店铺的流量分析" class="headerlink" title="L12 店铺的流量分析"></a>L12 店铺的流量分析</h2><h3 id="流量来源分析：流量从哪里来？"><a href="#流量来源分析：流量从哪里来？" class="headerlink" title="流量来源分析：流量从哪里来？"></a>流量来源分析：流量从哪里来？</h3><p>店铺流量来源及转化质量：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/68ea45f7f46be4a6.png" alt></p><p>在流量分析中还需要关注以下几个问题：</p><ol><li>店铺的流量是从什么渠道来的？</li><li>哪些渠道是主要渠道？</li><li>哪些渠道是付费/免费渠道？</li><li>哪些渠道的流量转化率最高？</li><li>当前流量的渠道分布占比是否正常？</li></ol><p>分析方法：</p><ul><li><p>参考数据</p><p><img src="https://i.bmp.ovh/imgs/2020/03/6037428acf7a6189.png" alt></p></li><li><p>用Excel的堆积图来跟踪每日流量的变化</p><p><img src="https://i.bmp.ovh/imgs/2020/03/af8a50c29d301cab.png" alt></p></li><li><p>店铺大型促销活动时的流量分析</p><p><img src="https://i.bmp.ovh/imgs/2020/03/904b58d1a4b17ad3.png" alt></p><p>通过上表，我们可以发现：</p><ol><li>无线端的流量占到全店的74%，但转化率却远远低于PC端，因此这家店铺的问题是<strong>应该想办法优化提升无线端的成交转化率</strong>。</li><li>PC端中，来自男装会场和聚划算的流量较高，占全店铺流量的18%，<strong>因此这两个渠道来源的流量应被视为重点流量</strong>，认真检查好承接页的商品及页面效果。</li></ol></li></ul><h3 id="流量路径分析：流量到哪儿去？"><a href="#流量路径分析：流量到哪儿去？" class="headerlink" title="流量路径分析：流量到哪儿去？"></a>流量路径分析：流量到哪儿去？</h3><p>一般情况下，在大促活动中的主推款会承接30%～50%的店铺流量。所以，从活动预热期开始，我们就必须挑选好本次活动的主推款，以及每天实时监测主推款的预热情况是否理想。</p><ul><li><p>要挑选哪些款作为主推款呢？</p><p>生意参谋中的流量来源去向查询：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/35f72966928fb37d.png" alt></p><p>商品温度计功能：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/19e55cf69d807cf8.png" alt></p></li><li><p>找到这些主推款之后，又需要如何监测呢？</p><p>从活动预热期开始，我们需要建立所有主推款的<strong>预热效果追踪表</strong>：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/7bd8a4a5d1621256.png" alt></p><p>表中加购倍率（=加购数/备货数）如果高于100%，则可视为预热表现良好的商品；若低于100%，则视为预热表现非常差；而若是高于500%，则可判断为非常热销的商品。据此分类，可为商品的预热策略调整提供指导意见。</p></li></ul><h2 id="L13-店铺的商品分析"><a href="#L13-店铺的商品分析" class="headerlink" title="L13 店铺的商品分析"></a>L13 店铺的商品分析</h2><p>在数据分析时，商品一般有两种状态：已销售商品和库存商品。因此，有关商品的分析也可分为两大方向：销售分析和库存分析。</p><h3 id="商品的销售结构分析"><a href="#商品的销售结构分析" class="headerlink" title="商品的销售结构分析"></a>商品的销售结构分析</h3><p>指<strong>对店铺某段时期内的所有销售商品进行分类汇总，然后再进行数据统计与分析</strong>。通过商品的销售结构分析，可以为店铺运营者<strong>梳理清楚店铺当前的主销商品，以及其销售表现</strong>，从而为运营者及时调整和优化销售策略提供可信的数据支撑。<br>在分析商品的销售结构时，可以按照商品年份、季度、波段、大类、小类、价格带、折扣带等指标来进行分类汇总。具体使用哪些指标和维度，需要根据实际分析需要来选择。</p><ul><li><p><strong>案例一：销售品类综合分析</strong> </p><p>下表是艾尚公司的三家电商店铺在第三季度的商品销售情况：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/62a67f9749039759.png" alt></p><p>我们可以获得以下信息：</p><ol><li>仅以“衬衫”与“T恤”而言，Q3季度衬衫的销售额是T恤的2～3倍；</li><li>T恤的件单价全线都比去年高50～100元。其中京东渠道的较高，达到102元；</li><li>衬衫的件单价在唯品会渠道出现了全季度同比下跌，而京东渠道则全季度同比上升。应与两个渠道不同的销售策略有密切关系；</li><li>如果将上表扩大到所有类目的数据，则可以对所有品类按销售贡献进行排名，然后据此判断各个品类的销售表现是否在应有的品类生命周期表现之内。</li></ol><p>根据这些信息，<strong>商品运营人员可以进行“运营复盘”，以销售结果来反推前期的运营策略是否正确，并加以调整与优化</strong>。譬如根据上表中“衬衫的件单价在唯品会与京东两个渠道中截然不同的表现”，商品运营人员便需要反思，在前期运营中唯品会渠道的商品折损是否没有控制好？抑或是有意将两个渠道衬衫上的商品款式“完全错开”的策略所导致的？ </p></li><li><p><strong>案例二：销售与退货分析</strong></p><p>某时间段内，店铺销售与退货分析的数据表：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/6633b8f585f87e4f.png" alt></p><ol><li>这份表可以找出各大品类中的主力销售品类。比如表中‘800元及以上的外套’销售额高达557万，销售占比达31%，这个品类无疑是当前的销售主力。但是这个价格带的退货率高达43%，因此需要特别注意加强退货挽回的措施。而平均折扣已经低至0.47，说明这批货可能都是往年的旧货，而且毛利率也不高。</li><li>这份表还可以<strong>分别用‘平均折扣’‘退货率’‘销售额’来做一个倒序排列，根据这种方式，可以找出店铺的‘高利润款’‘高退货款’‘畅销款’。然后针对不同的款来制定不同的销售策略。</strong><ol><li>400元以下的恤衫和400元以下的半截裙，平均销售折扣分别是0.78和0.84，毛利率足够高了。可是销量却没有起来，两者的销售占比还不到2%。【销售折扣（利润）】</li><li>从“高退货款”的角度来看，实销价高于800元的毛衣和恤衫，其退货率高达47%和54%；而同样是售价高于800元的半截裙退货率却只有32%。有可能这家店铺的毛衣与恤衫与其他竞品相比优势并不明显，而半截裙却是这家店铺的优势品类。【退货率】</li><li>从畅销度的角度来看，销售额靠前的分别是800元以上的外套、400～800元区间的毛衣、400～600元区间的半截裙；而且，除外套外，毛衣与半截裙的退货率与销售折扣都在合理范围之内。因此可以确定这三者的主推地位。【销量】</li></ol></li></ol></li></ul><h3 id="商品的库存结构分析"><a href="#商品的库存结构分析" class="headerlink" title="商品的库存结构分析"></a>商品的库存结构分析</h3><p>店铺聚划算活动报名盘货计划表：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/be1847c564987a9a.png" alt></p><p>此盘货计划的目的是统计库存中符合聚划算要求的商品，并计算货值，预估是否满足本次聚划算活动的业绩要求。</p><ol><li>本次计划参与聚划算的商品为217款，吊牌金额为292万。</li><li>本次参与活动的商品主要以毛织、半截裙、衬衫为主，此三大品类的备货超过整体活动备货额的2/3。</li><li>与活动款库存相比，库存中尚有约1400万的货值没有参与本次促销活动，按以往经验，这部分商品在活动促销期间，约可为店铺贡献 20%～30%的业绩。</li><li>按以往经验预估，聚划算商品的平均折扣为0.65折，活动商品的备货约是活动期间业绩目标的3.5～4.5倍；以这两个数值预估，本次活动预计可完成42万～55万的业绩。 </li></ol><p>两个关键的经验值：“预估平均折扣”与“预估备货/销售额倍数”</p><p>新品上市跟踪表：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/89f86e361e867a42.png" alt></p><p>关键指标：SPU数、消化率、落差</p><ul><li><p>SPU数：可以看出店铺上新的能力。也就是说店铺每个波段能够上新的数量多少，在某种程度上<strong>反映了店铺开发新款的能力高低</strong>。同时，SPU数与库存金额结合，也可计算出<strong>单款的库存深度</strong>。</p></li><li><p>消化率：配合落差，可以直观地看到<strong>此波段商品的销售进度是否符合预定进度</strong>。</p></li></ul><p>从上表中，我们可以得出以下分析结论：</p><ol><li>截止统计周期内，店铺共上线约300款春季款，其中春2波商品消化率达30%，在预期的销售进度计划之内； </li><li>春3波的商品消化率达42%，但是高出预期消化率（28%）许多。说明在后续的销售过程中，春3波商品可能会出现货品不足的风险；</li><li>本报表显示出的最大风险在于：春5、6、7波商品计划消化率达 65%～34%，是春2、春3波商品的将近一倍及以上，以经验判断，这些款应该是“春节款”。但是这些款的实际消化率仅24%～9%，存在非常大的销售落差；同时，春5、6、7波商品库存金额达近1000万，而期间累计销售额仅约180万，结合消化率落差判断，此处存在较大的库存风险。</li></ol><h3 id="商品ABC分级"><a href="#商品ABC分级" class="headerlink" title="商品ABC分级"></a>商品ABC分级</h3><p>商品的ABC分级法需要将分析颗粒精细到每个款式，分析相对繁杂，所以一般只有在店铺进行大型促销活动时才会用到。且只有店铺在大型促销活动时，每个单款商品所承载的流量与成交数据才足够大， ABC分级才更有意义。</p><p>商品ABC分级的重点在于“ABC的分级逻辑”。可以采用如下分级逻辑：</p><ol><li><strong>A级商品：高库存且有高转化率（转化率&gt;2%）的商品</strong>。因为这类商品既畅销，又有较深的库存作为保障，因此可以作为活动中的主推商品。需要注意的是，在挑选A类商品时，还应注意此款商品的<strong>访客不能太低</strong>，否则，没有经过“充分”流量测试的商品，其高转化率可能是“伪高转化率”。 </li><li><strong>B级商品：转化率中等（2%&gt;转化率&gt;0.65%），且经过流量测试的商品</strong>。由于这类商品经过流量测试，被证明对访客有一定吸引力，但却不如A类商品转化明显，所以可以继续保持当前的销售定位。B级商品中有两类商品需要特别注意：一是<strong>库存告急的</strong>， 这类商品需要特别注意避免超卖；二是占<strong>用了主推款陈列位置的</strong>，在大促中，宝贵的陈列位置是有限的，这类优质陈列位置需要留给A类商品使用，因此需要将其阵列位置往后移 动。</li><li><strong>C级商品：转化率低（转化率&lt;0.65%）且经过流量测试的商品</strong>。C类商品应处于店铺阵列页面的底端，基本是属于被放弃的一类商品。但是，C类商品中有一类需要特别注意，就是有<strong>高库存</strong>的，可以尝试主动改变原定策略，譬如换主图、降价等。</li></ol><p>在电商环境中，一般大促活动周期都在3天以上，因此，在经过第一天的流量测试后，迅速将商品的ABC分级表格分析结果提供给运营团队，可以帮助他们发现问题并及时调整商品运营策略，为业绩带来极大的推动作用。</p><h3 id="主推款销售追踪表"><a href="#主推款销售追踪表" class="headerlink" title="主推款销售追踪表"></a>主推款销售追踪表</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/09293d17fe54d9b1.png" alt></p><p>实销价：用于判断此主推款的消费群体与定位，一般而言，<strong>单价高的商品不适合使用直通车等付费工具进行推广</strong>；</p><p>总UV、 直通车占比、搜索流量占比等：用来判断此主推款的推广效果，流量越多，说明当前推广策略与推广渠道的选择越正确，反之就要考虑更换推广渠道或策略了；</p><p>消化率：用于判断此款<strong>是否继续作为主推的一个重要标志</strong>。如果消化高接近计划消化率，可以考虑暂时停止付费渠道的推广，以便提升营业利润； 如果消化率距离计划消化率较远，则可考虑加强付费推广的力度，以免造成库存风险。</p><ul><li><p>Q：像表格中款2这样已经超过计划消化率很多的款式应该如何调整？</p><p>调整主推款策略的关键因素：</p><ol><li>此款是临时主推，还是本身就定位为主推款。临时主推是为了临时突击，拉动此款的消化率；主推款则是承担着为店铺走量及引流等综合任务的款式。</li><li>此款库存量还剩余多少？</li><li>此款剩余销售周期还有多久？</li><li>在付费推广时，此款商品ROI是否在合理值？</li></ol></li></ul><h3 id="商品的屏效分析"><a href="#商品的屏效分析" class="headerlink" title="商品的屏效分析"></a>商品的屏效分析</h3><p>又称“商品的九宫格”数据运营法</p><p><strong>屏效</strong>：从传统零售分析中的‘坪效’借鉴过来的，指电商店铺的页面（首页/类目/二级页等）在电脑（或手机）上打开后，<strong>每个电脑（或手机）屏幕所产生的销售贡献</strong>。（一个电脑屏幕所呈现出来的商品（一般是6至8个商品）给店铺整体业绩所带来的贡献率）</p><p><strong>有效陈列面积</strong>：在聚划算活动中，店铺首页、活动二级页是承接流量较多的两大页面。所以，我们可以把店铺首页与聚划算二级页称为有效陈列页面。同理，在同一个网页中可以向下无限拉升，而用户的浏览习惯是一般只会专注于页面的前面3～5个屏幕的内容。所以，我们又把这些区域称为有效陈列面积，或者叫‘<strong>黄金陈列面积</strong>’。</p><p>黄金陈列位置所能够陈列的商品有限，因此只有尽量利用好每一个坑位的陈列机会，展现恰当的商品，才能达到更大的销售业绩。而<strong>‘屏效’就是用来评估黄金陈列位置利用率的</strong>。屏效高，则证明黄金陈列位置的商品利用率高；屏效低，则需要及时替换黄金陈列位置的商品。</p><ul><li><p>屏效分析第一步：挑选适合陈列在‘黄金陈列位置’的商品</p><p><img src="https://i.bmp.ovh/imgs/2020/03/cef736d8850c8609.png" alt></p><p>利用ABC分级的方法，从<strong>‘库存数量’与‘加购数量’</strong>两个维度，将活动期间的主推商品分为9个层级。</p><p>屏效分析其实就是通过‘商品ABC’分级方法，找出预热表现优秀且库存深厚的商品，将他们通过商品搭配的手段，陈列在‘黄金坑位’。这样，就可以从数据层面使销售更大化。</p><p>且陈列在‘黄金坑位’上的商品并不是固定不变的，而是要保持轮动：</p><ul><li>首先，既然我们把商品分为9个层级，那么陈列页面也可以分别对应的9大层级。</li><li>其次，我们要把握住活动当天的流量访问规律。<strong>在大型促销日的活动当天，流量一般有三大访问高峰期，分别是0～2点、8～9点、22 ～23点。</strong>因此，商品的轮转就需要安排在<strong>这三个流量高峰之后的一个小时内</strong>。</li></ul></li></ul><h2 id="L14-店铺的用户分析"><a href="#L14-店铺的用户分析" class="headerlink" title="L14 店铺的用户分析"></a>L14 店铺的用户分析</h2><h3 id="活跃度分析"><a href="#活跃度分析" class="headerlink" title="活跃度分析"></a>活跃度分析</h3><p>以某电商店铺的大促活动为例，验证如何通过数据来为运营提供指导。</p><p>数据分析人员应从<strong>店铺用户分类、收益预估、短信营销用户清单</strong>三个方面为本次运营提供了全面的支持</p><ul><li><p><strong>店铺用户分类</strong></p><p>在大促开始前7天，我们需要统计出店铺<strong>最近12个月内的用户活跃度数据分析表</strong>：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/2e8b441345d9a81f.png" alt></p><p>通过此表可以对店铺的“活跃用户”“沉睡用户”“即将流失客户”进行分类统计，以便于我们对店铺用户结构建立整体的认知，并且为接下来制定“用户唤醒”与“用户挽回”方案提供数据性参考。</p></li></ul><blockquote><p>关于‘<strong>活跃度</strong>’，每家公司都有不同的分类标准。一般的做法是：</p><ul><li>最近30天内有过消费的客户称为‘活跃用户’</li><li>最近（连续）60天内没有消费记录的客户称为‘沉睡用户’</li><li>最近（连续）90天内没有消费记录的用 户称为‘即将流失客户’</li></ul></blockquote><p><strong>用户激活方案</strong>：针对不同类型的用户，刺激的力度与文案的企划也应该有所不同。其中针对<strong>沉睡客户主要以“唤 醒”为主</strong>，常见的举措是<strong>告知本次促销力度，以及提供适量额度的优惠券</strong>；针对<strong>即将流失客户</strong>，除了告知促销信息与力度外，还需要<strong>提供较高额度的优惠券，另外最好再配上走心的文案</strong>。</p><ul><li><p><strong>收益预估</strong></p><p>根据“待唤醒”与“待挽留”人数，还可以<strong>推算出本次优惠券的使用率以及折损金额</strong>。譬如在大促活动中向约5000名即将流失客户发送“情怀短信”以及“高额优惠券”，发现<strong>挽回率可达1.8%左右</strong>。也就是说，5000名目标用户中，每次大促活动中激活约90名用户。按客单700元计算，在当次大促活动中被挽回用户可以为店铺贡献约6.3万元的销售额，但是更重要的是，<strong>本次挽回成功，可以使用户在接下来的一段时间内成为“沉睡用户”或者“活跃用户”</strong>，这种隐形的意义对店铺来说要更大一些。而90名用户即使人人都使用50元的代金券，店铺的<strong>折损</strong>也不过是4500元而已。虽然相比于直通车等收费流量的推广成本，这种手段的“获客成本”更高，但是胜在<strong>更精准，挽回的客户更符合品牌调性，也就更有质量</strong>。</p></li><li><p><strong>短信营销用户清单</strong></p><p>最后，需要与这些长时间不来店铺消费的用户建立起某种连接通道，<strong>最直接的“通道”是短信营销</strong>。我们需要为店铺运营者提供“待激活用户清单”。重要的是，运营人员需要撰写“走心营销短信”，短信内容是否走心，是决定用户能不能被“唤醒”的关键。</p></li></ul><h3 id="建立物流地图"><a href="#建立物流地图" class="headerlink" title="建立物流地图"></a>建立物流地图</h3><p>了解订单主要集中在哪些省份之后，再结合各大快递公司在不同地区的收费标准，就可以为店铺选择最优的快递方案。</p><p>电商企业在与快递公司合作时，由于订单量大，是有“优惠价”的。但每家店铺的订单量不一致，因此具体到每家电商店铺都有不同的价格。但是，不管如何优惠，<strong>每家快递公司的价格基数</strong>都是公开的，因此根据它来选择合作快递公司同样是可行的。</p><p>在实际应用场景中，选择多渠道快递公司合作的话，将节省更多的费用。而且，如果将这一策略扩大至全年，将会节省近百万的快递费用。</p><h2 id="L15-店铺的活动分析"><a href="#L15-店铺的活动分析" class="headerlink" title="L15 店铺的活动分析"></a>L15 店铺的活动分析</h2><ul><li>案例：跟踪过去三年双11当天的流量与销售数据，发现它们有着很明显的共性：<ol><li>从时段来看，全天大约共有三个时间段为销售及流量的高峰期：<strong>分别是0点至2点、8点至9点，以及21点至23点。这三个时间段大致可以代表三种购物特性：凌晨秒抢、上班购买、晚间捡漏。</strong>因此，建议营销节奏也可以据此来进行相应的铺排。</li><li>从销售占比来看，0点至2点这两个小时内，销售占比高达60% ～70%，这段时间的购买主要是以预热期间提前加购的用户为主。根据这一特性，我们可以做出全天的销售预测：<strong>首先将截至凌晨3点的销售额除以60%或70%，以此计算出全天的预估销售额。然后与当天的计划销售额加以对比，判断两者之间是否存在缺口。</strong>如果达不到预期，则应想办法在接下来的两个流量高峰中予以补救；如果达到预期，也应及时 检查商品的销售结构是否尚保持相对完整。重点监测动销率、售罄率等关键指标，降低主力商品牌出现断货的风险。</li></ol></li></ul><h3 id="可控因素"><a href="#可控因素" class="headerlink" title="可控因素"></a>可控因素</h3><p>促销活动中的可控因素，是指在做促销活动时，我们能够人为控制并且借此来改善促销业绩的一些因素。</p><p>对于一次大型促销活动而言，可以量化的影响活动的重要因素有5个：优惠券、资源位流量、老客户激活、承接页流量、加购商品监控。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/3a9ebef0ebde44bd.png" alt></p><h3 id="优惠券"><a href="#优惠券" class="headerlink" title="优惠券"></a>优惠券</h3><p>优惠券是电商促销活动中的常规武器，一般分为<strong>无门槛优惠券</strong>和<strong>满减优惠券</strong>两种。</p><p>优惠券的作用在于<strong>打消顾客在购买时对于价格的顾虑</strong>。把顾客从冷静理性的购物状态带入感性、冲动的购物状态。这样，便达到了刺激顾客购买欲望的目的——这一点，在那些对价格敏感的客户群体中尤其有效。但是缺点也同样明显，就是会显著拉低销售利润。控制不好，甚至会导致销售亏损。</p><p><strong>设置正确合理的优惠券面额：</strong></p><ul><li><p><strong>方法一：平均客单价设置法</strong></p><p>店铺的平均客单价代表了店铺目前用户群体的消费力水平。譬如某店铺的平均客单价为270元，那么，说明此店铺客群的消费力大致也是在270元左右（一般是学生或刚入职场的年轻人）。因此，我们可以把优惠券的门槛设置为300元，这样便可以<strong>达到鼓励用户进行高客单消费的目的</strong>。</p><p>利用平均客单价方法设置优惠券时，首先要规划本次共设几档优惠券，然后参考店铺的平均客单价，<strong>以再搭一个单品即可达到优惠门槛为佳</strong>。</p><p>举例说明：<br>A店铺在筹备三八妇女节的活动时，计划设置三档优惠券，用以提 升活动效果。那么，应该如何设置呢？</p><p>首先，<strong>预估一下活动期间的平均客单价，并且将其分为上中下三档</strong>。比如，连带率（连带率=销售的件数/交易的次数，反映的是顾客平均单次消费的产品件数）低于1.6时，客单价为多少？连带率低于3.0时，客单价为多少？连带率高于3.0时客单价为多少？根<strong>据此三个阶梯来划分优惠券的三大门槛</strong>。由于是促销期间，客单价肯定会比日常略低，因此可以根据活动商品的平均折扣，或者过去同类活动来预估。</p><p>其次，<strong>精选一些可以提升连带销售量的单品作为搭配产品</strong>，在首页或者活动二级页中组成搭配专区，以便于给用户凑单。这样可鼓励用户达到使用优惠券的门槛。披肩、毛巾、内搭等是常见的搭配产品。</p><p>最后，<strong>“平均客单价+搭配物件价格-可以承受的销售折损金额”便是优惠券的面额档级</strong>。如店铺连带率低于1.6时，客单价为340元，搭配物的价格为59元，可以承受的折损是不低于活动价的9.8折。那么，优惠券高则可以设置为“80元，满399元可用”，低则可设置为“40元，满399元可用”。</p></li><li><p><strong>方法二：价格带宽度设置法</strong></p><p>此种方法要求先将店铺统计周期内的销售价格带罗列出来，然后根据价格带的宽度分布来设置优惠券的层次与门槛。</p><p>某店铺10月销售价格带分布：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/ec8de154809b3c90.png" alt></p><p>假设把主销价格带分为三段，则可以分为300～499、500 ～699、800～899三段。根据这一分类，假设同样需要设置三档优惠券，则可以按图所示进行设置。</p></li></ul><p><strong>优惠券跟踪分析：</strong></p><p>在大促之前，数据部门更重要的职能是——<strong>需要跟踪优惠券的领用与使用情况来判断店铺需要承担的折损与能够带来的销售业绩</strong>。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/6e8fc85d94611916.png" alt></p><p>首先，综合“类型”“面额&amp;档级”“展现位置”“发放时间”四列信息，可以了解到<strong>店铺运营人员对优惠券的定位与运营手段</strong>。以“无门槛50元”的优惠券为例，这是运营人员在活动期间的最后几小时冲刺业绩所用的，因此可以看到它仅在活动结束前3小时才推出。这是运营上的解读。</p><p>其次，从数据层面，<strong>需要跟踪优惠券的领用情况与使用情况</strong>。在预热期间，每天观察优惠券的领用率，以便评估活动的预热效果是否足够理想。同时，如果发现优惠券的领用超过预期，在预热尚未结束而优惠券的领用率却达到85%以上时，可提醒业务部门增加优惠券的发放数量。</p><p>同时，还可以根据领用率来<strong>评估优惠券的投放位置与投放时间是否正确有效</strong>。譬如在表中所示的“无门槛50元”优惠券，“首页”的领用率达到了100%， 而“活动二级页”的领用率仅43%，说明同样的优惠券，在首页投放的效果比在二级页中投放的效果更好。因此，若下次再有类似优惠券时，在折损允许的范围内，可以建议运营人员在“首页”上投放更多的优惠券；而<strong>在活动开始后，则需要跟踪优惠券的使用量与使用率。根据优惠券的使用率来计算本次活动中优惠券所导致的折损，以此评估本次活动中优惠券的折损是否在预算范围之内</strong>。</p><blockquote><p>怎样根据使用率来计算优惠券的折损呢？怎样判断这个折损是否合理呢？</p><p>优惠券带来的折损金额与ROI预估：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/74c402b54bdfbd05.png" alt></p><p>本次活动折损金额约为12万元，这是所有优惠券使用后带来的销售损失，但与此同时，这些优惠券也带来了约226万的业绩。以此计算，ROI达到18.9。 在大促活动中，<strong>优惠券的ROI如果低于15，一般是不太理想的</strong>。</p></blockquote><h2 id="L16-店铺的双11年终大促"><a href="#L16-店铺的双11年终大促" class="headerlink" title="L16 店铺的双11年终大促"></a>L16 店铺的双11年终大促</h2><p>屏效分析（一小时后）：</p><p><img src="https://ftp.bmp.ovh/imgs/2020/03/962e6fbfd78dde89.png" alt></p><p>主推款：商品ABC分析法（1点、11点、22点）：</p><p><img src="https://ftp.bmp.ovh/imgs/2020/03/8d7b90db4091887e.png" alt></p><p>在每一波销售高峰中，以更有吸引力且库存深厚的商品去迎接集中化的流量。</p><p>淘宝渠道商品断码统计（21点）：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/5e1a9a401ecd5d7c.png" alt></p><p>*注：期内共有333个SKU产生销售，销售后，其中出现断码的SKU达到153个。断码率达：46%（断码：当M码或L码库存为0时，判断为断码）</p><p>平台最近四小时仅动销了333个SPU，全店商品约有1200个，也就是说，最近四小时的动销率仅28%左右。而动销过的商品中，已经出现断码的商品竟然高达46%。原因：淘宝渠道的商品调换轮转太慢导致。调整策略：优先调整首页与活动二级页面的前5屏</p><p>天猫店铺预售情况分析（22点）</p><p><img src="https://i.bmp.ovh/imgs/2020/03/fb29fd44f3780a1e.png" alt></p><p>注：可催付的金额约为32万元；“下单但未付订金”的订单金额达约65万，可短信提醒，或派送定向优惠券；</p><p>调整策略：预售款尾款没有支付的客户，以及仅下单未付订单的客户的名单，包括手机号与淘宝ID给抓取出来，给了天猫渠道经理和客服经理，提醒按照名单尽快安排催付。</p>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商数据分析与数据化运营Note——Part3：数据表格</title>
      <link href="/2020/03/20/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part3/"/>
      <url>/2020/03/20/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part3/</url>
      
        <content type="html"><![CDATA[<h1 id="Ch3-表作骨，美化为肉，方法是灵魂"><a href="#Ch3-表作骨，美化为肉，方法是灵魂" class="headerlink" title="Ch3 表作骨，美化为肉，方法是灵魂"></a>Ch3 表作骨，美化为肉，方法是灵魂</h1><p>本章主要讲解如何快速有效地构建一份适用的数据表格，并且选择恰当的数据分析方法来达到分析目的。</p><h2 id="L9-快速建立实用美观的数据表"><a href="#L9-快速建立实用美观的数据表" class="headerlink" title="L9 快速建立实用美观的数据表"></a>L9 快速建立实用美观的数据表</h2><h3 id="快速构成实用的数据表"><a href="#快速构成实用的数据表" class="headerlink" title="快速构成实用的数据表"></a>快速构成实用的数据表</h3><ol><li><p>三种常见的Excel表格类型</p><p><img src="https://i.bmp.ovh/imgs/2020/03/385e7ec81b201ac4.png" style="zoom:50%;"></p><p><img src="https://i.bmp.ovh/imgs/2020/03/8daf519980122f53.png" alt></p><p><img src="https://i.bmp.ovh/imgs/2020/03/95146dde24db3591.png" alt></p><ul><li>一维表：指表格的每一行都是一条独立而完整的信息；主要用于基础数据的存储，因为一维的格式方便把数据导入到各种数据处理软件；</li><li>二维表和三维表中，每表格的‘行’必须与‘列’上的字段结合起来，才能够形成一条完整而独立的数据。不同点在于，<strong>二维表中，‘行’只需要与‘列’上的一个字段结合；而三维表中，‘行’需要与‘列’的两个字段结合</strong>。</li><li>二维表主要用于各种简单场景下的数据分析，需要对品类进行销售分析，而不用区分渠道时，便是采用了二维表的方式</li><li>三维表主要用于比较复杂的数据分析需求，如对各渠道与各品类的交叉式销售分析</li></ul></li><li><p>[指标—维度]快速构表法 </p><p>把‘维度’放在数据表格的第一列，而‘指标’放在表格的第一行。当指标与维度交叉时，就会形成数据。</p><ul><li><p>指标：用来衡量某一事物发展程度的。比如我们要衡量店铺的业绩好坏，便需要用到销售量、 销售额、完成率等指标。指标可又分‘绝对指标’与‘相对指标’。 比如‘销售量’‘销售额’便是绝对指标，而‘完成率’‘转化率’等便是相对指标。</p></li><li><p>例如：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/6df3ce1aeb829578.png" alt></p><p>首先，从构表方法来讲，这个表格是用‘指标–维度’的方法构成的。它包括三个指标，分别是‘销量’‘销额’和‘完成率’，然后包含了五个维度，其中‘6月’‘同比’‘MTD’‘YTD’是时间维度；‘竞品’是空间维度。</p><p>从数据来解释，这家店铺6月销售额为1600万，超额完成了当月销售目标。但是1～6月的累积完成率仅96%，说明此前5个月是存在‘销售缺口’的；同样，年度完成率仅37%，结合MTD基本达标 （96%）的情况来看，证明这家店铺把大部分的销售目标‘押宝’在后面半年中。</p></li></ul></li></ol><h3 id="建立报表输出标准"><a href="#建立报表输出标准" class="headerlink" title="建立报表输出标准"></a>建立报表输出标准</h3><p>数据分析的过程：</p><ol><li>数据收集：做数据分析之前需要先收集能够被使用的数据，比如商品资料、 销售明细等数据。</li><li>数据处理：需要清洗的数据层出不穷，如果不清洗干净，便会导致分析的结果出现非常大的偏差。</li><li>数据建模：把一个个清洗好的数据放置于一个数据表格的模板中。需要注意的是，这个数据表格的结构与逻辑，必须确保是能够满足分析目的。</li><li>报告出样：当我们根据设定好的“模型”把数据填充好后，数据报告便基本出样了。此时，更至关重要的是，我们要对数据报告进行反复解读，确保数据报告的“说服逻辑”是顺畅而且有理有据的。</li><li>优化报告：再有用的数据与数据化建议，只有在美化后才更能打动用户。同样，假设一份数据报告过长，数据分析师便非常有必要把数据分析的重要结论摘抄下来，单独形成一页，并放置在数据报告的前文。</li></ol><p>建立报表输出标准：</p><ol><li>表格的行与列，分别用相同色系，但色差相邻的两个颜色填充。这样，可以达到立体化的视觉效果，便于用户阅读。同时，关于色系的选择，在销售类报表中建议使用暖色调的色系；在退货或成本相关的报表中，建议使用冷色调的色系。</li><li>表格的字体：标题用“宋体”11号字体、表格中其他汉字及数字均用“微软雅黑”9号字体。</li><li>关于数字的处理：表格中所有数字，均要使用千分位记数法， 同时过大的数字无须保留小数位，过小的数字可以保留1～2位小数，另外，表格中的数字的单位一定要在表格中备注好。</li><li>关于小计与合计：表格中所有小计类数据均为斜体，并加单下划线；所有合计类数据，需要加粗，加双下划线，并且用淡灰色填充。</li><li>关于表中重点/异常数据：对于表格中的重点数据，或是异常数据，必须用亮黄色填充，并用红色字体凸显，如此可引导表格的读者迅速发现数据重点，或异常数据。</li><li>关于百分比：这也是表格优化的一种技巧。在实际分析场景中，我们常把结构复杂、数据绝对值过多的表格，转化为百分比表格。 这样，我们一眼就可以从表格中找出重点数值与异常数值。</li></ol><h2 id="L10-简单而实用的三大分析方法"><a href="#L10-简单而实用的三大分析方法" class="headerlink" title="L10 简单而实用的三大分析方法"></a>L10 简单而实用的三大分析方法</h2><p>本节课主要介绍数据分析的三大基础方法，分别是对比分析、细分分析、转化分析。</p><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ol><li>绝对值对比与相对值对比</li></ol><p>在电商数据分析中，一般绝对值指正数之间的对比较多，如销售额、退货额等；</p><p>相对值对比，则是指转化率、完成率等这类相对数之间的对比。</p><ol><li><p>环比</p><p>环比是指<strong>统计周期内的数据与上期数据的比较</strong>，比如2017年6月数据与2017年5月数据的比较。</p><p>在电商数据分析中，由于每个自然月之间的销售差额比较大，如果采用绝对指标，便很难通过对比观察到业务的变化。因此，<strong>一般会采用相对指标来做环比分析</strong>。</p></li><li><p>同比</p><p>同比是指<strong>统计周期内数据与去年同期数据之间的对比</strong>，比如2017年6月数据与2016年6月数据的比较。</p><p>在电商分析中，同比是应用最广泛的数据分析方法。通过同比，我们能大致判断店铺的运营能力在最近一年中，是保持增长还是呈下滑趋势。同时，也可以根据同比增长趋势，来制订初步的销售计划。</p></li><li><p>横向对比与纵向对比</p><p>所谓横向对比与纵向对比，是指空间与时间两个不同的维度之间的对比。</p><p>横向对比是空间维度的对比，指<strong>同类型的不同对象在统一的标准下进行的数据对比</strong>。如“本店”与“竞品”之间的对比；</p><p>纵向对比是时间维度的对比，指<strong>同一对象在不同时间轴上的对比</strong>。如前面提到的“同比”“环比”都是纵向对比。</p></li><li><p>份额</p><p>严格地说，“份额”属于横向对比的一种。在某些情况下，数据表格中多一个“份额”，会让表格清晰明了许多。</p><p>假设我们要分析“某品牌天猫、京东、唯品会三大渠道”的“上衣、下衣、连衣裙和其他”在“Q1～Q4季度”的销售趋势和表现。但是，如表1这般的数据却不能直观告诉我们每个销售类别在不同渠道和不同季度的销售趋势是什么。因此，在数据分析中便需要加入表2这样的“份额”分析表格。如此，我们便可一目了然地掌握每个类别在不同渠道、不同时期的销售趋势。因此也就达到了数据分析的目的。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/b6d94f77f721b5b1.png" alt></p></li></ol><h3 id="细分"><a href="#细分" class="headerlink" title="细分"></a>细分</h3><p>细分分析法，常用于为分析对象找到更深层次的问题根源。难点在于我们要理解从哪个角度进行‘细分’与‘深挖’才能达到分析目的。在分析之前，选择正确的‘细分’方法便非常重要。</p><ol><li><p>分类分析</p><p>就是指对所有需要被分析到的数据单元，按照某种标准打上标签，再根据标签进行分类，然后使用汇总或者对比的方法来进行分析。</p><p>在服装行业中，常用于做分类分析的标签有“类目”“价格带”“折扣带”“年份”“季节”等。通过从“年份”“季节”的维度来对商品库存进行细分，我们可以轻松地知道有多少货属于“库存”，有多少货属于“适销品”；通过从“折扣带”的维度来对销售流水进行细分，我们可以大致知道店铺的盈利情况；通过从“类目”的维度对销售流水和库存同时进行细分，我们可以知道统计周期内品类的销售动态与库存满足度。</p></li><li><p>人—货—场</p><p>“人—货—场”能够为人提供宏观视野的分析。其原理类似于分类分析，即将所有需要被分析到的数据单元，打上“人”“货”“场”的标签，然后再进行相应的数据分析与处理。</p><p>在实际应用场景中，‘人—货—场’分析法往往被灵活运用在<strong>初步诊断某一竞品店铺</strong>时。如下图所示是利用“人—货—场”逻辑方法来分析竞品店铺的主流思路。在分析之前，先用“人—货—场”的方式罗列出来， 把所有能够想到的有用的“分支”都罗列出来，然后查漏补缺、标注重要与非重要。最后，再按此思路来进行分析。便可达到事半功倍的分析效果。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/caf642c9a846bb9e.png" alt></p></li><li><p>杜邦分析</p><p>在电商中，杜邦分析常被用于寻找销售变化的细小因素之中。 下图便是根据杜邦分析原理，<strong>将所有影响到销售额的量化指标都统计出来</strong>的一种常用分析方法。此种方法，有助于我们从细小的数据颗粒中找到影响销售变化的元素。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/0c201d5a6a0fa9c2.png" alt></p></li></ol><h3 id="转化"><a href="#转化" class="headerlink" title="转化"></a>转化</h3><p>转化分析常用于页面跳转分析、用户流失分析等业务场景。</p><p>转化分析的表现形式一般是选用漏斗模型，如下图所示，模拟了某电商店铺的流量转化情况，并以漏斗图的形式展现出来。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/0a0f02b9115b267a.png" style="zoom:67%;"></p><ol><li>转化分析方法的前提，是我们需要<strong>首先确定一条“转化路径”</strong>（如图左侧的路径所示），这条路径就是我们的“解题方法”，是决定我们接下来的分析能否达成目标的重要因素。</li><li>当“转化路径”确定后，我们需要把“路径”中的各个“节点”罗列出来，并把节点下的重要数据统计出来。</li><li>最后，根据路径把各节点的数据用漏斗图的形式表达出来。 </li></ol><p>同时，转化分析还可用于店铺微观方面的“转化”洞察。譬如在某一次店铺举行大促活动时，我们需要分析<strong>大促期间“活动二级页”的流量转化效果如何</strong>。此时，我们便可以参照如下图所示的漏斗模型。 </p><p><img src="https://i.bmp.ovh/imgs/2020/03/409afd5883505179.png" style="zoom:80%;"></p><p>在以上案例中，我们将转化路径定义为“活动页→详情页→支付页面（下单）→支付成功（购买）”四个节点。然后统计每个页面的流量到达数量，于是得出漏斗图。</p><p>通过此图，可以清晰明确地诊断出此次活动二级页在“下单→付款”环节转化率仅40%，存在一定问题。在支付界面的流量跳失，很可能是价格过高所致。</p>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商数据分析与数据化运营Note——Part2：数据指标</title>
      <link href="/2020/03/19/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part2/"/>
      <url>/2020/03/19/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part2/</url>
      
        <content type="html"><![CDATA[<h1 id="Ch2-像“堆积木”一样认识数据指标"><a href="#Ch2-像“堆积木”一样认识数据指标" class="headerlink" title="Ch2 像“堆积木”一样认识数据指标"></a>Ch2 像“堆积木”一样认识数据指标</h1><h2 id="L7-能够诊断业务的KOL数据指标"><a href="#L7-能够诊断业务的KOL数据指标" class="headerlink" title="L7 能够诊断业务的KOL数据指标"></a>L7 能够诊断业务的KOL数据指标</h2><h3 id="以运营为导向的业务框架"><a href="#以运营为导向的业务框架" class="headerlink" title="以运营为导向的业务框架"></a>以运营为导向的业务框架</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/99e1350022a77389.png" alt></p><p>在实际运营场景中，一次正常的运营闭环一般会经历以上的7个步骤：</p><ol><li>首先，<strong>运营者们会制订本次的销售目标、销售计划</strong>（包括促销方案）；在销售计划中，运营者需要着重提出，他们需要的商品资源与推广需求；</li><li>然后，<strong>商品与市场推广的负责人会根据运营的需求提供相应的解决方案</strong>，并协商达成一致；</li><li>同时，<strong>视觉部门</strong>的同事会根据促销方案、活动主题等<strong>设计</strong>店铺的活动二级页、详情页等。他们的页面设计直接影响到活动的促销效果；</li><li>于是，进入下面的<strong>客服接待、订单处理、物流发货</strong>等环节。</li><li>最后，<strong>财务</strong>对这一时期的销售业绩与平台对账，以便初步核算出期内业务达标率等财务指标。</li></ol><h3 id="能够诊断业务的KPI指标"><a href="#能够诊断业务的KPI指标" class="headerlink" title="能够诊断业务的KPI指标"></a>能够诊断业务的KPI指标</h3><p>运营导向的业务框架下各项重要数据指标：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/85ac5d7106aeb816.png" style="zoom:150%;"></p><ol><li><p><strong>运营模块</strong></p><ul><li><p>重要职能：</p><ul><li><p>负责达成整个品牌的业绩目标</p></li><li><p>控制运营成本</p></li></ul></li><li><p>数据指标：</p><ul><li>从数据指标角度来评估运营能力时，需要<strong>避免使用单一指标来评估组织的运营能力</strong></li><li>一般使用<strong>业绩达标率、业绩增长率、销售利润额</strong>三个指标来进行综合评估。</li></ul></li><li><p>例如：</p><ul><li><p>运营团队A在2016Q1季度完成销售2000万，达标率110%，同增2%，净利率15%。 </p></li><li><p>运营团队B在2016Q1季度完成销售2000万，达标率95%，同增55%，净利率10%。 </p></li><li><p>在A、B两个运营团队中，</p><ol><li><p>如果我们只看“销售达标率”一个指标，无疑会认为运营团队A更优秀，因为达标率达到110%；</p></li><li><p>如果我们看“销售达标率”“增长率”两个指标，就会认为团队B更优秀。因为虽然B团队达标率才95%，但<strong>增长迅速，证明团队采取了有效的运营手段来冲刺业绩</strong>；</p></li><li><p>如果我们同时看三个指标，团队A业绩爆标了，但增长率才2%，<strong>暴露了它增长乏力的事实</strong>，而它的净利润额却达到300万，远高于团队B的200万。我们能说团队A比团队B更优秀吗？</p></li><li><p>反之，团队B虽然没有达标，但达标率95%也已经达到业绩及格线，而且增长率达55%，说明此团队找到了业绩增长的钥匙。而它的利润额却才200万，<strong>证明此团队为了达成高业绩而牺牲了一部分利润</strong>。我们也不能简单地定义团队B比团队A更优秀。</p></li></ol></li><li><p>从实例中可以看出，<strong>如果我们使用单一指标来评判业绩好坏，在许多场景下，都会产生不合理的结论</strong>。甚至有时还会出现，即使同时使用了两三项指标也不能对业绩进行准确评估的情况，这时我们就要反思，是分析方向不对，还是使用的指标精细度不够了。</p></li></ul></li></ul></li><li><p><strong>商品模块</strong></p><ul><li><p>重要职能：</p><ul><li><p>商品企划</p><p>商品企划是指提前将一个销售周期（一般是指一个季度）的商品需求进行品类、价格带、风格等结构性的规划，并制订有前瞻性的商品销售进度计划。</p></li><li><p>商品运营</p><p>商品运营是指从商品入库、商品上架，到制定商品主推策划、商品流通规则、商品折损保护等一系列的运营动作。以“更高的利润，销售更多商品”为目的。</p><p>既要保护品牌调性（不能过度频繁打折，不能过多爆款），又要帮助运营走量。</p></li></ul></li><li><p>数据指标：</p><ul><li>对商品企划而言，主要对当季库存率（量/额）负责。从更细致的角度而言，就是要随时跟踪<strong>品类与主推款的售罄率</strong>：各品类的销售进度是否与预期一致？主推款的销售进度是否与预期一致？如果超出预期，是否需要及时补货？如果不达预期，是否需要提前促销？</li><li>对商品运营而言，<strong>商品的周转天数、新品动销率/售罄率、活动动销率/售罄率、销售折损</strong>都是非常重要的数据指标。周转天数越低，证明商品流动越快，则仓储成本更低、资金周转越灵活；销售折损越低，代表商品以更高的价格成交，销售利润就越高；动销率与售罄率则需要根据不同的商品生命周期与销售环境来考虑。 </li></ul></li></ul></li><li><p><strong>市场模块</strong></p><ul><li><p>重要职能：</p><ul><li><p>市场推广</p><p>主要指通过天猫的直通车、钻展，京东的京东快车、京选展位，以及第三方工具百度推广、淘宝客、今日头条等渠道来实现产品或者品牌的推广，从而达到为产品或品牌引流的目的。</p><p>尽管市场推广<strong>几乎都是以付费渠道与方式为主</strong>，付费的转化率也相对较高；但市场推广也存在免费方式，如百度贴吧、品牌微博等，一个注重品牌建设的公司，对这些渠道的数据分析也不能忽视。</p></li><li><p>会员维护</p><p>凡是在店铺内购买过一次的用户，几乎都被称为会员。因为电商的优势在于凡购买过一次，都可以在店铺中留下用户的收货人名称与联系方式，<strong>可以凭借这两项信息建立用户档案，并进行客户维护</strong>。有效的用户运营可以降低品牌的市场推广费用。</p></li><li><p>活动策划</p><p>商品部会从商品折损上维护品牌调性；而市场部则需要<strong>从品牌形象、品牌风格与定位上维护品牌调性</strong>。因此，但凡公司的重大促销活动，一般都会交由市场部<strong>进行活动主题的包装和策划</strong>。而且活动策划、包装得好，对活动的销售也会有较大的正面影响。</p></li></ul></li><li><p>数据指标：</p><ul><li><p><strong>ROI（投入产出比）、付费用户销售额、付费流量转化率三个指标</strong></p></li><li><p>许多公司可能会采用单一的ROI来考核市场推广能力，这并不是最合理的。因为当投入达到一定阶段时，ROI必然会下降，但此时投入所带来的产出却还是增加的。所以，如果单纯考核ROI，那么，有丰富经验的推广团队在把ROI做到理想值后，便会止步不前，为此就会浪费掉后续追加推广费用来带来的销售增量机会。</p></li><li><p>举个例子：</p><p>  假设在推广某件产品时有两个推广方案可供选择：</p><ol><li><p>A方案：投入2万元推广费用时，预估能够带来4万元销售业绩，此时ROI为1:2。 </p></li><li><p>B方案：投入2.5万元推广费用时，预估能够带来4.5万元销售业绩， 此时ROI降为1:1.8。</p><p>于是问题出现了，如果为了单纯追求高ROI值，推广团队必然会选择A方案投放；而如果选择B方案投放，则可以为该产品带来5千元的销售增量。假设这件产品件单价为500元，便是10件产品的额外销售收入；再假设这10件衣服分别由10位新客户购买，则又意味着该品牌损失了把10位新客户转化为老客户的机会。这样推算下去，选择A方案的损失无疑是巨大的。</p><p>所以不建议选择单一指标 （ROI）来考核，而<strong>应该结合ROI、付费用户销售额、付费流量转化率三个指标来看。</strong></p></li></ol></li></ul></li></ul></li><li><p><strong>视觉编辑模块</strong></p><ul><li><p>重要职能：视觉部的重要性体现在它对店铺转化漏斗的设计，以及能够显著提升详情页转化率上面。</p><ul><li><p>店铺视觉</p></li><li><p>详情页逻辑设计</p><p>详情页的重要作用在于建立访客对于产品的信任，因此这种用户的信任力直接影响到详情页的转化率。好的详情页逻辑可以为店铺直接带来销售提升。</p></li><li><p>页面框架设计</p><p>店铺的页面逻辑是否符合用户的浏览习惯，店铺的商品分类标签是否可供用户精准而及时地找到想要买的衣服，主推商品在店铺页面中是否被突出陈列……</p></li></ul></li><li><p>数据指标：</p><p>由于访客在店铺的浏览行为是动态的、不断变化的，因此很难用某一个单一的指标来衡量其成效。因此，行业都会采用<strong>“流量漏斗”+“热力图”</strong>的方式来分析与诊断。</p><ul><li><p>流量漏斗需要根据制定好的流量浏览路径来分析，不同的分析场景可以制定不同的流量路径。</p><p>比如，我们需要分析客户从详情页到支付购买之间的转化情况，此时首先要制定好一条类似于“详情页—加入购买车—生成订单—支付订单—交易完成界面”的用户浏览路径，然后把每一个关键页面的流量数统计出来，这样就可以制作出这条路径的流量漏斗图了：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/0545da09b4202260.png" alt></p></li><li><p>热力图用于诊断具体的页面结构设计是否合理。譬如我们通过流量漏斗发现在某一个页面的流量跳失率特别高，需要判断这个页面的跳失原因时，一般会采用热力图的方式。</p></li></ul></li></ul></li><li><p><strong>客服、仓储、财务模块</strong></p><ul><li><p>重要职能：从运营角度而言，客服、仓储、财务属于销售末端的支持部门。</p><ul><li><p>客服模块负责用户进店之后的咨询、成交引导，以及用户购买之后的售后服务。</p></li><li><p>仓储也是一个重要的支持部门， 商家未及时发货则会面临积分赔偿、用户投诉等各种风险；同时，仓储的另一个重要性也体现在需要尽快对仓库的大批量到货（包括用户的退货到货）进行入库，以便及时销售（或二次销售）。</p></li><li><p>财务模块比传统经营环境下的工作更复杂。由于电商行业的“退货滞后性”，导致同一时间内的营收收入始终不能等同于实 际财务收入。如果财务团队能够及时把上月的实际运营盈利情况告知运营团队，将会对运营产生非常大的帮助；财务的另一项职能是需要协助客户的售后人员进行退款操作。</p></li></ul></li><li><p>数据指标：</p><ul><li>对于客服而言，有三个重要指标：<ul><li>一是<strong>咨询转化率</strong>，就是指在店铺咨询过的访客中，有多少人最终成交了；</li><li>二是<strong>人效</strong>，是指经过咨询转化得到的业绩除以客服总人数的人均业绩，人效是体现客服团队贡献值的一个重要指标；</li><li>三<strong>是服务质量得分</strong>，这是店铺DSR评分中的一项，主要受店铺好评数、差评数、投诉率等影响。</li></ul></li><li>对于仓储与物流而言，有两大指标需要重点关注：<ul><li>一是<strong>日均发货单数</strong>，在销售订单能够满足的前提，以满负荷的工作状态下，日均能够发出多少个订单是一项重要的能力。</li><li>二是<strong>库存准确率</strong>，也就是盘点差异。所有实体零售行业的仓储都必须对盘点差异负责，这是仓储模块最基本的要求。</li></ul></li><li>由于财务很少直接参与到电商的一线运营中，因此对于运营有直接影响的指标较少。行业中几乎所有公司都会把用户申请退货之后的退款工作安排给财务团队，所以<strong>退款及时率</strong>应该是唯一对运营有直接影响作用的一项指标，同时它也是属于店铺DSR评分中的一项。 </li></ul></li></ul></li></ol><h2 id="L8-人、货、场下的数据指标库"><a href="#L8-人、货、场下的数据指标库" class="headerlink" title="L8 人、货、场下的数据指标库"></a>L8 人、货、场下的数据指标库</h2><h3 id="有关“人”的那些指标"><a href="#有关“人”的那些指标" class="headerlink" title="有关“人”的那些指标"></a>有关“人”的那些指标</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/d0f760ef14746b1e.png" alt></p><p>“人”可以分为“客服”与“用户”两类：</p><ul><li>“客服”是指客服团队，如售前、售后</li><li>“用户”按照成交状态又可以细分为“流量”与“成交用户”：<ul><li><strong>用户</strong>：凡是在店铺内有过成交记录的；有ID与联系方式可以作为单个的“个体”被追溯和联络</li><li><strong>流量</strong>：只要登录过店铺的；流量的定义明显要高于用户；流量只能作为“群体”而被统计</li></ul></li></ul><p>相关指标：</p><ol><li><p>流量来源：</p><p>流量来源分为自主、免费、付费、淘外、其他这五类。</p><p>但是在实际数据分析中，一致的口径都是使用<strong>主动、免费、付费</strong>三个来源的数据来交流。</p></li><li><p>新客/老客：</p><p>“新客户”是指在店铺内第一次成交的客户， 反之则称为“老客户”；</p><p>“<strong>新老客户比</strong>”是衡量店铺用户质量的一个重要占比。<strong>新客占比过高，说明店铺在统计周期内获客能力不错，但老客回头率过低。</strong></p></li><li><p>活跃/沉睡用户数：</p><p>根据客户生命周期，可以将客户大致分为<strong>新客户、活跃客户、沉睡客户、流失客户</strong>四大类。</p><p>活跃客户和沉睡客户是在做用户质量分析时需要重点关注的；<strong>活跃客户是指××天内有成交记录且购买次数&gt;N次的客户</strong>，活跃客户数量越大，店铺的主动和免费流量就越多；<strong>沉睡客户是指连续××天内没有购买记录的客户</strong>，用户运营团队需要定期执行沉睡客户的“唤醒计划”，因此，针对沉睡客户的监控显得非常有必要。</p></li></ol><h3 id="有关“货”的那些指标"><a href="#有关“货”的那些指标" class="headerlink" title="有关“货”的那些指标"></a>有关“货”的那些指标</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/dd2956179e757da4.png" alt></p><p>商品分析分为四大类：库存分析、配货需求与有效性分析、销售分析、退货分析。</p><ul><li><p>实例1：商品整体库存分析</p><p>某店铺Q1季度库存分析表：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/c6b79dbddb00dcef.png" alt></p><p>通过这份表，不仅可以看出此店铺的库存结构，并且可以判断每个品类的销售进度是否符合预期，以此来评估库存风险。所以，此表既是库存结构分析表，又可作为库存风险预警之用。</p><blockquote><p>SKU = Stock Keeping Unit（库存量单位）</p><ol><li>SKU是指一款商品，每款都有出现一个SKU，便于电商品牌识别商品。</li><li>一款商品多色，则是有多个SKU。例如：iPhone X 64G 银色 则是一个SKU。</li></ol><p>SPU = Standard Product Unit （标准产品单位）SPU是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息的集合，该集合描述了一个产品的特性。例如：iPhone X 可以确定一个产品即为一个SPU。</p><p>库存占比=库存量/总产量</p><p>动销率=店铺中有销量的商品数/全店所有商品数</p></blockquote></li><li><p>实例2：商品销售分析表</p><p><img src="https://i.bmp.ovh/imgs/2020/03/4b39c894ede52b15.png" alt></p><p>这份报表在电商店铺做大型促销活动时，非常有用。</p><p>它通过转化率、加购数、目前库存数这三个核心指标来监控店铺内的所有商品，帮助店铺运营者对所有单品进行“爆旺平滞”的分类，然后制定不同的销售策略；同时，这份表也可以及时发现“潜在畅销”款，提前规避“超卖”风险。 </p><p>如表中“支付转化率”一列中用黑体标注的，便是销售表现较差的款，不仅转化率低，而且库存相对较高。而“销售件数”一列中，用黑体标注的则是有“超卖”风险的。此款UV高达9万以上，售价相对较低， 单款销量上千件，但库存只余150件。以经验判断，此款应该是店铺某个“引流款”，长期投放直通车所致。因此，当通过数据发现此款后，便需要马上提醒商品人员进行库存补货，或者提醒推广人员暂停此款的直通车投放。否则便会有“超卖”风险。</p></li></ul><h3 id="有关“场”的那些常用指标"><a href="#有关“场”的那些常用指标" class="headerlink" title="有关“场”的那些常用指标"></a>有关“场”的那些常用指标</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/af1263f9d022ab5d.png" alt></p><p>场，就是指卖场。 在电商中，场主要由‘页面’与‘促销活动’构成，并体现在‘销售业绩’上。 所以，有关‘场’的指标，可以分为‘销售’‘页面’‘促销’三类。</p><ol><li><p>关于销售额与净销售额</p><p><strong>销售额</strong>是指统计周期内销售业绩的总和，<strong>净销售额</strong>是指统计周期内销售业绩<strong>减去期内退货额</strong>的业绩总和。</p><p>但是在实际分析场景中，这两个指标如何取舍？</p><ol><li>公司制定的本月销售目标是600万，可是这是销售额，还是净销售额呢？</li><li>在周销售报表中，销售额是70万，净销售额是-20万，净销售怎么会是负数呢？</li><li>不是说行业退货率是20%～30%吗，怎么上月退货率高达65%呢？</li></ol><p>以上三个问题来自同一个原因：<strong>电商滞后15天的退货周期，以及普遍高达20%以上的退货率</strong>。</p><p>问题1）：是数据统计口径的问题，一般在制定销售目标时，<strong>行业内都会使用“净销售额”</strong>，而在<strong>公众媒体上都会使用“销售额”</strong>。 </p><p>问题2）：是由于本周收到了金额高达90万的退货而导致净销售额为负；<br>问题3）：同样是由于期内收到的退货额过高所致的。如6月份店铺做了多个品牌团活动，而7月是淡季一场品牌团都没做。于是便会出现6月的退货大量出现在7月，于是拉高了7月的退货率。</p><blockquote><p>针对这种现象，行业内有一种“订单to订单”退货率（又简称A to A退货率，取“Apple to Apple”的意思）的计算方法，是按订单号来统计退货的一种方式，即不管客户滞后多久退货，只是退货所关联的订单号是属于同一个月的，便将退货额统计出来，并除以此月内销售额。</p></blockquote></li><li><p>关于业绩达标率</p><p>业绩达标率=销售额/计划额×100%。</p><p>往往需要衍生出更细致的分析维度，比如滚动达标率、YTD.%、 MTD.%等。</p><p>例如，某品牌2016年3月销售简报：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/b149793eb489bbb5.png" alt></p><p>年度滚动达标率 = 1～3月销售额/1～3月销售目标 ×100%，体现了累积销售进度的滚动达成情况</p><p>YTD.% = 1～3月销售额/全年销售目标×100% ，体现了累积销售额的年度达成情况</p><p>以天猫渠道为例：</p><ol><li>天猫3月份销售额约为102万，达标率仅96%，将近达标；</li><li>本月虽然没有达标，但得益于前两个月超额完成业绩目标，因此截至3月天猫渠道的滚动达标率为102%，说明前三个月，店铺的销售进度尚在预定进度之中；</li><li>在2016年已经过去3个月的情况下，天猫YTD进度只完成18%， 但滚动达标率达102%。说明天猫渠道把较多的销售业绩目标“押宝”在了后面的几个月中。</li></ol></li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>数据指标就像海量的积木零件，而优秀的数据分析师就像积木建筑师，需要从海量的积木零件中挑选出适用的，然后组装构造出一座理想的房子。</p><p><img src="https://i.bmp.ovh/imgs/2020/03/e3d2b83fa3b272a5.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商数据分析与数据化运营Note——Part1：建立电商运营的“上帝视角”</title>
      <link href="/2020/03/18/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part1/"/>
      <url>/2020/03/18/dian-shang-shu-ju-fen-xi-yu-shu-ju-hua-yun-ying-note-part1/</url>
      
        <content type="html"><![CDATA[<ul><li><p>优秀的数据分析师</p><p>有数据逻辑，结构化思维，商业认知能力，这是成为一个优秀数据分析师的必备技能。简单来说，就是对运营，数据，工具这三种能力的综合运用。</p></li><li><p>数据分析的价值在哪里？</p><p>能够为企业的运营提供<strong>更合理</strong>的运营建议。数据分析不是万能的，从数学角度来讲，数据分析只是一种让人理性思考和决策的工具与方法。而商业经营并不是纯靠理性的博弈就能赢的。除了理性的数据支撑，还需要丰富的情感驱动。所以数据只能做到更合理，但不一定会更有效。</p></li></ul><h1 id="Ch1-建立电商运营的“上帝视角”"><a href="#Ch1-建立电商运营的“上帝视角”" class="headerlink" title="Ch1 建立电商运营的“上帝视角”"></a>Ch1 建立电商运营的“上帝视角”</h1><h2 id="L1-服装与电商发展近史"><a href="#L1-服装与电商发展近史" class="headerlink" title="L1 服装与电商发展近史"></a>L1 服装与电商发展近史</h2><p>服装行业最重要的特点是<strong>周期</strong>——服装的生命周期、风格的生命周期，就连时尚趋势也是有生命周期的。</p><p>国内服装电商的12年发展历程：</p><p><img src="https://s1.ax1x.com/2020/03/18/8wQoIf.md.png" alt="8wQoIf.md.png"></p><ul><li><p>第一阶段：2003年～2007年电商1.0时代[流量为王] </p><p>电商处于C2C的时代，主要以草根卖家为主，运营方式也以刷单、打爆款、砸推广这样简单粗暴的手段为主。</p></li><li><p>第二阶段：2008年～2013年电商2.0时代[数据化运营] </p><p>许多传统服装品牌在这一阶段纷纷加入电商大军。受到“正规军”商家的正面影响，<strong>电商的运营逐渐趋向规范化和体系化</strong>。于是，“精细化运营”“数据化运营”的概念应运而生。数据分析师与数据分析技能便成为电商运营的重要拼图。</p></li><li><p>第三阶段：2014年～2016年电商3.0时代[内容营销]</p><p>结合视频直播、VR技术、网红号召等多种形式，为电商卖家打开新的营销思路，以便在流量稳定的情况下，提升商家的成交转化率。内容营销给商家带来的一个普遍影响是：<strong>所有商家都更加重视电商店铺的视觉效果，商家们在页面结构布局、顾客访问路径优化等方面有了很大的提升</strong>。</p></li></ul><h2 id="L2-数据分析不是“造火箭”"><a href="#L2-数据分析不是“造火箭”" class="headerlink" title="L2 数据分析不是“造火箭”"></a>L2 数据分析不是“造火箭”</h2><ul><li><p><strong>什么是电商数据分析师？</strong></p><p>数据分析师是<strong>把“运营、数据、工具”这三种能力综合运用，为电商店铺运营解决某一具体问题的职业</strong>。</p><p>一名合格的数据分析师必须有这三方面的能力：<strong>懂运营业务、有结构化思维、精通一两门数据工具</strong>。</p><p><img src="https://s1.ax1x.com/2020/03/18/8wllSe.md.png" alt="8wllSe.md.png"></p></li><li><p>数据报告加工流程</p><p><img src="https://s1.ax1x.com/2020/03/18/8wluFK.md.png" alt="8wluFK.md.png"></p><ol><li>明确目的：做任何数据分析之前，我们必须先了解<strong>本次数据分析的目的是什么</strong>。是诊断，还是预测，或者是总结？</li><li>构思结构/逻辑：针对本次分析的目的，我们需要<strong>从哪些角度来构建数据分析逻辑</strong>？用线性式的因果逻辑，还是用分布式相关逻辑？</li><li>开始分析：确定了报表的说服逻辑之后，本次分析需要用到<strong>哪些维度的数据</strong>？<strong>取值范围与口径</strong>是怎样的？这些数据能够得出什么样的<strong>结论</strong>？这些问题都需要在数据分析过程中考虑，最重要的是，对每次整理好的数据都要进行<strong>结论验证</strong>。</li><li>制作/美化报告：对整理好的数据进行取舍，按报表的说服逻辑排序，并编写相关文字观点。适当的美化，<strong>让报告更具有可读性</strong>，是非常有必要的。</li></ol></li></ul><h2 id="L3-电商运营就是“开飞机”"><a href="#L3-电商运营就是“开飞机”" class="headerlink" title="L3 电商运营就是“开飞机”"></a>L3 电商运营就是“开飞机”</h2><ul><li><p>什么是电商？</p><p><strong>电商=零售，零售=成交。</strong></p><p>所有的数据分析，都要以辅助运营、 提升业绩为目标。  </p><p>公司所有部门、所有人都是围绕“成交”两个字在转。比如：网站的页面设计要尽量满足用户使用习惯，活动策划要戳中用户痛点或是利益点，广告投放要选择精准的用户群体，商品配发要符合用户需求，包括我们所做的数据分析报告，也要以提升销售为目标。</p></li><li><p>电商分析最基本的公式</p><p><strong>UV * 转化率 * 客单价 = 销售额</strong></p><p>UV：访客；转化率：买单人数与访客的比值。</p><p>该公式的具体应用：</p><ol><li><p><strong>监测店铺运营状态</strong></p><p>当我们突然发现店铺的指标值不正常时，便应该引起警惕并且尽快找出原因。需要掌握不同时期下店铺的UV、转化率、客单价这些基本数据。</p></li><li><p><strong>制作年度运营目标</strong></p><p>UV、连带率、客单价三个因数，与销售额成正比。当三个因数中的每个因数都有细小的变化时，对销售额就会产生巨大的影响。这就是数学上的乘积效应。</p><p>利用这个原理，我们便可以根据各项指标的增长（或负增长）趋势，来预测来年的销售额。然后与财务目标，以及公司的商品与推广策略去匹配，便能大致预测我们的销售增长是否符合公司预期。</p><p>如果符合，我们的增长点体现在哪些指标上面？对应的这些指标是哪些业务部门在负责？他们在来年有哪些举措来确保这些指标的增长；如果不符合，又是哪些指标的增长达不到公司要求，是什么原因导致的？原因是否合理……</p></li></ol></li><li><p><strong>飞机模型图</strong>（核心业务部门的分工）</p><p><img src="https://s1.ax1x.com/2020/03/18/8wQ5Zt.md.png" alt="8wQ5Zt.md.png"></p><ul><li>运营部是驾驶员，他们负责根据外部（电商平台）的气候变化情况与飞机自身 （企业内部）的健康状态进行匹配，选择最适合的飞行高度与飞机路线。</li><li>商品部与市场部则是两个机翼，负责事业部在飞行过程中的方向选择。如果商品备货过重，则飞机会向右侧倾斜；如果市场推广费过高， 则飞机会向左侧倾斜；如果商品部与市场部都失去应有的作用，则飞机 失去双翼，就会变成滑翔机，只能随着机舱外风吹的方向前进。</li><li>设计部是尾翼，负责飞机在飞行过程中的平衡，如果品牌的风格不稳定，品牌就会陷入左右摇摆、飘忽不定的局面。</li><li>客服部负责在机舱内照顾好已经登机的客人。</li><li>商业智能部是飞行指挥塔，负责随时监测飞机内部的各项飞行指标，同时还要对飞行途中的外部气候做出准确的监测与预判，然后随时与飞行驾驶员沟通，及时提供飞行警示信息。同样，商业智能部也要随时监测企业经营过程中的一切指标，包括商品、流量、销售额、利润等，并且还要监测外部的行业情报、竞争对手情报，然后针对这些数据进行分析，提交可供决策人员参考的运营分析报告。 </li></ul></li></ul><h2 id="L4-在正确的渠道卖正确的货"><a href="#L4-在正确的渠道卖正确的货" class="headerlink" title="L4 在正确的渠道卖正确的货"></a>L4 在正确的渠道卖正确的货</h2><ul><li><p>什么是运营？</p><p>“机关枪”的比喻：<strong>“平台属性”“品牌调性”“商品属性”</strong></p><p>平台属性：平台就像一把机关枪，不停向你们发射子弹，子弹就是流量。我们要做的不是躲避流量，而是要接住流量。那么你们能接住多少子弹呢？这就要求你们要了解机关枪的属性。它一个弹夹（一次销售高峰）有多少子弹？射程（访问深度）多少？射速（停留时间）多少？什么时候换弹（销售高峰什么时候结束）？</p><p>品牌调性：平台同时有很多把性能不一样的机关枪在发射子弹，那么根据我们品牌的调性与风格，我们去哪一把机关枪前接子弹的成功率最高？</p><p>商品属性：用哪些商品才能接到更多的子弹？子弹就是流量，流量就是人，那么这把机关枪射击出来的子弹，它喜欢什么样的商品呢？</p><p>只有理解了这三点，并且能找到正确的匹配，才是真正优秀的运营。</p></li></ul><h3 id="根据渠道特性匹配商品属性"><a href="#根据渠道特性匹配商品属性" class="headerlink" title="根据渠道特性匹配商品属性"></a>根据渠道特性匹配商品属性</h3><ul><li><p>天猫销售分析</p><p><img src="https://s1.ax1x.com/2020/03/18/8wQbRg.md.png" alt="8wQbRg.md.png"></p><ol><li>天猫的新旧商品销售为7:3，就是说天猫是一个以新品为主的销售渠道。</li><li>在新品中，天猫有一半（38%/71%）销售是以接近正价，也就是大于8折的价格销售出去的。证明这家店铺的新品很被消费者所接受，因此<strong>品牌调性与平台属性契合度比较高</strong>。</li><li>需要注意的是，这家店铺的新品销售中，退货率接近35%，这意味着这家店铺每卖10件新品，其中有4件可能被退回，个人感觉有点太高了。</li></ol></li><li><p>京东销售分析</p><p><img src="https://s1.ax1x.com/2020/03/18/8wQqzQ.md.png" alt="8wQqzQ.md.png"></p><ol><li>京东的商品新旧比接近6∶4，也算是以新品为主的销售渠道。</li><li>不过有些不同的是，京东的新品中，以6～7折商品销售为主，6 ～7折的商品应该是处于商品生命周期末端的产品。所以，这个数据说明对于服装正价新品的消费力，京东不如天猫，也就是说，天猫以正价新品为主，京东以打折新品为主。</li><li>京东的退货率约在25%左右，这一点远远低于天猫的35%。证明在同一单成交记录中，京东的经营成本要小于天猫。因为每一笔退货都会给品牌商带来售后、物流上的经营成本。</li></ol></li><li><p>唯品会销售分析</p><p><img src="https://s1.ax1x.com/2020/03/18/8wQOMj.md.png" alt="8wQOMj.md.png"></p><ol><li>在唯品会中，新品的销售贡献不到10%，也就是说，唯品会是几乎完全以旧货为主的销售渠道。</li><li>在旧货中，唯品会的主销折扣带在3～5折，几乎占了总销售额的一半。3～5折的商品几乎是以微利的方式清仓出货的。所以，唯品会为需要清仓的商品提供了一个较好的销售渠道。</li><li>即使是清仓，品牌也不能不赚钱。所以，在旧货中，还有40%的销售业绩来自于旧品6～7折的货。旧品卖到6～7折，自然可以给品牌提供足够的利润空间了。这些货同样是旧品，为什么它们能够卖到6～7折呢？这是从旧品中精细挑选出来的比较应季的款式。</li><li>用商品运营的专业术语来讲，<strong>6～7折是盈利款，而3～5折是走量款</strong>。盈利款与走量款的销售占比能够达到4∶5，这是品牌与唯品会平台之间达成共识的结果。简单来说，品牌方与唯品会平台的共同目标， 就是“唯品会既让品牌达到清仓甩货的目的，又能保证品牌赚钱”。这就是唯品会的属性。</li></ol></li></ul><blockquote><p>总结：</p><ul><li>首先，天猫渠道是一个适合新品销售的渠道，并且它的正价新品消化能力也很不错，所以，我们可以将新品的商品重点向天猫渠道倾斜；</li><li>其次，京东渠道就显得比较均衡了，它的新旧货占比接近5∶5，而且京东的新品销售集中在6折左右，说明京东平台的新品销售利润率并没有天猫渠道高，而且京东的旧品销售也可以占到50%的销售，说明京东同时也承担了一部分库存清理的功能；</li><li>最后，唯品会的特征是最明显的，它本身就定位于一个专门做特卖的网站，所以我们往上面铺的货也几乎都是旧货，而且是超低折扣的旧货。</li></ul></blockquote><h2 id="L5-图解渠道的运营节奏"><a href="#L5-图解渠道的运营节奏" class="headerlink" title="L5 图解渠道的运营节奏"></a>L5 图解渠道的运营节奏</h2><p>产品生命周期图：</p><p><img src="https://s1.ax1x.com/2020/03/18/8w3bRO.md.png" alt="8w3bRO.md.png"></p><p>任何一个产品在其销售过程中，都会经历“介入—成长—成熟—衰退”四个阶段。</p><h3 id="天猫的运营节奏"><a href="#天猫的运营节奏" class="headerlink" title="天猫的运营节奏"></a>天猫的运营节奏</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/2407cbbf046ecce5.png" alt></p><p>把营销活动细致地规划到了每周的时间维度中，并且在每周应该做哪些品类的营销，以怎样的主题来营销都有了前瞻性的规划。</p><p>天猫的活动分为四大级别：</p><ol><li><strong>SS级是指天猫平台方策划的最大型营销活动</strong>。这其中包括双11、双12等重磅活动，也包括“春上新”“春清仓”之类的服装生命周期相关的主题活动。实际上，<strong>SS级活动的名称，被称之为“服装节点”，也正是因为这些活动都是根据服装的生命周期规律来制定和策划的</strong>。从这个意义讲，双11、双12的核心本质就是秋冬大清仓。</li><li><strong>S级是天猫平台特意留出来的一些可供品牌合作的空白活动档期</strong>，如××品牌日、品牌周年庆等活动。S级活动一般会配备品牌团资源，天猫也会从各个渠道优先将资源分配给正在做品牌合作的商家。</li><li>A级活动是天猫平台方根据<strong>不同风格的品牌</strong>主动策划和包装的不同主题的活动。商家参加这些活动需要先报名，入围后天猫才会匹配相关资源、预估会场流量等。</li><li>B级活动是天猫平台根据<strong>不同服装品类</strong>而主动策划和包装的一系列活动。如“连衣裙节”“T恤节”等。有些以某一品类为主打的服装品牌会对这一系列活动十分看重，比如有个品牌是以连衣裙或大衣为主打产 品，那么这个品牌一定会想方设法在连衣裙节或大衣节的活动中，拿到更好的会场资源。</li></ol><p>需要注意的是，这四大分级并不是绝对的。譬如某品牌为了在某个A类或者B类活动中完成冲击业绩的目标，此时往往会选择在做活动的同时，再叠加一个品牌团。此时，A类活动或者B类活动就会成为这个品牌的S级活动。</p><p><strong>“7减8清9上新”</strong>：7月是春夏装减价促销的月份，8月是清仓大促销的月份，9月便开始秋冬款的上新。这个规律贯穿了天猫整个年度营销活动的节奏之中。</p><h3 id="京东的运营节奏"><a href="#京东的运营节奏" class="headerlink" title="京东的运营节奏"></a>京东的运营节奏</h3><p><img src="https://i.bmp.ovh/imgs/2020/03/255324ce6476ecdd.png" alt></p><ul><li>京东的活动分为三大级别，这个与天猫的四大级别的划分逻辑类似，这里就不再详细描述了。</li><li>京东的营销活动有个特点，就是重要活动是呈现<strong>“一头一尾盆地状”</strong>策划的。比如“双11”之后，紧跟着会出现一个“双11返场”的活动， 而“圣诞活动”也是“双12”的返场活动。这样策划的结果，就会使商家呈现出“两头高，中间低”的盆地式销售趋势。而天猫则是“倒三角形”式的销售趋势。这个区别呈现出来的特征是，<strong>天猫的活动流量是有计划地爆发式分配给商家的；而京东的活动流量是按计划均分式分配给商家的</strong>。</li><li>京东营销活动节奏的另一个特点是，没有像天猫一样，留给商家明显的“品牌合作”机会。天猫全年给所有商家留了13次品牌合作的机会，包括这13次品牌合作分布的时间节点都列得很清楚。而京东的营销运营中有关“品牌合作”的策划并没有体现出来，从侧面说明了，京东平台的营销活动策划可能没有天猫那么严谨。</li></ul><h2 id="L6-建立店铺的说服逻辑与购买路径"><a href="#L6-建立店铺的说服逻辑与购买路径" class="headerlink" title="L6 建立店铺的说服逻辑与购买路径"></a>L6 建立店铺的说服逻辑与购买路径</h2><h3 id="电商的说服逻辑"><a href="#电商的说服逻辑" class="headerlink" title="电商的说服逻辑"></a>电商的说服逻辑</h3><ul><li><p><strong>什么是说服逻辑？</strong></p><p>能够条理清晰、有效地说服他人的一套思维方式。</p><p>“卖是表达、买是认同”：</p><ul><li>买是认同：用户之所以买了我的产品，便是对我产生了认同。这份认同可能是对品牌、产品的认同，更可能是对价格、服务，甚至某一种情怀的认同。</li><li>卖是表达：作为卖方，我们应该学会表达我们的品牌、产品、价格、服务，甚至是情怀。唯有这样，才能让用户找到“购买”的理由。</li></ul></li><li><p><strong>电商店铺是怎样来说服用户成交？</strong></p><ol><li><p>电商靠的是视觉呈现：90%的图片+9%的文案+1%的咨询</p></li><li><p>视觉的呈现必须有条理、有结构</p></li></ol></li><li><p><strong>首页的作用：</strong></p><ol><li>增加用户信任感：突出品牌形象，建立用户对品牌的信任感；</li><li>流量分配：做好流量梳理，让用户更精准地找到目标需求产品；</li><li>抓住用户利益点：抓住利益点，让用户找到留下来的理由。</li></ol></li><li><p><strong>首页的构成：</strong></p><ol><li><p><strong>店招</strong></p><ul><li><p>向用户展示品牌实力，是最容易让用户产生信任的手段。譬如“2012～2016年度天猫女装总冠军”。</p></li><li><p>向用户发名片：一键收藏店铺。</p></li><li><p>店内搜索框：大多数店铺都会把搜索框设计在店招中。因为店招有置顶的作用，这样可以避免某些用户因为在首页的目录导航中找不到想要的衣服，而直接跳失离店。</p></li></ul><p>相关指标：</p><ul><li>店铺收藏总数：收藏数越多，说明此品牌的粉丝越多，店铺用户运营的基础越好，可断定此店铺转化率也不会太差。</li><li>搜索栏点击数：搜索栏使用得越多（热力图可看出），说明搜索栏摆放位置更合理。但同时也说明<strong>店铺首页的页面逻辑和商品的主推逻辑相对不合理</strong>。如果搜索栏的点击量远远高于首页中的导航栏和入口图等其他位置，这时必须要检查店铺的首页逻辑是否合理。</li></ul></li><li><p><strong>导航栏</strong></p><ul><li>让想找不同类别或风格服装的用户能够快速找到相应的服装。</li><li>根据不同季度的热销程度与店铺主推的优先级别，会将优先级高的类目尽量放在导航栏的前面，有些还会用红色、黄色等耀眼的颜色来显示。这是为了使主推商品尽可能吸引更多的点击。</li><li>流量分配的作用很多都是通过导航栏来实现的。</li></ul></li><li><p><strong>POP</strong></p><p>POP一般分静态和轮播两种形式：</p><ul><li>在店铺内有特大型促销活动（如双11、双12）时，一般会使用活动主题的POP静态呈现，这样可以尽量避免用户跳失；</li></ul></li></ol><ul><li>如果在平时，则会使用轮播的方式来呈现，一般是3～4张左右。<strong>多个POP应当达到不同的作用，否则既是一种空间浪费，也是一种信息的重复性骚扰</strong>。</li></ul><ol><li><p><strong>豆腐块（入口图）</strong></p><p>豆腐块的作用是，将同一类主推单品集中在一起，并以同一个入口图的形式展现出来。一般的店铺会有6～8个豆腐块，这些豆腐块串联在一起，就是这个店铺所呈现给用户的商品运营逻辑。</p></li></ol></li><li><p>首页前三屏的流量会占首页整体流量的40%以上。 所以，对于首页的说服逻辑来说，<strong>前三屏是最重要的</strong>。而三屏之后，也就是在豆腐块后面的区域，可以看到都是以单品的展示为主。这种展现仅仅是为了提升店铺主推商品的曝光率，对于店铺的整体说服逻辑没有直接作用。</p></li></ul><h3 id="电商的购买路径"><a href="#电商的购买路径" class="headerlink" title="电商的购买路径"></a>电商的购买路径</h3><p>我们需要熟知店铺内的几条主要的购买路径（一般有2～3条），并进行数据分析与研究。当发现店铺的整体购买转化率连续走低时，便可以从这些购买路径中找出原因， 并提出优化与测试方案。</p><p><strong>用户流量路径</strong>：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/8d47a83084a98ad1.png" alt></p><p>“站内流量”：指电商平台本身的流量</p><p>“站外流量”：是指用户是从电商平台之外的渠道进入店铺的。站外流量在店铺流量总和的占比中很少（一般不超过2%），所以不是研究的主要流量类型。</p><p><strong>免费流量与付费流量的路径有很大不同</strong>，这样的分类便于针对某一特定路径进行刻意的分析，然后进行优化。譬如，业界常见的做法之一是针对某个单品直通车的页面来源与去向进行数据分析，如某项数据指标不达标，便会考虑优化此单品的详情页。</p><p>长期的数据跟踪结果显示， <strong>流量第一次出现在店铺时，在首页登录的流量占到70%以上</strong>。因此，首页的“说服逻辑”是否有效便显得非常重要。首页、需要投放直通车的单品详情页、品牌团活动时想买人数多的单品详情页、大型活动时为活动准备的活动二级页，这些页面都是需要被重点监控的重要分析对象。</p><p><strong>“页面分析”工作的核心就是：抓住店铺内的主要购买路径，并分析路径中重要的页面，优化页面的说服逻辑。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>精益数据分析Note</title>
      <link href="/2020/03/17/jing-yi-shu-ju-fen-xi-note/"/>
      <url>/2020/03/17/jing-yi-shu-ju-fen-xi-note/</url>
      
        <content type="html"><![CDATA[<h1 id="第一篇-别再欺骗自己了"><a href="#第一篇-别再欺骗自己了" class="headerlink" title="第一篇 别再欺骗自己了"></a>第一篇 别再欺骗自己了</h1><h2 id="第一章-我们都在说谎"><a href="#第一章-我们都在说谎" class="headerlink" title="第一章 我们都在说谎"></a>第一章 我们都在说谎</h2><ul><li><p><strong>最小可行化产品</strong>（Minimum Viable Product；MVP）</p><p>指足以向市场传达你所主张的价值的最小化产品。</p></li><li><p><strong>专人接待式最小可行化产品</strong></p><p>如：正在考虑创建一种拼车服务，则可以试着用人工牵线搭桥这种原始方式将司机和乘客联系在一起，而并不是先考虑是否能开发出一款配对司机与乘客的应用软件。有时并不需要为了产品（即使是最小可行化产品）的开发浪费时间与金钱。</p><p>优点：</p><ol><li>专人接待式最小可行化产品并不会大规模生产，但却可以<strong>在短时间内以最低的成本帮你尽快测试自己的想法</strong>。</li><li>通过这种专人接待方法<strong>了解用户真正使用的产品，并优化自己的业务流程</strong>。</li></ol><p>启示：</p><ul><li>有时，增长来自于自己未曾想到的方面。在你认为找到了值得一试的想法时，思<strong>考如何以最小的投入快速完成测试</strong>，然后事先为成功下定义，并明确如果直觉准确的话下一步要如何走。</li></ul></li><li><p><strong>精益分析思维</strong></p><p>指提出正确的问题，并重点关注那项可达成期望结果的关键指标。</p></li></ul><h2 id="第二章-创业的记分牌"><a href="#第二章-创业的记分牌" class="headerlink" title="第二章 创业的记分牌"></a>第二章 创业的记分牌</h2><h3 id="什么是好的数据指标"><a href="#什么是好的数据指标" class="headerlink" title="什么是好的数据指标"></a>什么是好的数据指标</h3><ul><li><p>衡量数据指标好坏的一些重要准则：</p><ol><li>好的数据指标是<strong>比较性</strong>的。如果能比较某数据指标在<strong>不同的时间段、用户群体、竞争产品</strong>之间的表现，就能更好的洞察产品的实际走向。</li><li>好的数据指标是<strong>简单易懂</strong>的。如果人不能很容易记住或讨论指标，那么通过改变它来改变公司的作为很困难。</li><li>好的数据指标是一个<strong>比率</strong>。比率之所以是一个好的指标，有以下几个原因：<ol><li>比率的可操作性强，是行动的向导（开车是速度可以告知状态以便调整确保按时抵达，而里程不可）</li><li>比率是一个天生的比较性指标（可以比较当前速度和前一小时速度，判断是加速还是减速）</li><li>比率还适用于各种因素间的相生和相克（正相关和负相关）</li></ol></li><li>好的指标会<strong>改变行为</strong>。这是<strong>最重要</strong>的评判标准：随着指标的变化，你是否会采取相应的措施。<ol><li>日销售额之类的“会计”指标，有助于进行更准确的财务预测</li><li>“试验指标”，有助于优化产品、定价以及市场定位，会极大影响接下来的动作。需要在收集数据之前就确定好针对不同情况的应变措施。</li></ol></li></ol></li><li><p>另外，数据指标之间的<strong>耦合现象</strong>也值得注意，例如转化率是和购买所需时间相绑定的，二者结合可以的出很多关于现金流的信息。类似地，病毒传播系数（平均每个用户邀请来的新用户数）和病毒传播周期（用户完成一次邀请所需的时间）共同推动产品的普及率。</p></li></ul><h3 id="定性指标与量化指标"><a href="#定性指标与量化指标" class="headerlink" title="定性指标与量化指标"></a>定性指标与量化指标</h3><p>定性指标：非结构化的、经验性的、揭示性的、难以归类的；</p><p>量化指标：涉及很多数值和统计数据，提供可靠的量化结果，但缺乏直观的洞察。</p><p>如果定量数据回答的是“什么”和“多少”这样的问题，那定性数据回答的就是“为什么”。</p><p>定量数据排斥主观因素，定性数据吸纳主观因素。</p><h3 id="虚荣指标与可付诸行动指标"><a href="#虚荣指标与可付诸行动指标" class="headerlink" title="虚荣指标与可付诸行动指标"></a>虚荣指标与可付诸行动指标</h3><p>虚荣指标表面上很美，但不能为公司带来丝毫的改变；如果有一个数据，却不知道如何根据它采取行动，该数据就仅仅是一个虚荣指标。每当看到一个指标，就应该下意识问自己：“依据这个指标，我如何改变当前的商业行为？”如果回答不了这个问题，那么就不用纠结这个指标了。</p><p>可付诸行动指标：可以帮助选出一个行动方案，从而指导你的商业行为。关键在于：你是根据收集到的数据行动。</p><p>例如，“总用户注册数”就是一个虚荣指标，这个数字只会随着时间增长。”总活跃用户数”稍微好些，但前提是对“活跃用户”定义正确，否则还是一个虚荣指标。</p><p>真正应该关注的可付诸行动指标，是<strong>“活跃用户占总用户数的百分比”（活跃用户占比）</strong>。这个指标揭示了产品的用户参与度。另外一个值得关注的指标：<strong>“单位时间内新用户的数量”（新用户增速）</strong>，它对比较不同营销手段的优劣往往很有帮助。</p><ul><li><strong>8个需要提防的虚荣指标</strong><ol><li>点击量</li><li>页面浏览量（PV值）</li><li>访问量</li><li>独立访客数</li><li>粉丝/好友/赞的数量</li><li>网站停留时间/浏览页数</li><li>收集到的用户邮件地址数量</li><li>下载量</li></ol></li></ul><h3 id="探索性指标与报告性指标"><a href="#探索性指标与报告性指标" class="headerlink" title="探索性指标与报告性指标"></a>探索性指标与报告性指标</h3><p>探索性指标：是推测性的；</p><p>报告性指标：时刻对公司的日常运营、管理性活动保持信息通畅、步调一致。</p><blockquote><p>唐纳德理论：世界上的事物可以分为这样几类：我们知道我们知道的，我们知道我们不知道的；我们不知道我们知道的，我们不知道我们不知道的。</p><p>我们知道我们知道的：不确定的事实，要经过数据的检验</p><p>我们知道我们不知道的：意味着某种度量行为。因为我们知道我们不知道这一类指标的具体值，所以要度量。这类指标可用于核算或衡量试验的结果。</p><p>我们不知道我们知道的：直觉，需要评估并训练以提高效率</p><p>我们不知道我们不知道的：是探索，蕴含着自身独特的优势。</p></blockquote><p>数据分析在唐纳德理论中的应用：</p><p> 1）检验手头上的事实和假设，以确保不是在自欺欺人，计划是切实可行的；</p><p> 2）验证我们的直觉，把假设变成证据；</p><p> 3）为业务预测表、瀑布式开发流程图和董事会议提供数据；</p><p> 4）帮助我们发现黄金机遇，大展宏图。</p><p>案例分析：“妈妈圈”的成功之路</p><p>在”朋友圈”拥有1000万用户时，发现一个问题：只有很少的用户在真正地使用这个产品</p><p>解决：1、麦克探寻背后原因，首先搞清楚用户们做了什么，进行探索性分析，发现妈妈群体在其他群体活跃度较低的情况下，撑起整个产品的用户参与度。</p><p>​      2、调整产品重心，做出关键转型，发布产品“妈妈圈”</p><p>总结：1、“朋友圈”出现在正确的时间（FaceBook刚启动开放平台）和正确的地点（FaceBook站内应用），只是找错了市场。</p><p>​      2、通过分析用户行为模式和理想行为的分布，发觉高活跃度用户的共同点，找到与自身相匹配的市场 。</p><p>​      3、找准目标后，不遗余力聚焦，直至更改产品名称。</p><p><strong>数据分析启示</strong></p><p>想要让社区产品极速启动就需要相当高的用户参与度。不温不火的用户没办法让你的产品直冲云霄。</p><p>更好的做法是：在一个更小的、更容易触及的目标市场中培养更多具有黏性的高活跃度用户。病毒式传播需要专注。</p><p><strong>（4）先见性指标与**</strong>后见性<strong>**指标</strong></p><p>先见性指标：用于预言未来；</p><p>比如，透过“销售漏斗”中现有的潜在客户数，大致预测将来所能获得的新客户数。</p><p>后见性指标：解释过去，能提示问题的所在。</p><p>比如，用户流失（及某一时间段内离开某产品或服务的客户量）</p><p>创业之初，所拥有的数据不足以预测未来，这时先关注后见性数据。如果要启用先见性数据，需要首先进行同期群分析并比较客户对照组在不同时间段的表现。</p><p>有关账号注销和产品退货的数据是很重要的指标，只是比较滞后。用户流失量是很重要的数据指标。</p><p>“指示剂”无处不在，在一个企业级软件公司，就销售业绩而言，季度订单量是一个后见性指标，而新增潜在客户量是一个先见性指标。任何一个在B2B销售领域工作过的人都会告诉你，除了培养有价值的潜在客户外，还需要对潜在客户转化率和销售周期有很好的把握。</p><p>在一个公司中，某一团队的后见性指标有时是另一个团队的先见性指标。例如，季度订单量对于销售部门来说是一个后见性指标，对于财务部门来说，是一个可以指示营收预期的先见性指标。</p><p><strong>（5）相关性指标与因果性指标</strong></p><p>相关性指标：两个指标总是一同变化</p><p>因果性指标：其中一个指标的变化会导致另一个指标的变化。</p><p>关键绩效指标 KPI</p>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>林轩田《机器学习基石》Note——Part4：How Can Machines Learn Better?</title>
      <link href="/2020/03/17/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part4/"/>
      <url>/2020/03/17/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>课程：</p><ul><li><a href="https://www.bilibili.com/video/av12463015" target="_blank" rel="noopener">https://www.bilibili.com/video/av12463015</a></li></ul><p>参考笔记：</p><ul><li><a href="http://redstonewill.com/" target="_blank" rel="noopener">http://redstonewill.com/</a></li><li><a href="https://beader.me/mlnotebook/index.html" target="_blank" rel="noopener">https://beader.me/mlnotebook/index.html</a></li><li><a href="https://me.csdn.net/github_36324732" target="_blank" rel="noopener">https://me.csdn.net/github_36324732</a></li><li><a href="https://zhuanlan.zhihu.com/ml-note" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/ml-note</a></li></ul></blockquote><h1 id="How-Can-Machines-Learn-Better"><a href="#How-Can-Machines-Learn-Better" class="headerlink" title="How Can Machines Learn Better?"></a>How Can Machines Learn Better?</h1><h2 id="L13-Hazard-of-Overfitting"><a href="#L13-Hazard-of-Overfitting" class="headerlink" title="L13 Hazard of Overfitting"></a>L13 Hazard of Overfitting</h2><h3 id="What-is-Overfitting"><a href="#What-is-Overfitting" class="headerlink" title="What is Overfitting?"></a>What is Overfitting?</h3><p>假设平面上有5个点，目标函数是2阶多项式：</p><ul><li>如果hypothesis是2阶多项式，那么这5个点很靠近这个hypothesis，$E_{in}$很小。</li><li>如果hypothesis是4阶多项式，那么这5点会完全落在hypothesis上，$E_{in}=0$，但是$E_{out}$很大。</li><li>根据VC Bound理论，阶数越大，即VC Dimension越大，就会让模型复杂度更高，$E_{out}$更大。</li></ul><p><img src="https://i.bmp.ovh/imgs/2020/03/655d3663a730bb9e.png" style="zoom: 67%;"></p><p>VC曲线：</p><p><img src="https://i.bmp.ovh/imgs/2020/03/b222e9809f91a19b.png" style="zoom:67%;"></p><ul><li>在$d_{VC} = d_{VC}^*$的时候， $E_{out}$取到最小值；</li><li>当$d_{VC} &gt; d_{VC}^<em>$，也就是向右移动时，$E_{in} \downarrow ,E_{out} \uparrow$，这就是<em>*过拟合</em></em>（overfitting）；</li><li><p>当$d_{VC} &lt; d_{VC}^<em>$，也就是向左移动时，$E_{in} \uparrow ,E_{out} \uparrow$，这就是<em>*欠拟合</em></em>（underfitting）。</p></li><li><p><strong>overfitting是VC dimension过大的过程</strong>；<strong>bad generalization是VC dimension过大的结果</strong></p></li></ul><p>造成overfitting的原因是什么（把overfit比喻为出车祸）：</p><ul><li>使用过大的$d_{VC}$（车开太快）</li><li>有noise（路面颠簸）</li><li>数据量N不足（对路况的观察不够）</li></ul><p>也就是说，<strong>VC Dimension、noise、N这三个因素是影响过拟合现象的关键</strong>。</p><h3 id="The-Role-of-Noise-and-Data-Size"><a href="#The-Role-of-Noise-and-Data-Size" class="headerlink" title="The Role of Noise and Data Size"></a>The Role of Noise and Data Size</h3><p>我们看这样一个在二维平面上的例子，离散的圆圈是数据集，目标函数是蓝色的曲线——</p><p><img src="https://i.bmp.ovh/imgs/2020/03/0c2d07c942e574c0.png" alt></p><p>左图：目标函数是x的10阶多项式。数据没有完全落在曲线上，是因为加入了noise。<br>右图：目标函数是x的50阶多项式。没有noise的情况下，数据就全部落在曲线上。</p><p>现在我们分别用二阶多项式和十阶多项式来对两个问题进行拟合，得到下面的结果——</p><p><img src="https://i.bmp.ovh/imgs/2020/03/67389ba96094d800.png" alt></p><p>我们能看到在两个问题中$g_{10}$都发生了过拟合，反而$g_2$却表现得相对不错。</p><p>这种现象产生的原因，从哲学上来说，就是“<strong>以退为进</strong>”。有时候，简单的学习模型反而能表现的更好。</p><p>下面我们来看看发生这样现象的具体原因：</p><p><img src="https://i.loli.net/2018/07/24/5b572f1d8cda6.png" alt="img"></p><p>以上是用Learning Curves来看两个模型在有noise的情况，具体可以复习笔记：基石Lecture 9 - Linear Regression。$E_{in}$和$E_{out}$可以表示为：</p><script type="math/tex; mode=display">E_{in}=\text{noise level}\ast (1-\frac{d+1}N)\\E_{out}=\text{noise level}\ast (1+\frac{d+1}N)</script><p>本节的实验问题中，数据量N不大，即对应于上图中的灰色区域。</p><ul><li>左图的灰色区域中，因为d=2，$E_{in}$和$E_{out}$比较接近；右图中的灰色区域中，d=10，$E_{in}$很小，而$E_{out}$很大；</li><li>这就解释了之前2阶多项式模型的总是更接近，泛化能力更好。</li></ul><p>值得一提的是，如果数据量N很大的时候，上面两图中$E_{in}$和$E_{out}$都比较接近，但是对于高阶模型，z域中的特征很多的时候，需要的样本数量N很大，且容易发生维度灾难。</p><p>在第二个noiseless的问题中，我们发现仍然是2阶的模型拟合的效果更好一些，明明没有noise，为什么是这样的结果呢？ </p><p>其实，<strong>当模型很复杂的时候，这种复杂度本身就会引入一种‘noise’</strong>。所以，这种高阶无noise的问题，也可以类似于10阶多项式的目标函数加上noise的情况，只是二者的noise有所不同，下面将会详细解释。</p><h3 id="Deterministic-Noise"><a href="#Deterministic-Noise" class="headerlink" title="Deterministic Noise"></a>Deterministic Noise</h3><p>下面我们介绍一个更细节的实验来说明什么时候小心overfit会发生。</p><p>假设我们产生的数据分布由两部分组成：第一部分是目标函数$f(x)$，$Q_f$阶多项式；第二部分是噪声$\epsilon$，服从Gaussian分布。接下来我们分析的是noise强度不同对overfitting有什么样的影响。总共的数据量是N。</p><p><img src="https://i.loli.net/2018/07/24/5b572f49ac10c.png" alt="img"></p><ul><li>$Q_f$：$f(x)$的复杂度</li><li>$\sigma^2$：噪音的复杂程度</li></ul><p>那么下面我们分析不同的$(N,\sigma^2)$和$(N,Q_f)$对overfit的影响。overfit可以量化为$E_{out}-E_{in}$。结果如下：</p><p><img src="https://i.loli.net/2018/07/24/5b572f5b5fc76.png" alt="img"></p><p>上图中红色越深，代表overfit程度越高。</p><p>左图中阶数$Q_f$固定为20，横坐标代表样本数量$N$，纵坐标代表噪声水平$\sigma^2$。红色区域集中在$N$很小或者$\sigma^2$很大的时候，也就是说$N$越小，$\sigma^2$越大，越容易发生overfit。</p><p>右边图中$\sigma^2=0.1$，横坐标代表样本数量$N$，纵坐标代表目标函数阶数$Q_f$。红色区域集中在$N$很小或者$Q_f$很大的时候，也就是说$N$越大，$Q_f$越大，越容易发生overfit。这部分两图基本相似。</p><p>从上面的分析，我们发现：</p><ul><li>$\sigma^2$对overfit是有很大的影响的，我们把这种noise称之为<strong>stochastic noise</strong>。</li><li>$Q_f$即模型复杂度也对overfit有很大影响，而且二者影响是相似的，所以我们把这种称之为<strong>deterministic noise</strong>。之所以把它称为noise，是因为模型高复杂度带来的影响。</li></ul><p>总结，有四个因素会导致发生overfitting：</p><ul><li><strong>data size $N \downarrow$</strong></li><li><strong>stochastic noise $\sigma^2\uparrow$</strong></li><li><strong>deterministic noise $Q_f\uparrow$</strong></li><li><strong>excessive power $\uparrow$</strong>（右图左下角部分）</li></ul><p>我们刚才解释了如果目标函数$f(x)$的复杂度很高的时候，那么跟有noise也没有什么两样。<strong>因为目标函数很复杂，那么再好的hypothesis都会跟它有一些差距，我们把这种差距称之为deterministic noise。</strong>deterministic noise与stochastic noise不同，但是<strong>效果一样</strong>。其实<strong>deterministic noise类似于一个伪随机数发生器</strong>，它不会产生真正的随机数，而只产生伪随机数。它的值与hypothesis有关，且固定点x的deterministic noise值是固定的。</p><h3 id="Dealing-with-Overfitting"><a href="#Dealing-with-Overfitting" class="headerlink" title="Dealing with Overfitting"></a>Dealing with Overfitting</h3><p>现在我们知道了什么是overfitting，和overfitting产生的原因，那么如何避免overfitting呢？避免overfitting的方法主要包括：</p><ul><li><p><strong>start from simple model</strong></p></li><li><p><strong>data cleaning/pruning</strong></p></li><li><p><strong>data hinting</strong></p></li><li><p><strong>regularization</strong></p></li><li><p><strong>validataion</strong></p></li></ul><p>介绍简单的data cleaning/pruning和data hinting两种方法：</p><ul><li><p>data cleaning/pruning：</p><ul><li>对训练数据集里label明显错误的样本进行修正（data cleaning）</li><li>或者对错误的样本看成是noise，进行剔除（data pruning）。</li><li>data cleaning/pruning关键在于如何准确寻找label错误的点或者是noise的点，而且如果这些点相比训练样本N很小的话，这种处理效果不太明显（不一定有用）。</li></ul></li><li><p>data hinting</p><p>针对N不够大的情况，如果没有办法获得更多的训练集，那么data hinting就可以对已知的样本进行简单的处理、变换，从而获得更多的（虚拟）样本。</p><p>举个例子，数字分类问题，可以对已知的数字图片进行轻微的平移或者旋转，从而让N丰富起来，达到扩大训练集的目的。这种额外获得的例子称之为virtual examples。但是要注意一点的就是，<strong>新获取的virtual examples可能不再是iid某个distribution（分布改变）</strong>。所以新构建的virtual examples要尽量合理，且是独立同分布的。</p></li></ul><h2 id="L14-Regularization"><a href="#L14-Regularization" class="headerlink" title="L14 Regularization"></a>L14 Regularization</h2><h3 id="Regularized-Hypothesis-Set"><a href="#Regularized-Hypothesis-Set" class="headerlink" title="Regularized Hypothesis Set"></a>Regularized Hypothesis Set</h3><p>那么如何对过拟合现象进行修正，使hypothesis更接近于target function呢？一种方法就是regularized fit。</p><p><img src="https://i.loli.net/2018/07/24/5b57423e5693a.png" alt="img"></p><p>这种方法得到的红色fit曲线，更接近目标函数，它的阶数要更低一些。那么问题就变成了我们要把高阶（10阶）的hypothesis sets转换为低阶（2阶）的hypothesis sets。</p><p>不同阶数的hypothesis存在如下包含关系：</p><p><img src="https://i.loli.net/2018/07/24/5b57424cddae5.png" alt="img"></p><p>我们发现10阶多项式hypothesis sets里包含了2阶多项式hypothesis sets的所有项，那么在$H_{10}$中加入一些限定条件，使它近似为$H_2$即可。这种函数近似曾被称之为<strong>不适定问题（ill-posed problem）</strong>。</p><p>如何从10阶转换为2阶呢？首先，$H_{10}$可表示为：</p><script type="math/tex; mode=display">H_{10}=w_0+w_1x+w_2x^2+w_3x^3+\cdots+w_{10}x^{10}</script><p>而H_2可表示为：</p><script type="math/tex; mode=display">H_2=w_0+w_1x+w_2x^2</script><p>所以，如果限定条件是$w_3=w_4=\cdots=w_{10}=0$，那么就有$H_2=H_{10}$。也就是说，<strong>对于高阶的hypothesis，为了防止过拟合，我们可以将其高阶部分的权重w限制为0，这样，就相当于从高阶的形式转换为低阶，fit波形更加平滑，不容易发生过拟合。</strong></p><p><a href="https://i.loli.net/2018/07/24/5b5742587fdec.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/07/24/5b5742587fdec.png" alt="img"></a></p><p>那有一个问题，令$H_{10}$高阶权重$w$为0，为什么不直接使用$H_2$呢？这样做的目的是拓展我们的视野，为即将讨论的问题做准备。</p><p>刚刚我们讨论的限制是$H_{10}$高阶部分的权重$w$限制为0，这是比较苛刻的一种限制。下面，我们把这个限制条件变得更宽松一点，即令任意8个权重$w$为0，并不非要限定$w_3=w_4=\cdots=w_{10}=0$，这个Looser Constraint可以写成：</p><script type="math/tex; mode=display">\sum_{q=0}^{10}[[w_q\neq0]]\leq3</script><p>也就只是限定了$w$不为0的个数，并不限定必须是高阶的w。这种hypothesis记为$H_2^′$，称为<strong>sparse hypothesis set</strong>，它与$H_2$和$H_{10}$的关系为：</p><script type="math/tex; mode=display">H_2\subset H_2’\subset H_{10}</script><p>Looser Constraint对应的hypothesis应该更好解一些，但事实是sparse hypothesis set $H_2^′$被证明也是NP-hard，求解非常困难。所以，还要转换为另一种易于求解的限定条件。</p><p>那么，我们寻找一种更容易求解的宽松的限定条件Softer Constraint，即：</p><script type="math/tex; mode=display">\sum_{q=0}^{10}w_q^2=||w||^2\leq C</script><p>其中，$C$是常数，也就是说，所有的权重$w$的平方和的大小不超过$C$，我们把这种hypothesis sets记为$H(C)$。</p><p>$H_2^′$与$H(C)$的关系是，它们之间有重叠，有交集的部分，但是没有完全包含的关系，也不一定相等。对应$H(C)$，$C$值越大，限定的范围越大，即越宽松：</p><script type="math/tex; mode=display">H(0)\subset H(1.126)\subset \cdots \subset H(1126)\subset \cdots \subset H(\infty)=H_{10}</script><p>当$C$无限大的时候，即限定条件非常宽松，相当于没有加上任何限制，就与$H_{10}$没有什么两样。$H(C)$<strong>称为regularized hypothesis set</strong>，这种形式的限定条件是可以进行求解的，我们把求解的满足限定条件的权重$w$记为$w_{REG}$。接下来就要探讨如何求解$w_{REG}$。</p><h3 id="Weight-Decay-Regularization"><a href="#Weight-Decay-Regularization" class="headerlink" title="Weight Decay Regularization"></a>Weight Decay Regularization</h3><p>现在，针对H(c)，即加上限定条件，我们的问题变成：</p><p><img src="https://i.loli.net/2018/07/24/5b574276c5ab2.png" alt="img"></p><p>我们的目的是计算$E_{in}(w)$的最小值，限定条件是$||w^2||\leq C$。这个限定条件从几何角度上的意思是，权重$w$被限定在半径为$\sqrt C$的圆内，而球外的$w$都不符合要求。</p><p>用矩阵来表达：</p><p><img src="https://i.loli.net/2018/07/24/5b5742869f669.png" alt="img"></p><p>下面用一张图来解释在限定条件下，最小化$E_{in}(w)$的过程：</p><p><a href="https://i.loli.net/2018/07/24/5b57429140f3c.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/07/24/5b57429140f3c.png" alt="img"></a></p><p>如上图所示，假设在空间中的一点$w$，根据梯度下降算法，$w$会朝着$-\nabla E_{in}$的方向移动（图中蓝色箭头指示的方向），在没有限定条件的情况下，$w$最终会取得最小值$w_{lin}$，即“谷底”的位置。</p><p>现在，加上限定条件，即$w$被限定在半径为$\sqrt C$的圆内，如图中红色圆圈所示$w^Tw=C$。那么，这种情况下，$w$不能到达$w_{lin}$的位置，最大只能位于圆上，沿着圆的切线方向移动（图中绿色箭头指示的方向）。</p><p>与绿色向量垂直的向量（图中红色箭头指示的方向）是圆切线的法向量，即$w$的方向。</p><p><strong>那么随着迭代优化过程，只要$-\nabla E_{in}$与$w$方向不平行，那么根据向量知识，$-\nabla E_{in}$一定在$w$点切线方向上有不为零的分量，即$w$点会继续移动</strong>。只有当$-\nabla E_{in}$与红色法向量平行的时候，$-\nabla E_{in}$在切线方向上没有不为零的分量了，也就表示这时$w$达到了最优解的位置。</p><p>有了这个平行的概念，我们就得到了获得最优解需要满足的性质：</p><script type="math/tex; mode=display">\nabla E_{in}(w_{REG})+\frac{2\lambda}{N}w_{REG}=0</script><p>上面公式中的$\lambda$<strong>称为Lagrange multiplier，是用来解有条件的最佳化问题常用的数学工具</strong>，$\frac2N$是方便后面公式推导。那么我们的目标就变成了求解满足上面公式的$w_{REG}$。</p><p>之前我们推导过，线性回归的$E_{in}$的表达式为：</p><script type="math/tex; mode=display">E_{in}=\frac1N\sum_{n=1}^N(x_n^Tw-y_n)^2</script><p>计算$E_{in}$梯度，并代入到平行条件中，得到：</p><script type="math/tex; mode=display">\frac2N(Z^TZw_{REG}-Z^Ty)+\frac{2\lambda}Nw_{REG}=0</script><p>这是一个线性方程式，直接得到$w_{REG}$为：</p><script type="math/tex; mode=display">w_{REG}=(Z^TZ+\lambda I)^{-1}Z^Ty</script><p>上式中包含了求逆矩阵的过程，因为$Z^TZ$是半正定矩阵，如果$\lambda$大于零，那么$Z^TZ+\lambda I$一定是正定矩阵，即一定可逆。统计学上把这叫做<strong>ridge regression</strong>，可以看成是linear regression的进阶版。</p><p>如果对于更一般的情况，例如逻辑回归问题中，$\nabla E_{in}$不是线性的，那么将其代入平行条件中得到的就不是一个线性方程式，$w_{REG}$不易求解。下面我们从另一个角度来看一下平行等式：</p><script type="math/tex; mode=display">\nabla E_{in}(w_{REG})+\frac{2\lambda}{N}w_{REG}=0</script><p>已知$\nabla E_{in}$是$E_{in}$对$w_{REG}$的导数，而$\frac{2\lambda}{N}w_{REG}$也可以看成是$\frac{\lambda}Nw_{REG}^2$的导数。那么平行等式左边可以看成一个函数的导数，导数为零，即求该函数的最小值。也就是说，问题转换为最小化该函数：</p><script type="math/tex; mode=display">E_{aug}(w)=E_{in}(w)+\frac{\lambda}Nw^Tw</script><p>该函数中第二项就是限定条件regularizer，也称为weight-decay regularization。我们把这个函数称为<strong>Augmented Error</strong>，即$E_{aug}(w)$。</p><p>如果$\lambda$不为零，对应于加上了限定条件，若$\lambda$等于零，则对应于没有任何限定条件，问题转换成之前的最小化$E_{in}(w)$。</p><p>下面给出一个曲线拟合的例子，$\lambda$取不同的值时，得到的曲线也不相同：</p><p><img src="https://i.loli.net/2018/07/24/5b5742b7058e4.png" alt="img"></p><p>从图中可以看出，当$\lambda=0$时，发生了过拟合；当$\lambda=0.0001$时，拟合的效果很好；当$\lambda=0.01$和$\lambda=1$时，发生了欠拟合。我们可以把$\lambda$看成是一种penality，即对hypothesis复杂度的惩罚，<strong>$\lambda$越大，$w$就越小，对应于$C$值越小，即这种惩罚越大，拟合曲线就会越平滑，高阶项就会削弱，容易发生欠拟合。</strong>$\lambda$一般取比较小的值就能达到良好的拟合效果，过大过小都有问题，但究竟取什么值，要根据具体训练数据和模型进行分析与调试。</p><p><img src="https://i.loli.net/2018/07/24/5b5742c5c7df3.png" alt="img"></p><p>事实上，这种regularization不仅可以用在多项式的hypothesis中，还可以应用在logistic regression等其他hypothesis中，都可以达到防止过拟合的效果。</p><p>我们目前讨论的多项式是形如$x,x^2,x^3,\cdots,x^n$的形式，若x的范围限定在[-1,1]之间，那么可能导致$x^n$相对于低阶的值要小得多，则其对于的$w$非常大，相当于要给高阶项设置很大的惩罚。为了避免出现这种数据大小差别很大的情况，可以使用<strong>Legendre Polynomials</strong>代替$x,x^2,x^3,\cdots,x^n$这种形式，Legendre Polynomials各项之间是正交的，用它进行多项式拟合的效果更好。关于Legendre Polynomials的概念这里不详细介绍。</p><h3 id="Regularization-and-VC-Theory"><a href="#Regularization-and-VC-Theory" class="headerlink" title="Regularization and VC Theory"></a>Regularization and VC Theory</h3><p>下面我们研究一下Regularization与VC理论之间的关系。Augmented Error表达式如下：</p><script type="math/tex; mode=display">E_{aug}(w)=E_{in}(w)+\frac{\lambda}Nw^Tw</script><p>VC Bound表示为：</p><script type="math/tex; mode=display">E_{out}(w)\leq E_{in}(w)+\Omega(H)</script><p><strong>其中$w^Tw$表示的是单个hypothesis的复杂度，记为$\Omega(w)$；而$\Omega(H)$表示整个hypothesis set的复杂度。</strong></p><p><strong>根据Augmented Error和VC Bound的表达式，$\Omega(w)$包含于$\Omega(H)$之内，所以，$E_{aug}(w)$比$E_{in}$更接近于$E_{out}$，即更好地代表$E_{out}$，$E_{aug}(w$)与$E_{out}$之间的误差更小。</strong></p><p><img src="https://i.loli.net/2018/07/24/5b5742dfcb9c4.png" alt="img"></p><p>根据VC Dimension理论，整个hypothesis set的$d_{VC}=\breve d+1$，这是因为所有的$w$都考虑了，没有任何限制条件。而引入限定条件的$d_{VC}(H(C))=d_{EFF}(H,A)$，即有效的VC dimension。也就是说，$d_{VC}(H)$比较大，因为它代表了整个hypothesis set，但是$d_{EFF}(H,A)$比较小，因为由于regularized的影响，<strong>限定了$w$只取一小部分</strong>。其中A表示regularized算法。当$\lambda \gt 0$时，有：</p><script type="math/tex; mode=display">d_{EFF}(H,A)\leq d_{VC}</script><p>这些与实际情况是相符的，比如对多项式拟合模型，<strong>当$\lambda=0$时，所有的$w$都给予考虑，相应的$d_{VC}$很大，容易发生过拟合。当$\lambda$&gt;0且越来越大时，很多$w$将被舍弃，$d_{EFF}(H,A)$减小，拟合曲线越来越平滑，容易发生欠拟合。</strong></p><h3 id="General-Regularizers"><a href="#General-Regularizers" class="headerlink" title="General Regularizers"></a>General Regularizers</h3><p>那么通用的Regularizers，即$\Omega(w)$，应该选择什么样的形式呢？一般地，我们会朝着目标函数的方向进行选取。有三种方式：</p><ul><li><p><strong>target-dependent</strong>：依据目标函数设定</p></li><li><p><strong>plausible</strong>：平滑</p></li><li><p><strong>friendly</strong>：方便优化</p></li></ul><p><img src="https://i.loli.net/2018/07/24/5b5742fb6b430.png" alt="img"></p><p>其实这三种方法跟之前error measure类似，其也有三种方法：</p><ul><li><p><strong>user-dependent</strong></p></li><li><p><strong>plausible</strong></p></li><li><p><strong>friendly</strong></p></li></ul><p>regularizer与error measure是机器学习模型设计中的重要步骤。</p><p>接下来，介绍两种Regularizer：L2和L1。</p><p>L2 Regularizer一般比较通用，其形式如下：</p><script type="math/tex; mode=display">\Omega(w)=\sum_{q=0}^Qw_q^2=||w||_2^2</script><p>这种形式的regularizer计算的是$w$的平方和，是凸函数，比较平滑，易于微分，容易进行最优化计算。</p><p>L1 Regularizer的表达式如下：</p><script type="math/tex; mode=display">\Omega(w)=\sum_{q=0}^Q|w_q|=||w||_1</script><p>L1计算的不是w的平方和，而是绝对值和，即长度和，也是凸函数。已知$w^Tw=C$围成的是圆形，而$||w||_1=C$围成的是正方形，那么在正方形的四个顶点处，是<strong>不可微分</strong>的（不像圆形，处处可微分）。根据之前介绍的平行等式推导过程，对应这种正方形，<strong>它的解大都位于四个顶点处</strong>，若$-\nabla E_{in}$不与其平行，那么$w$就会向顶点处移动，顶点处的许多$w$分量为零，所以，L1 Regularizer的解是稀疏的，称为sparsity。优点是计算速度快。</p><p><img src="https://i.loli.net/2018/07/24/5b57432c1e60a.png" alt="img"></p><p>下面来看一下$\lambda$如何取值，首先，若stochastic noise不同，那么一般情况下，$\lambda$取值有如下特点：</p><p><img src="https://i.loli.net/2018/07/24/5b57433f1809c.png" alt="img"></p><p>从图中可以看出，stochastic noise越大，$\lambda$越大。</p><p>另一种情况，不同的deterministic noise，$\lambda$取值有如下特点：</p><p><img src="https://i.loli.net/2018/07/24/5b5743534e379.png" alt="img"></p><p>从图中可以看出，deterministic noise越大，$\lambda$越大。</p><p>以上两种noise的情况下，都是noise越大，相应的$\lambda$也就越大。这也很好理解，如果在开车的情况下，路况也不好，即noise越多，那么就越会踩刹车，这里踩刹车指的就是regularization。但是大多数情况下，noise是不可知的，这种情况下如何选择$\lambda$？这部分内容，我们下节课将会讨论。</p><h2 id="L15-Validation"><a href="#L15-Validation" class="headerlink" title="L15 Validation"></a>L15 Validation</h2><p>如何保证训练的模型具有良好的泛化能力？</p><h3 id="Model-Selection-Problem"><a href="#Model-Selection-Problem" class="headerlink" title="Model Selection Problem"></a>Model Selection Problem</h3><p>机器学习模型建立的过程中有许多选择，不同的选择搭配，有不同的机器学习效果。我们的目标就是找到最合适的选择搭配，构建最佳的机器学习模型。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/1-4.png" alt="img"></p><p>假设有$M$个模型，对应有$H_1,H_2,\cdots,H_M$，即有$M$个hypothesis set，演算法为$A_1,A_2,\cdots,A_M$，共$M$个。我们的目标是从这$M$个hypothesis set中选择一个模型$H_{m^<em>}$，通过演算法$A_{m^</em>}$对样本集$D$的训练，得到一个最好的矩$g_{m^<em>}$，使其$E_{out}(g_{m^</em>})$最小。所以，问题的关键就是机器学习中<strong>如何选择到最好的矩$g_{m^*}$。</strong></p><ul><li><p>方法一：对$M$个模型分别计算使$E_{in}$最小的矩$g$，再横向比较，取其中<strong>能使$E_{in}$最小</strong>的模型的矩$g_{m^*}$：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-3.png" alt="img"></p><p>但是$E_{in}$足够小并不能表示模型好，反而<strong>可能表示训练的矩$g_{m^*}$发生了过拟合</strong>，泛化能力很差。而且这种“模型选择+学习训练”的过程，它的VC Dimension是$d_{VC}(H_1\cup H_2)$，模型复杂度增加。总的来说，泛化能力差，用$E_{in}$来选择模型是不好的。</p></li><li><p>方法二：如果有这样一个独立于训练样本的测试集，将$M$个模型在测试集上进行测试，选取$E_{test}$<strong>最小</strong>的模型作为最佳模型：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-3.png" alt="img"></p><p>这种测试集验证的方法，根据finite-bin Hoffding不等式，可以得到：</p><script type="math/tex; mode=display">E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O(\sqrt \frac{log M}{N_{test}})</script><p>由上式可以看出，模型个数$M$越少，测试集数目越大，那么$O(\sqrt \frac{log M}{N_{test}})$越小，即$E_{test}(g_{m^<em>})$越接近于$E_{out}(g_{m^</em>})$。</p></li></ul><p>比较这两种方法：</p><ul><li><p>第一种方法使用$E_{in}$作为判断基准，使用的数据集就是训练集$D$本身；不仅使用$D$来训练不同的$g_m$，而且又使用$D$来选择最好的$g_{m^<em>}$，那么$g_{m^</em>}$对未知数据并不一定泛化能力好。举个例子，这相当于老师用学生做过的练习题再来对学生进行考试，那么即使学生得到高分，也不能说明他的学习能力强。所以最小化$E_{in}$的方法并不科学。</p></li><li><p>第二种方法使用$E_{test}$作为判断基准，使用的是独立于训练集$D$之外的测试集。相当于新的考试题能更好地反映学生的真实水平，所以最小化$E_{test}$更加理想。</p></li><li><p>但是，我们拿到的都是训练集$D$，测试集是拿不到的。所以，寻找一种折中的办法，<strong>我们可以使用已有的训练集$D$来创造一个验证集validation set，即从$D$中划出一部分$D_{val}$作为验证集</strong>。$D$另外的部分作为训练集，$D_{val}$独立开来，用来测试各个模型的好坏，最小化$E_{val}$，从而选择最佳的$g_{m^*}$。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/4-1.png" alt="img"></p></li></ul><h3 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h3><p>从训练集$D$中抽出一部分$K$个数据作为验证集$D_{val}$，前提是保证$D_{val}$独立同分布(iid)于$P(x,y)$，也就是说$D_{val}$的选择是从$D$中平均随机抽样得到的。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/5-1.png" alt="img"></p><p>$D$中去除$D_{val}$后的数据就是供模型选择的训练数据$D_{train}$，其大小为$N-k$。</p><p>使用$D_{train}$训练模型，得到$g_m^-$，使用$g_m^-$对$D_{val}$进行验证，得到如下Hoffding不等式：</p><script type="math/tex; mode=display">E_{out}(g_m^-)\leq E_{val}(g_m^-)+O(\sqrt \frac{log M}{K})</script><p>假设有$M$种模型hypothesis set，$D_{val}$的数量为$K$，那么从每种模型$m$中得到一个在$D_{val}$上表现最好的矩，再横向比较，从$M$个矩中选择一个最好的$m^*$作为我们最终得到的模型。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/6-1.png" alt="img"></p><p>现在由于数量为$N$的总样本$D$的一部分$K$作为验证集，那么只有$N-k$个样本可供训练。从$D_{train}$中得到最好的$g_{m^<em>}^-$，而总样本$D$对应的最好的矩为$g_{m^</em>}$。根据之前的leraning curve很容易知道，<strong>训练样本越多，得到的模型越准确，其hypothesis越接近target function</strong>，即$D$的$E_{out}$比$D_{train}$的$E_{out}$要小：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/7-2.png" alt="img"></p><p>所以，我们通常的做法是通过$D_{val}$来选择最好的矩$g_{m^<em>}^-$对应的模型$m^</em>$，再<strong>对整体样本集$D$使用该模型进行训练</strong>，最终得到最好的矩$g_{m^*}$。</p><p>总结使用验证集进行模型选择的整个过程：</p><ul><li>先将$D$分成两个部分，一个是训练样本$D_{train}$，一个是验证集$D_{val}$</li><li>若有$M$个模型，那么分别对每个模型在$D_{train}$上进行训练，得到矩$g_{m}^-$</li><li>再用$D_{val}$对每个$g_{m}^-$进行验证，选择表现最好的矩记为$g_{m^*}^-$</li><li>最后使用该模型对整个$D$进行训练，得到最终的$g_{m^*}$。</li></ul><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/9-2.png" alt="img"></p><p>不等式关系满足：</p><script type="math/tex; mode=display">E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O(\sqrt \frac{log M}{K})</script><p>下面我们举个例子来解释这种模型选择的方法的优越性：</p><p>假设有两个模型：一个是5阶多项式$H_{\Phi_5}$，一个是10阶多项式$H_{\Phi_{10}}$。通过不使用验证集和使用验证集两种方法对模型选择结果进行比较：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/10-2.png" alt="img"></p><p>图中，横坐标表示验证集的样本数量$K$，纵坐标表示$E_{out}$大小。</p><ul><li>黑色水平线表示没有验证集，完全使用$E_{in}$进行判断基准。这种方法的$E_{out}$较大，而且与$K$无关。</li><li>黑色虚线表示测试集非常接近实际数据，这是一种理想的情况，$E_{out}$很小，与$K$无关，实际中很难得到这条虚线。</li><li>红色曲线表示使用验证集，但是最终选取的矩是$g_{m^<em>}^-$，其趋势是随着$K$的增加，它对应的$E_{out}$先减小再增大，当$K$大于一定值的时候，甚至会超过黑色水平线。这是因为随着$K$的增大，$D_{val}$增大，但可供模型训练的$D_{train}$在减小，那得到的$g_{m^</em>}^-$不具有很好的泛化能力。</li><li>蓝色曲线表示也使用验证集，最终选取的矩是$g_{m^*}$，其趋势是随着$K$的增加，它对应的$E_{out}$先缓慢减小再缓慢增大，且一直位于红色曲线和黑色直线之下。从此可见，蓝色曲线对应的方法最好，符合我们之前讨论的使用验证集进行模型选择效果最好。</li></ul><p>那么，如何设置验证集K值的大小呢？</p><ul><li>当$K$值很大时，$E_{val}\approx E_{out}$，但是$g_{m}^-$与$g_m$相差很大；</li><li>当$K$值很小时，$g_m^-\approx g_m$，但是$E_{val}$与$E_{out}$可能相差很大。</li></ul><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/11-1.png" alt="img"></p><p>所以有个折中的办法，通常设置$k=\frac N5$。值得一提的是，划分验证集，通常并不会增加整体时间复杂度，反而会减少，因为$D_{train}$减少了。</p><h3 id="Leave-One-Out-Cross-Validation"><a href="#Leave-One-Out-Cross-Validation" class="headerlink" title="Leave-One-Out Cross Validation"></a>Leave-One-Out Cross Validation</h3><p>假如考虑一个极端的例子，$K=1$，也就是说验证集大小为1，每次只用一组数据对$g_m$进行验证。这样做的优点是$g_m^-\approx g_m$，但是$E_{val}$与$E_{out}$可能相差很大。</p><p>为了避免$E_{val}$与$E_{out}$相差很大，<strong>每次从$D$中取一组作为验证集，直到所有样本都作过验证集</strong>，共计算$N$次，最后对验证误差求平均，得到$E_{loocv}(H,A)$，这种方法称之为<strong>留一法交叉验证</strong>，表达式为：</p><script type="math/tex; mode=display">E_{loocv}(H,A)=\frac1N\sum_{n=1}^Ne_n=\frac1N\sum_{n=1}^Nerr(g_n^-(x_n),y_n)</script><p>这样求平均的目的是为了让$E_{loocv}(H,A)$尽可能地接近$E_{out}(g)$。</p><p>下面用一个例子图解留一法的过程：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/12-2.png" alt="img"></p><p>如上图所示，要对二维平面上的三个点做拟合，上面三个图表示的是线性模型，下面三个图表示的是常数模型。对于两种模型，分别使用留一交叉验证法来计算$E_{loocv}$，<strong>计算过程都是每次将一个点作为验证集，其他两个点作为训练集，最终将得到的验证误差求平均值</strong>，就得到了$E_{loocv}(linear)$和$E_{loocv}(constant)$，比较两个值的大小，取值小对应的模型即为最佳模型。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/13-1.png" alt="img"></p><p>接下来，我们从理论上分析<strong>Leave-One-Out方法的可行性</strong>，即$E_{loocv}(H,A)$是否能保证$E_{out}$的矩足够好？</p><p>假设有不同的数据集$D$，它的期望分布记为$\varepsilon_D$，则其$E_{loocv}(H,A)$可以通过推导，等于$E_{out}(N-1)$的平均值。由于$N-1$近似为$N$，$E_{out}(N-1)$的平均值也近似等于$E_{out}(N)$的平均值。具体推导过程如下：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/14-2.png" alt="img"></p><p>最终我们得到的结论是$E_{loocv}(H,A)$的期望值和$E_{out}(g^-)$的期望值是相近的，这代表得到了比较理想的$E_{out}(g)$，Leave-One-Out方法是可行的。</p><p>举一个例子，使用两个特征：Average Intensity和Symmetry加上这两个特征的非线性变换（例如高阶项）来进行手写数字识别。平面特征分布如下图所示：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/15-1.png" alt="img"></p><p>Error与特征数量的关系如下图所示：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/16-1.png" alt="img"></p><p>从图中我们看出，随着特征数量的增加，$E_{in}$不断减小，$E_{out}$先减小再增大，虽然$E_{in}$是不断减小的，但是它与的差距$E_{out}$越来越大，发生了过拟合，泛化能力太差。</p><p>而$E_{cv}$与$E_{out}$的分布基本一致，能较好地反映$E_{out}$的变化。所以，我们只要使用Leave-One-Out方法得到使$E_{cv}$最小的模型，就能保证其$E_{out}$足够小。</p><h3 id="V-Fold-Cross-Validation"><a href="#V-Fold-Cross-Validation" class="headerlink" title="V-Fold Cross Validation"></a>V-Fold Cross Validation</h3><p>Leave-One-Out可能的问题：</p><ul><li>计算量，假设$N=1000$，那么就需要计算1000次的$E_{loocv}$，再计算其平均值。当$N$很大的时候，计算量是巨大的，很耗费时间。</li><li>稳定性，例如对于二分类问题，取值只有0和1两种，预测本身存在不稳定的因素，那么对所有的$E_{loocv}$计算平均值可能会带来很大的数值跳动，稳定性不好。</li></ul><p>所以，这两个因素决定了Leave-One-Out方法在实际中并不常用。</p><p>针对Leave-One-Out的缺点，我们对其作出了改进。将$N$个数据分成$V$份（例如V=10），计算过程与Leave-One-Out相似。这样可以减少总的计算量，又能进行交叉验证，得到最好的矩，这种方法称为<strong>V-折交叉验证</strong>。其实Leave-One-Out就是V-折交叉验证的一个极端例子。</p><script type="math/tex; mode=display">E_{cv}(H,A)=\frac1V\sum_{v=1}^VE_{val}^{(V)}(g_V^-)</script><p>所以，<strong>一般的Validation使用V-折交叉验证来选择最佳的模型</strong>。</p><p>值得一提的是Validation的数据来源也是样本集中的，所以并不能保证交叉验证的效果好，它的模型一定好。只有样本数据越多，越广泛，那么Validation的结果越可信，其选择的模型泛化能力越强。</p><h2 id="L16-Three-Learning-Principles"><a href="#L16-Three-Learning-Principles" class="headerlink" title="L16 Three Learning Principles"></a>L16 Three Learning Principles</h2><h3 id="Occam’s-Razor"><a href="#Occam’s-Razor" class="headerlink" title="Occam’s Razor"></a>Occam’s Razor</h3><p>奥卡姆剃刀定律（Occam’s Razor）：“切勿浪费较多东西去做用较少的东西同样可以做好的事情。” “如无必要，勿增实体”，就像剃刀一样，将不必要的部分去除掉。</p><p>Occam’s Razor反映到机器学习领域中，指的是在所有可能选择的模型中，我们应该<strong>选择能够很好地解释已知数据并且十分简单的模型</strong>。</p><p>问题：什么模型称得上是简单的？为什么简单模型比复杂模型要好？</p><ul><li><p><strong>什么模型称得上是简单的？</strong></p><ul><li><p><strong>简单的hypothesis $h$</strong>，简单的hypothesis就是指<strong>模型使用的特征比较少</strong>，例如多项式阶数比较少。</p></li><li><p><strong>模型$H$包含的hypothesis数目有限</strong>，不会太多，这也是简单模型包含的内容。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/2-4.png" alt="img"></p></li></ul><p>simple hypothesis $h$和simple model $H$是紧密联系的。如果hypothesis的特征个数是$l$，那么$H$中包含的hypothesis个数就是$2^l$，也就是说，hypothesis特征数目越少，$H$中hypothesis数目也就越少。</p><p>所以，为了让模型简单化，我们可以<strong>一开始就选择简单的model，或者用regularization，让hypothesis中参数个数减少</strong>，都能降低模型复杂度。</p></li><li><p>为什么简单模型比复杂模型要好？</p><p>机器学习的目的是“找规律”，即分析数据的特征，总结出规律性的东西出来。</p><p>假设现在有一堆没有规律的杂乱的数据需要分类，要找到一个模型，让它的$E_{in}=0$是很难的。但是如果是很复杂的模型，也有可能将其分开。如果使用某种简单的模型就可以将数据分开，那表明数据本身应该符合某种规律性。相反地，<strong>如果用很复杂的模型将数据分开，并不能保证数据本身有规律性存在，也有可能是杂乱的数据，因为无论是有规律数据还是杂乱数据，复杂模型都能分开。</strong>这就不是机器学习模型解决的内容了。所以，模型选择中，我们应该尽量先选择简单模型，例如最简单的线性模型。</p></li></ul><h3 id="Sampling-Bias"><a href="#Sampling-Bias" class="headerlink" title="Sampling Bias"></a>Sampling Bias</h3><p>抽样的样本会影响到结果。如果抽样有偏差的话，那么学习的结果也产生了偏差，这种情形称之为抽样偏差Sampling Bias。</p><p>从技术上来说，就是训练数据和验证数据要服从同一个分布，最好都是独立同分布的，这样训练得到的模型才能更好地具有代表性。</p><h3 id="Data-Snooping"><a href="#Data-Snooping" class="headerlink" title="Data Snooping"></a>Data Snooping</h3><p>之前的课程，我们介绍过在模型选择时应该尽量避免偷窥数据，因为这样会使我们人为地倾向于某种模型，而不是根据数据进行随机选择。所以，$\Phi$应该自由选取，最好不要偷窥到原始数据，这会影响我们的判断。</p><p>事实上，数据偷窥发生的情况有很多，不仅仅指我们看到了原始数据。什么意思呢？其实，当你在使用这些数据的任何过程，都是间接地偷看到了数据本身，然后你会进行一些模型的选择或者决策，这就增加了许多的model complexity，也就是引入了污染。</p><p>下面举个例子来说明。假如我们有8年的货比交易数据，我们希望从这些数据中找出规律，来预测货比的走势。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/3-2.png" alt="img"></p><p>现在有两种训练模型的方法：</p><ul><li>一种是使用前6年数据进行模型训练，后2年数据作为测试，图中蓝色曲线表示后2年的预测收益；</li><li>另一种是直接使用8年数据进行模型训练，图中红色曲线表示后2年的预测收益情况。</li></ul><p>很明显，使用8年数据进行训练的模型对后2年的预测的收益更大，似乎效果更好。但是这是一种自欺欺人的做法，<strong>因为训练的时候已经拿到了后2年的数据，用这样的模型再来预测后2年的走势是不科学的</strong>。这种做法也属于间接偷窥数据的行为。直接偷窥和间接偷窥数据的行为都是不科学的做法，并不能表示训练的模型有多好。</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/4-2.png" alt="img"></p><p>还有一个偷窥数据的例子，比如对于某个基准数据集$D$，某人对它建立了一个模型$H_1$，并发表了论文。第二个人看到这篇论文后，又会对$D$，建立一个新的好的模型$H_2$。这样，不断地有人看过前人的论文后，建立新的模型。其实，后面人选择模型时，已经被前人影响了，这也是偷窥数据的一种情况。也许你能对$D$训练很好的模型，但是<strong>可能你仅仅只根据前人的模型，成功避开了一些错误，甚至可能发生了overfitting或者bad generalization</strong>。所以，机器学习领域有这样一句有意思的话“If you torture the data long enough, it will confess.”所以，我们不能太“折磨”我们的数据了，否则它只能“妥协”了。</p><p>在机器学习过程中，避免“偷窥数据”非常重要，但实际上，完全避免也很困难。实际操作中，有一些方法可以帮助我们尽量避免偷窥数据：</p><ul><li>第一个方法是“看不见”数据。就是说当我们在选择模型的时候，尽量用我们的经验和知识来做判断选择，而不是通过数据来选择。先选模型，再看数据。</li><li>第二个方法是保持怀疑。就是说时刻保持对别人的论文或者研究成果保持警惕与怀疑，要通过自己的研究与测试来进行模型选择，这样才能得到比较正确的结论。</li></ul><h3 id="Power-of-Three"><a href="#Power-of-Three" class="headerlink" title="Power of Three"></a>Power of Three</h3><p>对16节课做个简单的总结</p><p>首先，我们介绍了跟机器学习相关的三个领域：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/6-2.png" alt="img"></p><p>我们还介绍了三个理论保证：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/7-3.png" alt="img"></p><p>然后，我们又介绍了三种线性模型：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/8-3.png" alt="img"></p><p>同时，我们介绍了三种重要的工具：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/9-3.png" alt="img"></p><p>还有我们本节课介绍的三个锦囊妙计：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/10-3.png" alt="img"></p><p>最后，我们未来机器学习的方向也分为三种：</p><p><img src="http://47.94.229.135/wp-content/uploads/2018/07/11-2.png" alt="img"></p><p>完结~</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LaTeX相关</title>
      <link href="/2020/03/12/latex-xiang-guan/"/>
      <url>/2020/03/12/latex-xiang-guan/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>数据化管理——洞悉零售及电子商务运营Note</title>
      <link href="/2020/03/11/shu-ju-hua-guan-li-dong-xi-ling-shou-ji-dian-zi-shang-wu-yun-ying-note/"/>
      <url>/2020/03/11/shu-ju-hua-guan-li-dong-xi-ling-shou-ji-dian-zi-shang-wu-yun-ying-note/</url>
      
        <content type="html"><![CDATA[<p>如何快速识别真假数值？</p><ul><li>尾数法（首尾法）：只看最后一位数字（第一位数字），尾数（首位数）相互加减乘除后的结果必须满足相应的算术规律。</li><li>数位法：通过位数判断，如4位数乘以3位数的结果应该是6位数或7位数。</li><li>极值法：在求和运算中，最大值能左右运算。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataAnalysis </tag>
            
            <tag> Books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>林轩田《机器学习基石》Note——Part2：Why Can Machines Learn?</title>
      <link href="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part2/"/>
      <url>/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>课程：</p><ul><li><a href="https://www.bilibili.com/video/av12463015" target="_blank" rel="noopener">https://www.bilibili.com/video/av12463015</a></li></ul><p>参考笔记：</p><ul><li><a href="http://redstonewill.com/" target="_blank" rel="noopener">http://redstonewill.com/</a></li><li><a href="https://beader.me/mlnotebook/index.html" target="_blank" rel="noopener">https://beader.me/mlnotebook/index.html</a></li><li><a href="https://me.csdn.net/github_36324732" target="_blank" rel="noopener">https://me.csdn.net/github_36324732</a></li><li><a href="https://zhuanlan.zhihu.com/ml-note" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/ml-note</a></li></ul></blockquote><h1 id="Why-Can-Machines-Learn"><a href="#Why-Can-Machines-Learn" class="headerlink" title="Why Can Machines Learn?"></a>Why Can Machines Learn?</h1><h2 id="VC-Dimension"><a href="#VC-Dimension" class="headerlink" title="VC Dimension"></a>VC Dimension</h2><h3 id="Dichotomy"><a href="#Dichotomy" class="headerlink" title="Dichotomy"></a>Dichotomy</h3><p>从中任意选取一个方程，让这个对进行二元分类，输出一个结果向量，比如对4个点进行预测，输出，这样的一个输出向量我们称它为一个dichotomy。</p><p>我们把一个dichotomy对应的所有直线方程视为一类，则effective number of lines=dichotomy的数量。显然这个dichotomy的数量小于等于所有数据点的排列组合数的，例如下图中画大叉的那幅图对应的排列组合，就不能成为一个dichotomy，因为它们无法由任何一条直线方程产生。如果存在三点共线的情况，则dichotomy的数量会更少。</p><p>2D Perceptrons：</p><p><img src="https://beader.me/mlnotebook/section2/images/4points14lines.png" alt="img"></p><h3 id="Growth-Function"><a href="#Growth-Function" class="headerlink" title="Growth Function"></a>Growth Function</h3><p>成长函数：有效线的数量，描述的是“<strong>最多</strong>”能产生的dichotomy种数。是有限的，以$2^N$为上界。</p><script type="math/tex; mode=display">m_\mathcal H(N)=\max_{x_1,x_2,\cdots,x_N\in\mathcal X}|\mathcal H(x_1,x_2,\cdots,x_N)|</script><p>在确定的情况下，growth function是一个与N相关的函数。以下是几种常见的Hypothesis Set的成长函数。</p><ol><li><p>Positive Rays</p><p><img src="https://beader.me/mlnotebook/section2/images/postive_rays.png" alt="img"></p><p>输入空间为一维实数空间。大于threshold a的预测+1，否则预测-1。</p><p>当N=4时，共能产生5个不同的dichotomies。如下图：</p><p><img src="https://beader.me/mlnotebook/section2/images/positive_rays_dichotomies.png" alt="img"></p><p>成长函数为</p><script type="math/tex; mode=display">m_\mathcal H(N)=N+1</script></li><li><p>Positive Intervals</p><p><img src="https://beader.me/mlnotebook/section2/images/positive_intervals.png" alt="img"></p><p>当N=4时，共能产生11种dichotomies。</p><p><img src="https://beader.me/mlnotebook/section2/images/positive_intervals_dichotomies.png" alt="img"></p><p>成长函数为</p><script type="math/tex; mode=display">m_\mathcal H(N)=C_{N+1}^{2}+1=\frac{1}{2}N^2+\frac{1}{2}N+1</script></li><li><p>Convex Sets</p><p><img src="https://beader.me/mlnotebook/section2/images/convex_sets.png" alt="img"></p><p>任选k个点，在这k个点组成的convex多边形包围内的所有点都预测+1，否则预测-1。这N个点的任意一种排列组合都能成为一个dichotomy。因此Convex Sets的成长函数为：</p><script type="math/tex; mode=display">m_\mathcal H(N)=2^N</script><p>当作用于有N个inputs时，产生的dichotomies数量等于这N个点的排列组合数时（也就是上述这种情况），我们就称这N个inputs被shatter掉了，或者说产生的dichotomies把这N个点的排列组合给shatter了。</p><blockquote><p>shatter 的原意是「打碎」，在此指「N個點的所有(碎片般的)可能情形都被產生了」。</p><p>从打游戏过关的角度去理解：“是把散弹枪，在每个关卡(level N)中，他可以有发小子弹（每发小子弹对应一种dichotomy），而你面临的是个敌人。你得一枪打出去shatter掉所有人。对于这把散弹枪来说，第一关和第二关都还好，第三关6发小子弹shatter不掉8个人，于是它就break了。”</p></blockquote></li></ol><h3 id="Break-Point"><a href="#Break-Point" class="headerlink" title="Break Point"></a>Break Point</h3><p>第一个小于$2^N$的点以及之后的点均是break point。令$k$为最小的那个break point。</p><ol><li>Positive Rays成长函数的break point为2。</li><li>Positive Intervals成长函数的break point为3。</li><li>Convex Sets不管N多大都可以去shatter掉那N个点，因此它的成长函数没有break point。</li><li>2D Perceptrons的break point为4，当N=4时，它不能够shatter，最多只能产生14种dichotomies（而非16种），因此2D Perceptrons成长函数的break point为4。</li></ol><p>因此结合break point和成长函数，猜测：</p><ul><li>没有break point：$m_\mathcal H(N)=2^N$，肯定正确</li><li>k(min break point)：$m_\mathcal H(N)=O(N^{k-1})$，可能是多项式而非指数！（后验证猜想是正确的）</li></ul><h3 id="Restriction-of-Break-Point"><a href="#Restriction-of-Break-Point" class="headerlink" title="Restriction of Break Point"></a>Restriction of Break Point</h3><ul><li>限制：有些成长函数很容易找到，比如前面说到的Positive Rays、Positive Intervals以及Convex Sets；有些则没有那么容易，比如2D perceptrons，我们无法直接看出它的成长函数是什么。</li><li><p>考虑：能否利用break point得到成长函数的upper bound呢？</p></li><li><p>先用例子来看看，当我们完全不知道是什么，只知道它的break point k时，作用于“<strong>最多最多</strong>”可以产生多少个dichotomies。注意这里我用了两个“<strong>最多</strong>”，由于我们无法确切知道成长函数，因此我们用这个break point推算出的这个dichotomies的数量仍然是个高估值，这个高估值实际上是任何break point为k的作用于所真实产生的dichotomies数量的上界 (upper bound)。</p></li><li><p>举例说明，假设我们不知道某个的成长函数，但知道它的break point k=2，那么作用于N=3的时，“<strong>最多最多</strong>”能产生多少种dichotomies？</p><ul><li><p>从k=2我们可以知道，任意2个数据点都不能被shatter，意思就是我产生的dichotomies不能完全包含任何2个数据点所有的排列组合。</p><p><img src="https://beader.me/mlnotebook/section2/images/n3k2d4s.png" alt="img"></p><p>上图右边两列被shatter了。k=2，即任意2个点不能被shatter，因此不可能产生这4种dichotomies。那我们换一个dichotomy试试看。</p><p><img src="https://beader.me/mlnotebook/section2/images/n3k2d4.png" alt="img"></p><p>换了一个dichotomy之后就行了，检查任意的两个点都没有被shatter，看来这4种dichotomies是可以的。</p></li><li><p>5个dichotomies的情形这里就不再画出来了，很容易看出不管增加怎样的dichotomy进去，都会有两个点被shatter掉。因此这里“<strong>最多最多</strong>”只能有4种dichotomies。因此，k=2时的upper bound是4。</p></li></ul></li><li><p>我们用Bounding Function $B(N,k)$来表示：break point为$k$时，任意的作用于size为$N$时，所能产生的dichotomies的数量的上限（“<strong>最多最多</strong>”）。比如刚刚得出的结论可以表示为，当$k=2,N=3$时，$B(N,k)=B(3,2)=4$。</p></li><li><p>从以上可以看出，虽然很多时候我们无法直接得到成长函数，但如果我们知道它的break point是多少，我们似乎还是有办法算出这个的上界的。于是乎我们就有了新的目标，不去直接研究成长函数，转而去研究$B(N,k)$。</p></li></ul><h3 id="Bounding-Function"><a href="#Bounding-Function" class="headerlink" title="Bounding Function"></a>Bounding Function</h3><p>考察$B(N,k)$的取值情况：</p><ul><li>$k=1$时，1个点（2种排列组合）都没有办法shatter，因此恒等于1。</li><li>$k&gt;N$时，一定能shatter掉$2^N$个点，此时无任何条件限制。</li><li>$k=N$时，从所有的排列组合中移除掉一个（否则会shatter掉），剩下的都可以作为dichotomies，因此它产生的dichotomies的数量“<strong>最多最多</strong>”可以是$2^N-1$。</li></ul><p>  因此我们可以得到下表：</p><p><img src="https://beader.me/mlnotebook/section2/images/bnk_table.png" alt="img"></p><p>如何求取其他部分？</p><ul><li><p>以$B(4,3)$为例，采用穷举法得到所有可能的dichotomies：</p><p><img src="https://beader.me/mlnotebook/section2/images/n4k3d11.png" alt="img"></p><p>整理一下后得到：</p><p><img src="https://beader.me/mlnotebook/section2/images/n4k3d11_ordered2.png" alt="img"></p><p>其中橙色的部分是成对的，紫色的部分是单个出现的。</p><p>去掉$x_4$并去重，可以得到：</p><p><img src="https://beader.me/mlnotebook/section2/images/n4k3d7.png" alt="img"></p><p>$\alpha+\beta$部分可以成为这3个点的dichotomies，因为对于$B(4,3)$任3个点不能够被shatter，所以$\alpha+\beta$部分这3个点也不能够被shatter，从而有</p><script type="math/tex; mode=display">\alpha+\beta\le B(3,3)</script><p>再单独观察$\alpha$部分：</p><p><img src="https://beader.me/mlnotebook/section2/images/n4k2_alpha.png" alt="img"></p><p>因为对于$B(4,3)$任3个点不能够被shatter，所以$\alpha$部分这3个点中任2个点也不能够被shatter，从而有</p><script type="math/tex; mode=display">\alpha\le B(3,2)</script></li></ul><p>  结合以上两个结论，可以得出</p><script type="math/tex; mode=display">  B(4,3)=2\alpha+\beta\le B(3,3)+B(3,2)</script><p>  这样就能够把前面那张表给填完整：</p><p>  <img src="https://beader.me/mlnotebook/section2/images/bnk_table_full.png" alt="img"></p><p>  从而得到了Bounding Function的upper bound</p><ul><li><p>可以推广上述结论，得到</p><script type="math/tex; mode=display">B(N,k)\le B(N-1,k)+B(N-1,k-1)</script><p>（可以证明上述不等号其实可以取等号）</p><blockquote><p>思路可以归纳为：</p><p>成长函数（Growth Function）&lt;上限函数（Bounding Function）&lt;上限的上限（Bounding Function的upper bound）（最高次项为$N^{k-1}$的多项式）</p><p>从而证明霍夫丁不等式中的M是有上限的。</p></blockquote></li><li><p>思路总结：上一篇说的learning的可行性，讲到：如果遇上bad sample，与就会差很多，此时learning不可行。遇到bad sample的概率与中方程的数量以及中的数据量有关。然而中方程的数量往往是无穷的（比如2D Perceptrons的是平面上所有的直线），本篇则继续阐述，方程的数量看上去是无穷的，但真正有效(effective)的方程的数量却是有限的，我们可以用成长函数来描述作用于会产生多少种有效的方程。但实际上我们很难确切知道各种的成长函数究竟长什么样子，我们只好通过break point去寻找成长函数的upper bound。</p></li></ul><h3 id="VC-Bound"><a href="#VC-Bound" class="headerlink" title="VC Bound"></a>VC Bound</h3><p>我们设想利用有限的$m_{\mathcal{H}}(N)$来替换无限的大$M$，得到$\mathcal{H}$遇到Bad Sample的概率上界：</p><script type="math/tex; mode=display">\mathbb{P}_\mathcal{D}[BAD\ D]=\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \epsilon]\leq 2m_{\mathcal{H}}(N)\cdot exp(-2\epsilon ^2N)</script><p>其中$\mathbb{P}_\mathcal{D}[BAD\ D]$是$\mathcal{H}$中所有有效的方程(Effective Hypotheses)遇到Bad Sample的联合概率，即$\mathcal{H}$中存在一个方程遇上bad sample，则说$\mathcal{H}$遇上bad sample。</p><p>但事实上上面的不等式是不严谨的，为什么呢？</p><p>$m_{\mathcal{H}}(N)$描述的是$\mathcal{H}$作用于数据量为$N$的资料$\mathcal{D}$，有效的方程数，因此$\mathcal{H}$当中每一个$h$作用于$\mathcal{D}$都能算出一个$E_{in}$来，$E_{in}$的可能取值是一个有限的数。</p><p>但在out of sample的世界里(总体)，往往存在无限多个点，平面中任意一条直线，随便转一转就能产生一个不同的$E_{out}$来。<strong>$E_{in}$的可能取值是有限个的，而$E_{out}$的可能取值是无限的，无法直接套用union bound，我们得先把上面那个无限多种可能的$E_{out}$换掉。</strong>那么如何把$E_{out}$变成有限个呢？</p><ul><li>Step 1: 用$E_{in}^{’}$替换$E_{out}$</li></ul><p>假设我们能从总体当中再获得一份$N$个样本的验证资料(verification set)$\mathcal{D}’$，对于任何一个$h$我们可以算出它作用于$\mathcal{D}’$上的$E_{in}^{’}$。<strong>由于$\mathcal{D}’$也是总体的一个样本，因此如果$E_{in}$和$E_{out}$离很远，有非常大的可能$E_{in}$和$E_{in}^{’}$也会离得比较远。</strong></p><p><img src="https://beader.me/imgs/vc-dimension-two/pdf_of_ein.png" alt="img"></p><p>事实上，当$N$很大的时候，$E_{in}$和$E_{in}^{’}$可以看做服从以$E_{out}$为中心的近似正态分布(Gaussian)，如上图。</p><p>$[|E_{in}-E_{out}|\text{ is large}]$这个事件取决于$\mathcal{D}$，如果$[|E_{in}-E_{out}|\text{ is large}]$，则如果我们从总体中再抽一份$\mathcal{D}^{‘}$出来，有50%左右的可能性会发生$[|E_{in}-E_{in}^{‘}|\text{ is large}]$，还有大约50%的可能$[|E_{in}-E_{in}^{’}|\text{ is not large}]$。</p><p>从而得到下式（没有进行严格的推导）：</p><script type="math/tex; mode=display">\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \varepsilon]\leq 2\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{in}^{'}(h)|\gt \frac{\varepsilon}{2}]</script><p>这样一来我们就把无限多种的$E_{out}$换成了有限多种的$E_{in}^{‘}$。</p><ul><li>Step 2：重新构成$\mathcal{H}$</li></ul><p>因为$\mathcal{D}$与$\mathcal{D}^{’}$的大小相等，都为$N$，因此我们手中一共有$2N$笔数据，这样$\mathcal{H}$作用于$\mathcal{D}+\mathcal{D}^{’}$最多能产生$m_{\mathcal{H}}(2N)$种dichotomies，此时又可以使用union bound了。</p><p><img src="https://i.loli.net/2020/03/13/d8VGeU7pDJL3tsn.png" alt="微信截图_20200313124748.png" style="zoom:67%;"></p><p>用固定的$h$来看$E_{in}$和$E_{in}^{’}$之间的差别：</p><script type="math/tex; mode=display">2\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{in}^{'}(h)|\gt \frac{\varepsilon}{2}] \le 2m_{\mathcal{H}}(2N) \mathbb{P}[\text{fixed h s.t. } |E_{in}(h)-E_{in}^{'}(h)|\gt \frac{\varepsilon}{2}]</script><ul><li>Step 3：使用Hoeffding inequality</li></ul><p>前面的动作相当于先从总体中抽出$2N$笔数据，把这$2N$笔数据当成一个比较小的bin，然后在这个bin中抽取$N$笔作为$\mathcal{D}$，剩下的$N$笔作为$\mathcal{D}^{’}$，$\mathcal{D}$和$\mathcal{D}^{’}$之间是没有交集的。在我们想象出来的这个small bin当中，整个bin的错误率为$\frac{E_{in}+E_{out}}{2}$，又因为：</p><script type="math/tex; mode=display">|E_{in}-E_{in}^{'}|\gt \frac{\epsilon}{2} \Leftrightarrow |E_{in} - \frac{E_{in}+E_{in}^{'}}{2}|\gt \frac{\epsilon}{4}</script><p>所以不等式就又可以使用Hoeffding inequality了：</p><script type="math/tex; mode=display">2m_{\mathcal{H}}(2N) \mathbb{P}[\text{fixed h s.t. } |E_{in}(h)-E_{in}^{'}(h)|\gt \frac{\varepsilon}{2}]\le2m_{\mathcal{H}}(2N)·2\exp(-2(\frac{\epsilon}{4})^2N)</script><p>最终整理得到：</p><script type="math/tex; mode=display">\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \varepsilon]\leq 4m_{\mathcal{H}}(2N)\cdot \exp(-\frac{1}{8}\varepsilon ^2N)</script><p>上式右侧千辛万苦得出来的这个bound就叫做VC Bound。</p><h3 id="VC-Dimension-1"><a href="#VC-Dimension-1" class="headerlink" title="VC Dimension"></a>VC Dimension</h3><p>VC Bound所描述的是在给定数据量N以及给定的Hypothesis Set的条件下，遇到坏事情的概率的上界，即$E_{in}$与$E_{out}$差很远的概率，最多是多少。</p><p>因为寻找所有Hypothesis Set的成长函数是困难的，因此我们再利用$N^{d_{vc}}$来bound住所有VC Dimension为$d_{vc}$的Hypothesis Set的成长函数。所以对于任意一个从$\mathcal{H}$中的$g$来说，如果$k$存在，有：</p><script type="math/tex; mode=display">\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \varepsilon]\leq 4(2N)^{k-1}\cdot \exp(-\frac{1}{8}\varepsilon ^2N)</script><p>因此说想让机器真正学到东西，并且学得好，有三个条件：</p><ol><li>$\mathcal{H}$的$d_{vc}$是有限的，即存在break point $k$，这样VC Bound才存在。(good $\mathcal{H}$)</li><li>$N$足够大(对于特定的$d_{vc}$而言)，这样才能保证上面不等式的bound不会太大。(good $\mathcal{D}$)</li><li>算法$\mathcal{A}$有办法在$\mathcal{H}$中顺利地挑选一个使得$E_{in}$最小的方程$g$。(good $\mathcal{A}$)</li></ol><blockquote><p>为什么要费那么大的力气来讲这个VC Bound和VC Dimension呢？因为对于初学者来说，最常犯的错误就是只考虑到了第3点，而忽略掉了前两点，往往能在training set上得到极好的表现，但是在test set中表现却很烂。关于算法$\mathcal{A}$的部分会在后续的笔记当中整理，目前我们只关心前面两点。</p></blockquote><p>假设空间$\mathcal H$的VC Dimension记为$d_{VC}(\mathcal H)$，是这个假设空间最多能够shatter掉的点的数量。</p><ul><li>如果该假设空间中存在$N$个点能够shatter他们，则$d_{VC}(\mathcal H)\ge N$。</li><li>如果该假设空间中任意$N$个点都不能够shatter他们，则$d_{VC}(\mathcal H)&lt; N$。</li><li>不难看出与break point k的关系，有$k=d_{vc}+1$</li></ul><p>因此我们用下式来描述成长函数的上界（$N\ge 2,d_{VC}\ge 2）$：</p><script type="math/tex; mode=display">m_{\mathcal{H}}(N)\leq \sum_{i=0}^{d_{vc}} \binom {N}{i}</script><p>上式右边事实上是最高项为$d_{vc}$的多项式，利用数学归纳法可得：</p><script type="math/tex; mode=display">m_{\mathcal{H}}(N)\leq \sum_{i=0}^{d_{vc}} \binom {N}{i} \leq N^{d_{vc}}+1</script><p>对于以下几个$\mathcal{H}$，由于之前我们已经知道了他们的成长函数，因此可以根据$m_{\mathcal{H}}(N)\leq N^{d_{vc}}$，直接得到他们的VC Dimension：</p><ul><li>positive rays: $m_{\mathcal{H}}(N)=N+1$，看N的最高次项的次数，知道$d_{vc}=1$</li><li>positive intervals: $m_{\mathcal{H}}(N)=\frac{1}{2}N^2+\frac{1}{2}N+1$，$d_{vc}=2$</li><li>convex sets: $m_{\mathcal{H}}(N)=2^N$，$d_{vc}=\infty$</li><li>2D Perceptrons: $m_{\mathcal{H}}(N)\leq N^3\;for\;N\geq 2$，所以$d_{vc}=3$</li></ul><p>由于convex sets的$d_{vc}=\infty$，不满足上面所说的第1个条件，因此不能用convex sets这个$\mathcal{H}$来学习（不是好的假设空间）。</p><p>但这里要回归本意，通过成长函数来求得$d_{vc}$没有太大的意义，引入$d_{vc}$很大的一部分原因是，我们想要得到某个Hypothesis Set的成长函数是困难的，希望用$N^{d_{vc}}$来bound住对应的$m_{\mathcal{H}}(N)$。对于陌生的$\mathcal{H}$，如何求解它的$d_{vc}$呢？下面用自由度的角度进行解释。</p><p>对于比较简单的模型，可以从它最多能够shatter的点的数量，得到$d_{vc}$，但对于一些较为复杂的模型，寻找能够shatter掉的点的数量，就不太容易了。此时我们可以通过模型的自由度，来近似的得到模型的$d_{vc}$。</p><p>定义自由度是：<strong>模型当中可以自由变动的参数的个数</strong>，即我们的机器需要通过学习来决定模型参数的个数。</p><p>譬如：</p><ul><li>Positive Rays，需要确定1个threshold，这个threshold就是机器需要根据$\mathcal{D}$来确定的一个参数，则Positive Rays中自由的参数个数为1，$d_{vc}=1$</li><li>Positive Intervals，需要确定左右2个thresholds，则可以由机器自由决定的参数的个数为2，$d_{vc}=2$</li><li>d-D Perceptrons，$d$维的感知机，可以由机器通过学习自由决定的参数的个数为$d+1$（别忘了还有个$w_0$），$d_{vc}=d+1$</li></ul><h3 id="Model-Complexity"><a href="#Model-Complexity" class="headerlink" title="Model Complexity"></a>Model Complexity</h3><p>learning的问题应该关注的两个最重要的问题是：</p><ol><li>能不能使$E_{in}$与$E_{out}$很接近；</li><li>能不能使$E_{in}$足够小。</li></ol><ul><li>对于相同的$\mathcal{D}$而言，$d_{vc}$小的模型，其VC Bound比较小，比较容易保证$E_{in}$与$E_{out}$很接近，但较难做到小的$E_{in}$。试想，对于2D Perceptron，如果规定它一定要过原点($d_{vc}=2$)，则它就比没有规定要过原点($d_{vc}=3$)的直线更难实现小的$E_{in}$，因为可选的方程更少。2维平面的直线，就比双曲线($d_{vc}=6$)，更难实现小的$E_{in}$。</li><li>对于相同的$\mathcal{D}$而言，$d_{vc}$大的模型，比较容易实现小的$E_{in}$，但是其VC Bound就会很大，很难保证模型对$\mathcal{D}$之外的世界也能有同样强的预测能力。</li></ul><p>令之前得到的VC Bound为$\delta$，坏事情$[|E_{in}(g)-E_{out}(g)|\gt \varepsilon]$发生的概率小于$\delta$，则好事情$[|E_{in}(g)-E_{out}(g)|\leq \varepsilon]$发生的概率就大于$1-\delta$，这个$1-\delta$在统计学中又被称为置信度，或置信水平。</p><script type="math/tex; mode=display">\mathbb{P}[|E_{in}(h)-E_{out}(h)|\gt \varepsilon]\leq 4(2N)^{d_{vc}}\cdot \exp(-\frac{1}{8}\varepsilon ^2N)=\delta</script><p>因此$E_{in}$、$E_{out}$又有下面的关系：</p><script type="math/tex; mode=display">|E_{in}(h)-E_{out}(h)|\le\sqrt{\frac{8}{N}\ln(\frac{4(2N)^{d_{vc}}}{\delta})}</script><p>令$\Omega (N,\mathcal{H},\delta)=\sqrt{…}$，即上式的根号项为来自模型复杂度的，模型越复杂，$E_{in}$与$E_{out}$离得越远。</p><p><img src="https://beader.me/imgs/vc-dimension-three/model_complexity_curve.png" alt="model_complexity_curve.png"></p><p>随着$d_{vc}$的上升，$E_{in}$不断降低，而$\Omega$项不断上升，他们的上升与下降的速度在每个阶段都是不同的，因此我们能够寻找一个二者兼顾的，比较合适的$d_{vc}^{*}$，用来决定应该使用多复杂的模型。</p><p>反过来，如果我们需要使用$d_{vc}=3$这种复杂程度的模型，并且想保证$\varepsilon = 0.1$，置信度$1-\delta =90\%$，我们也可以通过VC Bound来求得大致需要的数据量$N$。通过简单的计算可以得到理论上，我们需要$N\approx 10,000d_{vc}$笔数据。</p><p>但VC Bound事实上是一个极为宽松的bound，因为它对于任何演算法$\mathcal{A}$，任何分布的数据，任何目标函数$f$都成立，所以经验上，常常认为$N\approx 10d_{vc}$就可以有不错的结果。</p><h2 id="Noise-and-Error"><a href="#Noise-and-Error" class="headerlink" title="Noise and Error"></a>Noise and Error</h2><p>首先我们认为存在一个未知的真理$f$，认为 $\mathcal{D}$中的$y$就是$f$作用于$x$产生的，因此虽然无法直接得到$f$，但若能找到一个和$f$表现差不多的函数，也算是能学到东西。</p><p>但在现实世界中，我们拿到的$\mathcal{D}$并不是完美的，会有noise的存在。在Learning中，noise主要表现为以下几种形式：</p><p>在Learning中，noise主要表现为以下几种形式：</p><ul><li>noise in y : 本来应该是圈圈的，却被标记为叉叉</li><li>noise in y : 输入$\mathcal{X}$完全相同的点，既有被标记圈圈的，也有被标记叉叉的</li><li>noise in x : 输入$\mathcal{X}$本身就存在问题，譬如100被写成了100万</li></ul><p>$f$是一个“确定性”(deterministic)的模型，但$noise$是一个随机发生的东西，他们两个共同作用的结果，就成了一个“概率性”(probabilistic)的东西：</p><p>对于某个样本 $x$，理想状态下，应该有$y=f(x)=+1$，但由于某种noise的存在，该noise会有30%的概率会转换$f(x)$的结果(把+1变成-1或把-1变成+1)。因此在$\mathcal{D}$中，该样本有70%的概率表现出$y=+1$，30%的概率表现出。</p><h3 id="Error-Measure"><a href="#Error-Measure" class="headerlink" title="Error Measure"></a>Error Measure</h3><p>在把learning的工作交给机器的时候，必须让机器明白你学习的目标，譬如你想让什么什么最大化，或者什么什么最小化。通常的做法是把每一个预测值与真实值之间的误差(error)看成一种成本，机器要做的，就是在$\mathcal{H}$中，挑选一个能使总成本最低的函数。</p><p>之前一直说的$E_{in}(h)$，就是$h$作用于$\mathcal{D}$中每一笔数据，所产生的成本之和：</p><script type="math/tex; mode=display">E_{out}(g)=\varepsilon[[g(x)\neq f(x)]]</script><p>这种误差衡量方式称为”pointwise measure”，即对每个点记录误差，总误差为所有点产生的误差之和。</p><p>针对不同的问题与不同的使用环境，我们可以设计不同的误差衡量方法，下面是常见的pointwise误差的定义：</p><ul><li><p>0/1 error ，通常用于分类问题：</p><script type="math/tex; mode=display">err(\widetilde{y},y)=[\widetilde{y}\neq y]</script></li><li><p>squared error，通常用于回归问题：</p><script type="math/tex; mode=display">err(\widetilde{y},y)=(\widetilde{y}-y)^2</script></li><li><p>absolute error：</p><script type="math/tex; mode=display">err(\widetilde{y},y)=|\widetilde{y}-y|</script></li></ul><p>之前提到的二元分类问题，就是对判断错误的点，记误差为1，判断正确的点，记误差为0；不管是把$y=+1$的猜错成$-1$，或是把$y=-1$的猜错成$+1$，其产生的误差都为1。</p><p>但在实际应用中，这个误差的定义可以很灵活，例如下面指纹验证的例子：</p><ul><li><p>中情局的门禁系统，利用指纹判断是内部工作人员，才允许进入。这种情形下，若是把好人当坏人，代价并不高，无非就是请工作人员多按一次指纹的功夫，但如果把坏人当好人，损失可就大了。针对这种需求，下面这个error的衡量办法可能更加合理。</p><p><img src="https://i.loli.net/2020/03/13/InbO4kXmYZaxE7R.png" alt="微信截图_20200313175204.png" style="zoom:50%;"></p><p>其中权重1000可以视为：将$y=-1$时将数据复制了1000倍（过采样），从而也可以转化为等权重的问题</p><p>（随机地重复选取这些$y=-1$的样本1000次）</p></li></ul><p>总结一下，先根据问题的不同选择合适的误差衡量方式，0/1 error还是squared error或者是其他针对某一场景特殊设计的error？把$h$作用于$\mathcal{D}$中所有点的error加总起来就成了一个cost function，也就是$E_{in}(h)$，接着要设计一个最优化算法$\mathcal{A}$，它能够从$\mathcal{H}$中挑选出能够使$E_{in}$最小的方程$g$，learning就完成了。</p><p>对于不同类型的cost function，通常会使用不同的最优化算法。对于某些cost function，很容易实现$E_{in}$最小，但对于某些cost function，寻找最小的$E_{in}$是困难的，比如用0/1 error来衡量误差，要minimize $E_{in}$就是个NP Hard问题。可以将问题转化为求解闭式解、凸优化的问题。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>林轩田《机器学习基石》Note——Part3：How Can Machines Learn?</title>
      <link href="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/"/>
      <url>/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>课程：</p><ul><li><a href="https://www.bilibili.com/video/av12463015" target="_blank" rel="noopener">https://www.bilibili.com/video/av12463015</a></li></ul><p>参考笔记：</p><ul><li><a href="http://redstonewill.com/" target="_blank" rel="noopener">http://redstonewill.com/</a></li><li><a href="https://beader.me/mlnotebook/index.html" target="_blank" rel="noopener">https://beader.me/mlnotebook/index.html</a></li><li><a href="https://me.csdn.net/github_36324732" target="_blank" rel="noopener">https://me.csdn.net/github_36324732</a></li><li><a href="https://zhuanlan.zhihu.com/ml-note" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/ml-note</a></li></ul></blockquote><h1 id="How-Can-Machines-Learn"><a href="#How-Can-Machines-Learn" class="headerlink" title="How Can Machines Learn?"></a>How Can Machines Learn?</h1><p>接下来要讲的就是各种error measurement的区别以及针对它们如何设计最优化的算法。通过设计出来的算法，使得机器能够从$\mathcal{H}$(Hypothesis Set)当中挑选可以使得cost function最小的$h$作为$g$输出。</p><h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><p>本篇以线性回归为例，从方程的形式、误差的衡量方式、如何最小化$E_{in}$的角度出发，并简单分析了Hat Matrix的性质与几何意义。</p><h3 id="方程的形式"><a href="#方程的形式" class="headerlink" title="方程的形式"></a>方程的形式</h3><script type="math/tex; mode=display">h(x)=w^Tx</script><p>和perceptron相差一个sign（perceptron是$h(x)=sign(w^Tx)$）。</p><h3 id="误差的衡量"><a href="#误差的衡量" class="headerlink" title="误差的衡量"></a>误差的衡量</h3><p>平方误差(squared error)：</p><script type="math/tex; mode=display">err(\hat{y},y)=(\hat{y}-y)^2</script><h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h3><script type="math/tex; mode=display">E_{in}(w)=\frac{1}{N}\sum_{n=1}^{N}(h(x_n)-y_n)^2</script><p>$h(x)$是一个以$x$为变量的方程，而$E_{in}(w)$变成了一个以$w$为变量的方程。这样一来，我们就把“在$\mathcal{H}$中寻找能使平均误差最小的方程”这个问题，转换为“求解一个函数的最小值”的问题。使得$E_{in}(w)$最小的$w$，就是我们要寻找的那个最优方程的参数。</p><h3 id="参数求解"><a href="#参数求解" class="headerlink" title="参数求解"></a>参数求解</h3><p>用矩阵形式表示：</p><p>$X$与$y$来源于$\mathcal{D}$，是固定不变的，因此它是一个以$w$为变量的函数。我们需要解使得$E_{in}$最小的$w$，即</p><script type="math/tex; mode=display">\underset{w}{min}\,E_{in}(w)=\frac{1}{N}\begin{Vmatrix}Xw-y\end{Vmatrix}^2</script><p>$E_{in}(w)$是一个连续(continuous)、处处可微(differentiable)的凸函数(convex)：</p><p><img src="https://beader.me/imgs/linear-regression/wlin.png" alt="img"></p><p>对于这一类函数，只需要解其一阶导数为0时的解即可。</p><p>令$\nabla E_{in}(w)=0$，可得最佳解：</p><script type="math/tex; mode=display">w_{LIN}=(X^TX)^{-1}X^Ty</script><ul><li>当$X^TX$可逆的时候，记$(X^TX)^{-1}X^T$为pseudo-inverse（伪逆）矩阵$X^{\dagger}$</li><li>当$X^TX$不可逆的时候，再用其他方式定义$X^{\dagger}$（不展开）</li></ul><h3 id="帽子矩阵"><a href="#帽子矩阵" class="headerlink" title="帽子矩阵"></a>帽子矩阵</h3><p>用以$w_{LIN}$为参数的线性方程对原始数据做预测，可以得到拟合值$\hat{y}=Xw_{LIN}=XX^{\dagger}y$。这里称</p><script type="math/tex; mode=display">H=XX^{\dagger}=X(X^TX)^{-1}X^T</script><p>为Hat Matrix（帽子矩阵）。$H$为$y$带上了帽子，成为$\hat{y}$。</p><h4 id="H-的几何含义"><a href="#H-的几何含义" class="headerlink" title="$H$的几何含义"></a>$H$的几何含义</h4><p><img src="https://beader.me/imgs/linear-regression/geoview_hatmatrix.png" alt="img"></p><p>这张图展示的是在$N$维实数空间$\mathbb{R}^N$中，注意这里是$N$为样本量，$y$为真实值，$\hat{y}$为预测值。$X$中包含$d+1$个column。</p><ul><li>$\hat{y}=Xw_{LIN}$是$X$的一个线性组合，$X$中每个column对应$\mathbb{R}^N$下的一个向量，共有$d+1$个这样的向量，因此$\hat{y}$在这$d+1$个向量所构成的$span$(平面)上。</li><li>事实上我们要做的就是在这个平面上找到一个向量$\hat{y}$使得他与真实值之间的距离$|y-\hat{y}|$最短。不难发现当$\hat{y}$是$\color{purple}{y}$在这个平面上的投影时，即$y-\hat{y}\perp span$时，$|y-\hat{y}|$最短。</li><li><strong>因此Hat Matrix $H$为$y$戴上帽子转化为$\hat{y}$，所做的就是投影这个动作，寻找$span$上$y$的投影。</strong></li><li>$Hy=\hat{y}$，$(I-H)y=y-\hat{y}$。($I$为单位矩阵)</li></ul><h4 id="H-的性质"><a href="#H-的性质" class="headerlink" title="$H$的性质"></a>$H$的性质</h4><ul><li><p>对称性(symetric)，即$H=H^T$</p></li><li><p>幂等性(idempotent)，即$H^2=H$</p></li><li><p>半正定(positive semi-definite)，即所有特征值为非负数：0或1</p></li><li><p>$trace(I-H) = N-(d+1)$。$trace$为矩阵的迹，一个矩阵的$trace$等于该矩阵的所有特征值(Eigenvalues)之和。$X$的维度为$d+1$维。用物理意义来解释这个式子：</p><p><img src="https://beader.me/imgs/linear-regression/geoview_hatmatrix_noise.png" alt="geoview_hatmatrix_noise.png"></p><p>假设$y$由$f(X)\in span+noise$构成的。有$y=f(X)+noise$。</p><p>之前讲到$H$作用于某个向量，会得到该向量在$span$上的投影，而$I-H$作用于某个向量，会得到那条与$span$垂直的向量，在这里就是图中的$y-\hat{y}$，即$(I-H)noise=y-\hat{y}$。这个$y-\hat{y}$是真实值与预测值的差，其长度就是就是所有点的平方误差之和。于是就有：</p><script type="math/tex; mode=display">E_{in}(w_{LIN})=\frac{1}{N}||y-\hat{y}||^2\\=\frac{1}{N}||(I-H)noise||^2=\frac{1}{N}trace(I-H)||noise||^2=\frac{1}{N}(N-(d+1))||noise||^2</script><p>因此，就平均而言，有：</p><script type="math/tex; mode=display">\overline{E_{out}}=\text{noise level}·(1+\frac{d+1}{N})\\\overline{E_{in}}=\text{noise level}·(1-\frac{d+1}{N})</script><p>花这么大力气是为了什么，又回到之前learning可行性的话题了。</p><p><img src="https://beader.me/imgs/linear-regression/linear_regression_learning_curve.png" alt="img" style="zoom:80%;"></p><p>$\overline{E_{in}}$和$\overline{E_{out}}$都向$\sigma ^2$(noise level)收敛，并且他们之间的差异被$\frac{2(d+1)}{N}$给bound住了。虽然与VC Bound不同，VC Bound是通过最差错误概率来推导$E_{in}$与$E_{out}$接近，这里是从平均的角度，仍然能证明线性回归算法能够学习！</p></li></ul><h3 id="线性回归与线性分类"><a href="#线性回归与线性分类" class="headerlink" title="线性回归与线性分类"></a>线性回归与线性分类</h3><p>实际中进行线性分类时，可以先做一个regression来求一个初始化参数值，然后再应用诸如PLA/Pocket这类的算法降低error。这样可以提升分类效率。</p><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>之前提过的二元分类器如PLA，其目标函数为$f(x)=sign(w^Tx)\in\{-1,+1\}$，输出要么是-1要么是+1，是一个硬分类器。而Logistic Regression是一个软分类器，它的输出是$y=+1$的概率，因此Logistic Regression的目标函数是$f(x)=P(+1|x)\in [0,1]$。</p><h3 id="方程形式"><a href="#方程形式" class="headerlink" title="方程形式"></a>方程形式</h3><p>使用</p><script type="math/tex; mode=display">h(x)=\frac{1}{1+e^{-w^Tx}}</script><p>来近似Target Function$f(x)=P(+1|x)$</p><h3 id="误差衡量"><a href="#误差衡量" class="headerlink" title="误差衡量"></a>误差衡量</h3><blockquote><p>为什么不能像Linear Regression一样使用平方误差？</p><p>如果使用平方误差，每个点产生的误差是：</p><script type="math/tex; mode=display">err(h,x_n,y_n)=y_n(1-\theta(w^Tx))^2+(1-y_n)(\theta(w^Tx))^2</script><p>此时cost function，$E_{in}(w)=\sum{err}$就是一个关于$w$的非凸函数(non-convex)：</p><p><img src="https://beader.me/imgs/logistic-regression/non_convex.png" alt="img"></p><p>非凸函数由于存在很多个局部最小点，因此很难去做最优化(解全局最小)。所以Logistic Regression没有使用平方误差来定义error，而是使用极大似然法来估计模型的参数。</p></blockquote><p>Logistic Regression的目标函数的输出是，在已知$x$的条件下，$y=+1$的概率，因此在已知$x$的条件下，$y=+1$的概率是$f(x)$，$y=-1$的概率是$1-f(x)$:</p><p>考虑训练样本$\mathcal{D}=\{(x_1,+1),(x_2,-1),…,(x_N,-1)\}$，并不是每次抽样都能抽到一模一样的$\mathcal{D}$，抽到这么一份样本是由于各种的机缘巧合。那么我们能抽到这么一份$\mathcal{D}$的概率取决于两部分：</p><ol><li>抽到样本$x_1,…,x_N$的概率；</li><li>这些样本对应的$y_1,…,y_N$等于$+1$的概率</li></ol><p>对于目标函数$f$，抽到$\mathcal{D}$的概率只取决于第1部分，而我们无法知道$f$，即第2部分也是未知的，因此我们称在$h$的作用下抽出$\mathcal{D}$的概率为“似然性”。如果 $h\approx f$，则 $likelihood(h)\approx \text{probability using }f$，并且我们认为在$f$的作用下，产生$\mathcal{D}$这样的样本的概率通常是非常的大的。</p><p>所以有：</p><script type="math/tex; mode=display">\text{if }h\approx f\text{, then }\; likelihood(h)\approx(\text{probability using }f)\approx\text{large}</script><p>则理想的hypothesis就是能使得似然函数最大的那个$h$：</p><script type="math/tex; mode=display">g=\underset{h}{argmax}\;likelihood(h)</script><p>当$h$是logistic函数的时候，即$h(x)=\theta(w^Tx)$，由于logistic函数的中心对称性，有:</p><script type="math/tex; mode=display">1-h(x)=h(-x)</script><p>所以有：</p><script type="math/tex; mode=display">1-h(x_n)=h(-x_n)=h(y_nx_n)</script><p>因此：</p><script type="math/tex; mode=display">likelihood(logistic\;h)\propto \prod_{n=1}^{N}h(y_nx_n)</script><p>我们的目标是想找到一个似然性最大的方程:</p><script type="math/tex; mode=display">\underset{h}{max}\;\;{likelihood(logistic\;h) \propto}\prod_{n=1}^{N}h(y_nx_n)\propto\prod_{n=1}^{N}\theta(y_nw^Tx_n)\propto\frac{1}{N}\sum_{n=1}^{N}\ln\theta(y_nw^Tx_n)</script><p>转化成与参数$w$有关的形式（求解上式最大值，等价于求解下式的最小值）：</p><script type="math/tex; mode=display">\underset{w}{min}E_{in}(w)=\frac{1}{N}\sum_{n=1}^{N}\ln(1+\exp(-y_nw^Tx_n))</script><p>求和符号后面的部分就是在极大似然估计下，logistic方程的误差函数，这种形式的误差函数称为cross entropy error:</p><script type="math/tex; mode=display">err(w,x_n,y_n)=\ln(1+\exp(-y_nw^Tx_n))</script><h3 id="参数求解-1"><a href="#参数求解-1" class="headerlink" title="参数求解"></a>参数求解</h3><p>那么如何能够最小化$E_{in}(w)$呢？按照之前Linear Regression的逻辑，由于它是凸函数，如果我们能解出一阶微分(梯度)为0的点，这个问题就解决了。</p><p>先来看看$E_{in}(w)$在$w_i$方向上的偏微分：</p><p><img src="https://beader.me/imgs/logistic-regression/deriv_costf_logistic.png" alt="img"></p><p>再把偏微分方程中的$x_{n,i}$换成向量的形式，就得到$E_{in}(w)$的一阶微分:</p><script type="math/tex; mode=display">\triangledown E_{in}(w)=\frac{1}{N}\sum_{n=1}^{N}\theta(-y_nw^Tx_n)(-y_nx_n)</script><p>和之前的Linear Regression不同，它不是一个线性的式子，要求解$\triangledown E_{in}(w)=0$这个式子，是困难的。那么该使用何种方法实现$E_{in}(w)$最小化呢？</p><p>这里可以使用类似PLA当中的，通过迭代的方式来求解，这种方法又称为梯度下降法(Gradient Descent)。</p><p><img src="https://beader.me/imgs/logistic-regression/iterative_opt.png" alt="img"></p><p>有点类似一个小球，往山谷方向滚，直至山谷。每一步我们只要决定两个东西：1、滚动的方向；2、滚动的步长。</p><p>滚动的方向好决定，即在该点一阶微分后的向量所指的方向；步长${\eta}$比较难决定，太小了更新太慢，太大了容易矫枉过正:</p><p><img src="https://beader.me/imgs/logistic-regression/choise_of_eta.png" alt="img"></p><p>一个比较好的做法是让 $\eta$ 与 $||\triangledown E_{in}(w_t)||$ 成一定的比例。</p><p>完整的梳理下梯度下降法(Gradient Descent)：</p><p>initialize $w_0$</p><p>For t = 0, 1, …</p><ol><li><p>compute</p><script type="math/tex; mode=display">\triangledown E_{in}(w_t)=\frac{1}{N}\sum_{n=1}^{N}\theta(-y_nw^T_tx_n)(-y_nx_n)</script></li><li><p>update by</p><script type="math/tex; mode=display">w_{t+1} \leftarrow w_t - \eta\triangledown E_{in}(w_t)</script></li></ol><p>…until $E_{in}(w_{t+1})=(\approx)0$ or enough iterations</p><p>return $\text{last }w_{t+1}\text{ as }g$</p><h2 id="Linear-Models-for-Classification"><a href="#Linear-Models-for-Classification" class="headerlink" title="Linear Models for Classification"></a>Linear Models for Classification</h2><p>前面介绍了三种线性模型：PLA、Linear Regression与Logistic Regression。之所以称他们是线性模型，是因为这三种分类模型的方程中，都含有一个相同的部分，该部分是各个特征的一个线性组合，也可以称这个部分叫做线性评分方程（linear scoring function）：</p><script type="math/tex; mode=display">s=w^Tx</script><p>对比这三种模型：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\llloverview.png" alt="img"></p><ul><li>Linear Classification模型：取$s$的符号作为结果输出，使用0/1 error作为误差衡量方式，但它的cost function，也就是$E_{in}(w)$是一个离散的方程，并且该方程的最优化是一个NP-hard问题。</li><li>Linear Regression模型：直接输出评分方程，使用平方误差square error作为误差衡量方式，好处是$E_{in}(w)$是一个凸二次曲线，非常方便求最优解（可通过矩阵运算一次得到结果，一步登天）。</li><li>Logistic Regression模型：输出的是评分方程经过sigmoid的结果，使用cross-entropy作为误差衡量方式，其$E_{in}(w)$是一个光滑的凸函数，可以使用gradient descent的方式求最佳解。</li></ul><p>Linear Regression和Logistic Regression的输出是一个实数，而不是一个Binary的值，他们能用来解分类问题吗？可以，只要定一个阈值，高于阈值的输出+1，低于阈值的输出-1就好。既然Linear Regression和Logistic Regression都可以用来解分类问题，并且在最优化上，他们都比Linear Classification简单许多，<strong>我们能否使用这两个模型取代Linear Classification呢？</strong></p><p><strong>三个模型的区别在于误差的衡量</strong>：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\lll_error_function.png" alt="img"></p><p>这里$y$是一个binary的值，要么是-1，要么是+1。</p><p>注意到三个模型的error function都有一个$ys$的部分，也叫做<strong>分类正确性分数 (classification correctness score)</strong>。其中$s$是模型对某个样本给出的分数，$y$是该样本的真实值。</p><p>当$y=+1$时，$s$越大越好；当$y=-1$时，$s$越小越好。所以总的来说，我们希望$ys$尽可能大。因此这里希望给较小的$ys$较大的cost，给较大的$ys$较小的cost即可。因此，不同模型的本质差异，就在于这个cost该怎么给。</p><p>既然这三个error function都与$ys$有关，我们可以以$ys$为横坐标，$err$为纵坐标，把这三个函数画出来。</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\lll_error_function_vis.png" alt="img"></p><ul><li><p>sqr(squre error)为Linear Regression的误差函数。可以看出：</p><ul><li>在$ys$较小的时候很大，符合情况；</li><li>在$ys$较大的时候$err_{sqr}$同样很大，这点不是很理想，因为我们希望$ys$大的时候cost要小</li><li>尽管如此，至少在$err_{sqr}$小的时候（在$ys=1$附近），$err_{0/1}$也很小，因此可以拿来做error function。</li></ul></li><li><p>ce(cross entropy)为Logistic Regression的误差函数。可以看出：</p><ul><li><p>$err_{ce}$是一个单调递减的函数，形态有一点像$err_{0/1}$，但来的比较平缓。</p></li><li><p>注意到$err_{ce}$有一部分是小于$err_{0/1}$的，我们希望$err_{ce}$能成为$err_{0/1}$的一个upper bound（目的一会儿会说到），只要将$err_{ce}$做一个换底的动作，将以$e$为底的对数换成以$2$为底的对数：</p><script type="math/tex; mode=display">\text{scaled ce : err}_{sce}(s,y)=\log_2(1+\exp(-ys))</script><p>换底过后三种误差函数的图像如下：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\lll_error_function_scale.png" alt="img"></p><p>事实上这里做scale的动作并不会影响最优化的过程，它只是让之后的推导证明更加容易一些。</p></li></ul></li></ul><p>回到问题：能不能拿Linear Regression或Logistic Regression来替代Linear Classification？</p><ul><li><p>为什么会想做这样的替代？</p><p>Linear Classification在分类上做的很好，但在最优化上是NP-hard问题，而Linear Regression与Logistic Regression在最优化上比较容易。如果他们在分类能力上的表现能够接近Linear Classification，用他们来替代Linear Classification来处理分类的问题，就是件皆大欢喜的事。</p></li><li><p>为何要对$err_{se}$进行换底，将其scale成$err_{0/1}$的upper bound？</p><ul><li>目的就是为了让这几个模型的观点在某个方向上是一致的，即：$err_{sqr}$或$err_{sce}$低的时候，$err_{0/1}$也低。</li><li>通俗一点讲：假设某种疾病有两种检测方法A和B。A方法检查结果为阳性时，则患病，为阴性时，则未患病。B方法的效率差一些，对于一部分患病的人，B方法不一定结果为阳性，但只要B的结果为阳性，再用A来检查，A的结果一定也为阳性。这么一来，我们就可以说，如果B方法的结果为阳性的时候，我们就没有必要使用A方法再检查一次了，它的效率是和A相同的。</li><li><p>从理论上来说明，我们能得到如下的三个性质：</p><script type="math/tex; mode=display">err_{0/1}(s,y)\leq err_{SCE}(s,y)=\frac1{ln2}err_{CE}(s,y)\\E_{in}^{0/1}(w)\leq E_{in}^{SCE}(w)=\frac1{ln2}E_{in}^{CE}(w)\\E_{out}^{0/1}(w)\leq E_{out}^{SCE}(w)=\frac1{ln2}E_{out}^{CE}(w)</script><p>由VC理论可得：</p><script type="math/tex; mode=display">E_{out}^{0/1}(w)\leq E_{in}^{0/1}(w)+\Omega^{0/1}\leq \frac1{ln2}E_{in}^{CE}(w)+\Omega^{0/1}\\E_{out}^{0/1}(w)\leq \frac1{ln2}E_{out}^{CE}(w)\leq \frac1{ln2}E_{in}^{CE}(w)+\frac1{ln2}\Omega^{CE}</script><p>从而我们就能够把LinReg和LogReg 作为Linear Classification的上界。即如果使用$err_{sqr}$或$err_{sce}$来衡量一个模型分类分得好不好的时候，如果他们认为分得好，那么如果使用$err_{0/1}$，它也会认为分得好。</p></li></ul></li></ul><p>对比下在处理分类问题时，使用PLA，Linear Regression以及Logistic Regression的优缺点：</p><ul><li><p><strong>PLA</strong></p><ul><li>优点：高效（一个样本更新一次）；数据是线性可分时，$E_{in}^{0/1}$保证可以降到最低</li><li>缺点：数据不是线性可分时，要额外使用pocket技巧，较难做最优化</li></ul></li><li><p><strong>Linear Regression</strong></p><ul><li>优点：在这三个模型中最容易做最优化</li><li>缺点：在$ys$很大或很小时，这个bound是很宽松的，没有办法保证$E_{in}^{0/1}$能够很小</li></ul></li><li><p><strong>Logistic Regression</strong></p><ul><li>优点：较容易最优化</li><li>缺点：当$ys$是很小的负数时，bound很宽松</li></ul></li></ul><p>所以我们常常可以使用Linear Regresion跑出的$w$作为(PLA/Pocket/Logistic Regression)的$w_0$（用于初始化），然后再使用$w_0$来跑其他模型，这样可以加快其他模型的最优化速度。同时，由于拿到的数据常常是线性不可分的，我们常常会去使用Logistic Regression而不是PLA+pocket。</p><h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><p>我们知道PLA与Logistic Regression都是通过迭代的方式来实现最优化的，区别在于：</p><ul><li>PLA每次迭代只需要针对一个点进行错误修正，时间复杂度为$O(1)$</li><li>Logistic Regression每一次迭代都需要遍历所有样本点，时间复杂度为$O(N)$</li></ul><p>这样一来，数据量大的时候，由于需要计算每一个点，Logistic Regerssion就会很慢了。那么可不可以每次只看一个点，即不要公式中先求和再取平均数的那个部分呢？随机取一个点$n$，它对梯度的贡献为：</p><script type="math/tex; mode=display">\triangledown _w err(w,x_n,y_n)</script><p>我们把它称为随机梯度（stochastic gradient），而真实的梯度可以认为是随机抽出一个点的梯度值的<strong>期望</strong>：</p><script type="math/tex; mode=display">\triangledown_w E_{in}(w) = \underset{random\,n}\epsilon\triangledown_w err(w,x_n,y_n)</script><p>因此我们可以把随机梯度当成是在真实梯度上增加一个均值为0的noise：</p><script type="math/tex; mode=display">\text{stochastic gradient} = \text{true gradient} + \text{zero-mean ‘noise’ directions}</script><p>从单次迭代上来看，好像确实会对每一步找到正确的梯度方向有影响，但是从整体期望值来看，与真实的梯度方向没有差太多，同样能找到差不多好的位置。我们把这种方法称为<strong>随机梯度下降，Stochastic Gradient Descent (SGD)</strong>：</p><script type="math/tex; mode=display">w_{t+1} \leftarrow w_t + \eta \underbrace{ {\theta({-y_nw_t^Tx_n} }){(y_nx_n)} }_{-{\triangledown_{err}(w_t,x_n,y_n)} }</script><p>和之前说到的Gradient Descent相比：</p><ul><li>SGD的好处在于时间复杂度大幅减小（每次只随机地看一个点），在数据量很大的时候可以很快得得到结果；且可以应用到在线学习（online learning）上。</li><li>缺点在于，当noise比较大的时候，会较不稳定。</li></ul><p>我们看到SGD logistic regression和PLA有非常相似的地方：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\20180805195816307.png" alt="img" style="zoom:50%;"></p><ul><li>都是对当前的与进行修正，可把SGD logistic regression称之为’soft’ PLA（更新速度随着错误的多少变动）；</li><li>当$\eta=1$且足够大的时候，PLA近似于SGD。</li></ul><p>关于SGD算法的两点经验（rule-of-thumb）：</p><ul><li>SGD的终止迭代条件一般是让迭代次数足够多；</li><li>更新速度$\eta$是根据实际情况来决定的，一般$\eta=0.1$就可以了。</li></ul><h3 id="Multiclass-Classification"><a href="#Multiclass-Classification" class="headerlink" title="Multiclass Classification"></a>Multiclass Classification</h3><p>我们现在已经有办法使用线性分类器解决二元分类问题，但有的时候，我们需要对多个类别进行分类，即模型的输出不再是0和1两种，而会是多个不同的类别。那么如何套用二元分类的方法来解决多类别分类的问题呢？</p><p><strong>利用二元分类器来解决多类别分类问题主要有两种策略，OVA(One vs. ALL)和OVO(One vs. One)。</strong></p><ol><li><p><strong>One-Versus-All(OVA)</strong></p><p>假设原问题有四个类别，那么每次我把其中一个类别当成圈圈，其他所有类别当成叉叉，建立二元分类器，循环下去，最终我们会得到4个分类器。</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\ova-1584414720961.png" alt="img"></p><p>做预测的时候，分别使用这四个分类器进行预测，预测为圈圈的那个模型所代表的类别，即为最终的输出。譬如正方形的那个分类器输出圈圈，菱形、三角形、星型这三个分类器都说是叉叉，则我们认为它是正方形。</p><p>优点：简单高效，并且可以和Logistic Regression的方法搭配使用；</p><p>缺点：当数据类别$k$很大时，那么二分的正类和负类的数量差别就很大，数据不平衡unbalance，这样就不容易得出正确结果。另外，在选取某一类概率最大时，所有类别的概率之和不一定为1，虽然实际中影响不大，但统计上有更加严谨的方法——multinomial logistic regression。</p></li><li><p><strong>One-Versus-One(OVO)</strong></p><p>在类别较多的时候，如果使用OVA方法，则又会遇到数据不平衡(unbalance)的问题，你拿一个类别作为圈圈，其他所有类别作为叉叉，那么圈圈的比例就会非常小，而叉叉的比例非常高。为了解决这个不平衡的问题，我们可以利用OVO，即每次只拿两个类别的数据出来建立分类器，如下图。</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\ovo.png" alt="img"></p><p>一笔新数据进来之后，分别使用这六个模型进行预测，投票得票数最多的那个类别，作为最终的输出。</p><p>优点：更加高效，因为虽然需要进行的分类次数增加了，但是每次只需要进行两个类别的比较，也就是说单次分类的数量减少了；而且一般不会出现数据unbalanced的情况，比较稳定；可以和任何的binary classification方法搭配使用。</p><p>缺点：分类次数增加到$C_k^2$，时间复杂度和空间复杂度可能都比较高。</p></li></ol><p>总之，OVA和OVO是两个多类别分类方法，都是非常不错的多类别分类算法，在$k$不大的时候比较推荐OVO，减少分类次数。</p><h2 id="Nonliear-Transformation"><a href="#Nonliear-Transformation" class="headerlink" title="Nonliear Transformation"></a>Nonliear Transformation</h2><p>前面所谈到的分类模型，都是基于线性的，即我们假设数据是线性可分，或者至少看起来用一条线来做分类是不错的。但现实中我们的数据往往不那么容易得能用一条线区分开来。</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\linear-vs-nonlinear.png" alt="img"></p><p>可以发现$\mathcal{D}$并不是一个线性可分的数据，但使用一个圆圈，却可以很好得把圈圈和叉叉区分开来。这个”圆圈分类器”可以是下面这种形式:</p><script type="math/tex; mode=display">h_{SEP}(x)=sign(-x_1^2-x_2^2+0.6)</script><p>于是我们就能把这个式子再写成下面的形式</p><script type="math/tex; mode=display">h(x)=sign(\tilde{w}_0\cdot z_0+\tilde{w}_1\cdot z_1+\tilde{w}_2\cdot z_2)=\tilde{w}^Tz</script><p>如果我们只看包含$z$的部分，它事实上依然是一个线性方程。即$\mathcal{X}$空间下的一个圆圈，对应到$\mathcal{Z}$空间下的一条直线。</p><p><img src="https://beader.me/imgs/nonlinear-transformation/two-space.png" alt="img"></p><p>这个转换的过程称为nonlinear feature transform，用符号$\Phi$表示，$\Phi$把两个互相独立的空间给联系了起来:</p><script type="math/tex; mode=display">(1,x_1^2,x_2^2)=\Phi(x)=(z_0,z_1,z_2)=z</script><p>$\mathcal{X}$空间下的每个点，都对应$\mathcal{Z}$空间下的某个点，同样$\mathcal{X}$空间下的二次曲线方程，都对应$\mathcal{Z}$空间下的某个一次直线方程。</p><script type="math/tex; mode=display">h(x)=sign({\tilde{w}_0}+{\tilde{w}_1}{x_1^2}+{\tilde{w}_2}{x_2^2})=sign({\tilde{w}^T}{\Phi}(x))={\tilde{h}({z})}</script><p>这样以来，两个空间产生了关联，前面说的$\Phi$就是这两个空间的纽带，在这个纽带下，$\mathcal{Z}$空间下的不同直线也就对应$\mathcal{X}$下的不同形态的分类器。</p><div class="table-container"><table><thead><tr><th style="text-align:center">$\tilde{w}$</th><th style="text-align:left">X空间下的曲线形态</th></tr></thead><tbody><tr><td style="text-align:center">(0.6,−1,−1)</td><td style="text-align:left">circle(圈圈在内部，叉叉在外部)</td></tr><tr><td style="text-align:center">(−0.6,+1,+1)</td><td style="text-align:left">circle(圈圈在外部，叉叉在内部)</td></tr><tr><td style="text-align:center">(0.6,−1,−2)</td><td style="text-align:left">ellipse椭圆</td></tr><tr><td style="text-align:center">(0.6,−1,+2)</td><td style="text-align:left">hyperbola双曲线</td></tr><tr><td style="text-align:center">(0.6,+1,+2)</td><td style="text-align:left">所有点都判断为圈圈</td></tr></tbody></table></div><p>更加一般化，我们把一次空间$\mathcal{X}$映射到二次空间$\mathcal{Z}$的时候，还会保留其一次项（图形中心不一定在原点），即下面这个样子的映射才是完整的二次映射:</p><script type="math/tex; mode=display">\Phi(x)=(1,x_1,x_2,x_1^2,x_1x_2,x_2^2)</script><p>这样一来，这个完整版的$\mathcal{Z}$空间的直线，就可以代表$\mathcal{X}$空间下的所有二次曲线了。</p><p>我们为何要做这个非线性变换？逻辑是这样的：</p><ul><li>在$\mathcal{X}$空间中，我们使用一条直线，很难把圈圈和叉叉分开</li><li>但是如果我们使用一条曲线，可以很容易做到</li><li>可我们只学过找最优“直线”的算法，没有学过找最佳“曲线”的算法</li><li>我们有一个纽带$\Phi$，它能够把$\mathcal{X}$空间中的所有曲线，对应到$\mathcal{Z}$空间中的曲线，反过来也可以根据$\mathcal{Z}$空间的一条直线，找到$\mathcal{X}$空间中对应的曲线</li><li>所以我们可以把$\mathcal{X}$空间下的原始数据$\mathcal{D}$映射到$\mathcal{Z}$空间下</li><li>然后在$\mathcal{Z}$空间下寻找最佳的“直线”，找直线这件事我们已经学过该怎么做了</li><li>找到这条最佳的“直线”后，把它对应回$\mathcal{X}$空间，就是我们刚开始说的需要找的那条最佳的“曲线”了。</li></ul><p><img src="https://beader.me/imgs/nonlinear-transformation/nonlinear-transform-steps.png" alt="img"></p><p>实际操作上分以下三步：</p><ol><li>变换原始数据 ${(x_n,y_n)}\Rightarrow {(z_n=\phi(x_n),y_n)}$</li><li>利用之前学过的算法，使用${(z_n,y_n)}$训练线性模型，得到$\tilde{w}$</li><li>得到分类器方程$g(x)=sign({\tilde{w}^T}{\Phi_2}(x))$</li></ol><h3 id="非线性变换的代价"><a href="#非线性变换的代价" class="headerlink" title="非线性变换的代价"></a>非线性变换的代价</h3><p>d维向量$x$经过Q次多项式变换（Q-th Order Polynomial Transform）:</p><script type="math/tex; mode=display">\tilde{d}=C_{Q+d}^Q=C_{Q+d}^d=O(Q^d)</script><p>以上是Q次完整变换，当然我们不一定会需要完整项，譬如之前那个圆圈，就舍弃了$x_1x_2$项。若考虑完整变化，原来的$1+d$维向量经过变换，就成了$1+\tilde{d}=1+\binom{Q+d}{Q}$维向量，复杂度由$O(d)$变为$O(Q^d)$。</p><ol><li><p>计算变复杂，需要的存储空间增大</p><p>这点很容易理解，如之前的例子，原始数据$(1,x_1,x_2)$经过变换之后变成$(1,x_1,x_2,x_1^2,x_1x_2,x_2^2)$，需要多一倍的空间来存转换后的数据，同时参数的增加，也增大了计算量。</p></li><li><p>模型复杂度增大</p><p>之前有讲到自由度与VC Dimension的关系，线性模型的$d_{vc}\approx 自由度 \approx \tilde{d}+1$。如果Q非常大的话，则模型的$d_{vc}$也会非常大，我们知道$d_{vc}$越大，越容易实现小的$E_{in}$，同时，也会造成$|E_{out}-E_{in}|$的加大，即模型的泛化能力(generalization)变差。</p></li></ol><h4 id="模型的泛化问题-Generalization-Issue"><a href="#模型的泛化问题-Generalization-Issue" class="headerlink" title="模型的泛化问题(Generalization Issue)"></a>模型的泛化问题(Generalization Issue)</h4><p><img src="https://beader.me/imgs/nonlinear-transformation/phi1-vs-phi4.png" alt="img"></p><p>上图是分别使用原始数据进行训练以及进行4次非线性变换后的数据进行训练的结果对比。从视觉上看，虽然右图（经过4次非线性变换的模型）能够把圈圈叉叉完全分开，但显然这种模型过于复杂了。</p><p>很多时候我们会面临模型泛化能力和分类能力的权衡取舍，即：</p><div class="table-container"><table><thead><tr><th style="text-align:center">$\tilde{d}(Q)$</th><th style="text-align:center">$E_{out}(g)$能否与$E_{in}(g)$很接近?</th><th style="text-align:center">$E_{in}(g)$是否足够小?</th></tr></thead><tbody><tr><td style="text-align:center">高</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">低</td><td style="text-align:center">√</td><td style="text-align:center">×</td></tr></tbody></table></div><p>那么如何选择合适的复杂度呢？暂且不讨论10维的数据有没有办法用眼睛看，就拿前面2维的例子来说，用眼睛看来选择模型是件很危险的事情。</p><p>$d_{vc}$是比较难判断的，因为你是在“看过”数据之后，由你大脑选择的一个模型，这里要考虑到你大脑“选择模型”产生的一个复杂度，因为如果重新选取一部分数据，你有可能就不再挑选正圆模型了，事实上你的大脑不知不觉地参与到了模型参数估计上。（human learning√ machine learning ×）</p><h3 id="Structured-Hypothesis-Sets"><a href="#Structured-Hypothesis-Sets" class="headerlink" title="Structured Hypothesis Sets"></a>Structured Hypothesis Sets</h3><p>通常我们说的非线性变换，指的是多项式变换(Polynomial Transform)。用符号$\Phi_Q$来表示$Q$次多项式变换：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\20180806215127288.png" alt="img"></p><p>可以发现$\Phi_{i}(x)$中包含了$\Phi_{i-1}(x)$，因此他们对应的Hypothesis Set也有如下关系：</p><p><img src="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part3/1Study\hexo\source\_posts\林轩田《机器学习基石》笔记Part3.assets\20180806215426586.png" alt="img"></p><p>假如我们分别对原始数据进行$i$次非线性多项式变换并训练模型，$g_i$表示使用$i$次非线性多项式变换后的数据所训练出的最优模型，$\color{blue}{g_i=argmin_{h\in \mathcal{H}_i}E_{in}(h)}$则有：</p><script type="math/tex; mode=display">H_{\Phi_0} \subset H_{\Phi_1} \subset H_{\Phi_2} \subset \cdots \subset H_{\Phi_Q} \\d_{VC}(H_0)\leq d_{VC}(H_1)\leq d_{VC}(H_2)\leq \cdots \leq d_{VC}(H_Q)\\E_{in}(g_0)\geq E_{in}(g_1)\geq E_{in}(g_2)\geq \cdots \geq E_{in}(g_Q)</script><p>通常在进行高次非线性变换的时候，应该特别小心，因为$d_{vc}$上升很快，极容易造成overfitting。</p><p>比较安全的做法是，先尝试不做非线性变换，即使用$\mathcal{H}_{\phi_1}$，如果效果足够好了，就不需要进行非线性变换，如果效果不够好，再慢慢尝试使用复杂更高的模型。</p><p><img src="https://beader.me/imgs/nonlinear-transformation/model_complexity_curve.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>林轩田《机器学习基石》Note——Part1：When Can Machines Learn?</title>
      <link href="/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part1/"/>
      <url>/2020/03/08/lin-xuan-tian-ji-qi-xue-xi-ji-shi-note-part1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>课程：</p><ul><li><a href="https://www.bilibili.com/video/av12463015" target="_blank" rel="noopener">https://www.bilibili.com/video/av12463015</a></li></ul><p>参考笔记：</p><ul><li><a href="http://redstonewill.com/" target="_blank" rel="noopener">http://redstonewill.com/</a></li><li><a href="https://beader.me/mlnotebook/index.html" target="_blank" rel="noopener">https://beader.me/mlnotebook/index.html</a></li><li><a href="https://me.csdn.net/github_36324732" target="_blank" rel="noopener">https://me.csdn.net/github_36324732</a></li><li><a href="https://zhuanlan.zhihu.com/ml-note" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/ml-note</a></li></ul></blockquote><h1 id="When-Can-Machines-Learn"><a href="#When-Can-Machines-Learn" class="headerlink" title="When Can Machines Learn?"></a>When Can Machines Learn?</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p><strong>技巧</strong>：某种表现的增进（e.g. prediction accuarcy）</p><p><strong>机器学习</strong>：</p><ul><li>从数据出发，经过电脑的计算后，最终得到某种表现的增进（data→ML→improved performance measure）</li><li>一种构建复杂规则的路径，授机以渔(?)</li></ul><p><strong>机器学习条件</strong>：</p><ul><li>存在某些潜在的模式可以学习</li><li>有一定的难以具体言明的规则（not easily programmable）</li><li>一定的数据资料</li></ul><p><strong>机器学习的组成部分</strong>：</p><ul><li>输入： $x\in X$</li><li>输出： $y\in Y$</li><li>目标函数 $f$：$X\rightarrow Y$（未知的目标函数）</li><li>数据，即训练样本， $D=\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$</li><li>假设函数 $g$： $X\rightarrow Y$ （能够学习到的函数），$g$与$f$越接近越好</li><li><img src="https://www.zhihu.com/equation?tex=g%5Cin+H+%3D+%5Cleft%5C%7B+h_1%2Ch_2...h_n+%5Cright%5C%7D" alt="[公式]"> ，是属于假设空间$H$的一个假设，$H$称为假设函数集，包含了好与不好的各种$h$（假设），反映数据中可能存在的规律，从输入到输出的函数</li></ul><p><strong>机器学习 v.s. 数据挖掘 v.s. 人工智能 v.s. 统计</strong></p><ul><li>机器学习的目的是从数据资料出发，假设空间中选出一个最接近目标函数$f$的函数$g$，使得$g\approx f$</li><li>数据挖掘：用数据找到隐含在资料中的有用信息，与机器学习密不可分，相互帮助（但有时候并不是以找到函数$g$为目标）</li><li>人工智能：机器学习是实现人工智能的一种方法</li><li>统计：使用数据来进行推论，$g$就是一个推论结果，统计是实现机器学习的一种方法；由于统计是从数学出发的，统计会更注重数学假设，而非计算。</li></ul><h2 id="感知机算法"><a href="#感知机算法" class="headerlink" title="感知机算法"></a>感知机算法</h2><p>Perceptron Learning Algorithm（PLA）</p><p>首先要保证在这些得到的数据中，假设函数可以预测的很好</p><p>根据预测与实际结果，不断地去修正决策平面</p><script type="math/tex; mode=display">sign(w^T_tx_n)\neq y_n \\w_{t+1}\leftarrow w_t+y_{n(t)}x_{n(t)}</script><p><img src="https://i.loli.net/2020/03/09/wLcn5qdYjgOCkl9.png" alt="未命名1583747872.png"></p><p>$w$是决策平面的法向量</p><p>当发生错误时，比如，当实际标签为正$y=+1$而预测为负，则决策平面会更接近$x$；当实际标签为负$y=-1$而预测为正，则决策平面会更远离$x$。</p><p>不断更新决策平面，直到不犯错误，最终得到的$w_{PLA}$是所要求的$g$。</p><p>因此又称PLA为“知错能改算法”。</p><blockquote><p>感知器学习算法对$w$的更新方法，首先$w$和$x$的内积就表示两个向量的夹角大小，假如$x$的类别是+1，那么内积也是正的，如果初始的$w_0$使得这个值为负，那么代表$w_0$和$x$之间的夹角是钝角，太大了，就旋转$w_0$到$w_1$， 使得内积的值是正的，这就对$w_0$完成了一次更新</p></blockquote><p>终止条件：线性可分(linear separable)，即存在一个向量$w_f$使得能够完美地区分开正负样本</p><p>由于函数间隔大于0（均可完全区分，且最近点离平面的也有一定的距离）：</p><script type="math/tex; mode=display">y_{n(t)}w_f^Tx_{n(t)}\ge \min_n y_{n}w_f^Tx_{n}>0</script><p>因此可以推导</p><script type="math/tex; mode=display">\begin{align}w^T_fw_{t+1}&=w^T_f(w_{t}+y_{n(t)}x_{n(t)})\\&\ge w^T_fw_{t}+\min_n y_{n}w_f^Tx_{n}\\&> w^T_fw_{t} +0\end{align}</script><p>可以看出随着$w_t$的更新，是在不断接近$w_f$</p><p>（衡量向量接近的一个方法是内积，越大越接近）</p><h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><p>根据输出类型可以划分为：</p><ul><li>分类（二元，多元）</li><li>回归</li><li>结构化学习（如标识词性，NLP）</li></ul><p>根据是否具有标签可分为：</p><ul><li>有监督</li><li>无监督（聚类、密度分析、异常值检测）</li><li>半监督（有标注+无标注混合）</li><li>强化学习（通过对错误进行惩罚/对正确进行奖励，从而实现对序列化的信息进行学习）</li></ul><p>根据训练的形式可分为：</p><ul><li>批学习（batch）：一批样本一起学习，填鸭式’duck feeding’</li><li>在线学习（online）：一个样本学习一次，一条一条地</li><li>主动学习（active）：让机器有问问题的能力</li></ul><p>根据输入空间（特征）的类别可分为：</p><ul><li>具体的（concrete）</li><li>原始的（raw）：通常需要人或机器去将抽象转化为具体</li><li>抽象的（abstract）：通常也需要进行特征转换、提取等</li></ul><h2 id="机器学习可行性论证"><a href="#机器学习可行性论证" class="headerlink" title="机器学习可行性论证"></a>机器学习可行性论证</h2><blockquote><p><strong>第一部分：证明适用于训练集的$g$同样适用于整个输入空间</strong></p></blockquote><ul><li><strong>No Free Lunch（没有免费午餐定理）</strong>：即使对于已有的样本算法完全能够预测正确，但对于未知的样本来说并不能做到。</li><li><p>这表明：<strong>学习可能是做不到的</strong>，在训练集中可以求得一个最佳假设$g$，但是在训练集外的样本中，$g$可能和目标函数$f$相差甚远。</p></li><li><p>引入<strong>Hoeffding’s Inequality（霍夫丁不等式）</strong></p><script type="math/tex; mode=display">P(|\nu-\mu|> \varepsilon) \le 2\exp(-2\varepsilon^2N)</script><ul><li>$|\nu-\mu|$表示$\nu$与$\mu$的接近程度</li><li>随着样本量$N$增大，$\nu$与$\mu$相差较大的概率不断变小，<strong>$\nu$与$\mu$相等的结论“可能近似正确”（Probably Approximately Correct，PAC）</strong></li><li>用$E_{in}(h)$和$E_{out}(h)$表示一个确定的假设函数$h$在样本内的错误率和样本外的错误率，则有： $P(|E_{in}(h)-E_{out}(h)|&gt; \varepsilon) \le 2\exp(-2\varepsilon^2N)$</li><li>如果求得一个$h$，使得$E_{in}(h)$很小，且$E_{in}(h)\approx E_{out}(h)$，则可以推出$E_{out}(h)$很小，则可以推出$h\approx f$ </li></ul></li></ul><p><strong>通过大数定理由样本估计总体，可以增加样本数量使得估计与真实更加接近。证明了在一个$h$的情况下，当样本的数量足够多，该$h$在样本集上的表现可以代表它与真实$f$的接近程度。</strong></p><ul><li><p>但$h$只是假设空间的一种，不能由$h\approx f$得到$g\approx f$。（#不能由部分可行来推断总体可行）</p></li><li><p>因此算法要能够自由的从中挑选$h$，这里就需要添加一个<strong>验证流程(Verification Flow)</strong>，这个流程使用历史数据来判断某个够不够好。选出一个最小的$E_{in}(h)$，把挑选出的最好的称为final hypothesis，从而得到$g\approx f$。</p><p><img src="https://beader.me/mlnotebook/section2/images/verification_flow.png" alt="img"></p></li></ul><p><strong>以上证明了机器学习在训练样本中学习得到的$g$在整个输入空间中也可行。</strong></p><blockquote><p><strong>第二部分：证明训练样本的误差不会导致选择到的$g$对整个输入空间有误差</strong></p></blockquote><ul><li><p>当$h$有多个时，要从中挑选最好的$h$，但验证所用的数据只是来自于总体的一个样本 (sample)，会存在抽样误差。譬如你想知道一枚硬币抛出正面的概率是多少，于是扔了5次，有一定的可能你连续扔了5个正面出来，这时候说抛出正面的概率是1，这当然是行不通的，因此你扔的这5次硬币，就是一个<strong>bad sample</strong>。</p></li><li><p>凡是由于抽样误差所造成样本分布与总体分布相差很大的样本，$E_{in}(h)$和$E_{out}(h)$差很远，我们都可以称之为<strong>bad sample</strong>。</p></li><li><p>由于数据不完美有噪声，在假设$h$有很多个的情况下，会倾向于选择让$E_{in}(h)$最小的那个$h$，导致恶化。</p></li><li><p>但当数据量足够多时，肯定能有数据使得机器学习$g$时不踩雷，即在每个$h$上$E_{in}(h)\approx E_{out}(h)$，能正确学习到g。（例如样本$D_{1126}$）</p><p><img src="https://pic4.zhimg.com/80/v2-4d9f3d54a18a3edefecff9f3f47d3437_1440w.jpg" alt="img"></p><ul><li>上图包含了$M$个假设$h$，而不好的$D$不是由单一假设就能确定的，而是只要有一个假设在此抽样$D$上表现不好则该抽样被标记为不好的。求训练样本不好的几率是多少：</li></ul><p><img src="https://pic4.zhimg.com/80/v2-574d528dd3031280c049da6a3000b0df_1440w.jpg" alt="img"></p><ul><li>当训练样本量$N$足够大且$M$有限大，则概率可以小于一个足够小的数字，可以说每一个假设$h$都是安全的，因此肯定会存在一个$D_{1126}$这样的样本。</li></ul></li><li><p>所以如果通过机器学习找出了$g$满足<script type="math/tex">E_{in}(g)\approx 0</script> ，则PAC规则可以保证$E_{out}(g)\approx 0$</p></li><li><p>此时，我们就能把选到的最小$E_{in}(h)$的$h$当做$g$，那么$E_{out}(h)\approx 0$，从而达到了学习的效果。</p></li></ul><p>此处留坑：这里假定$M$有限大，但如果像感知机一样$M=\infin$呢？</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>剑指offer题目Python解答</title>
      <link href="/2020/02/14/jian-zhi-offer-ti-mu-python-jie-da/"/>
      <url>/2020/02/14/jian-zhi-offer-ti-mu-python-jie-da/</url>
      
        <content type="html"><![CDATA[<h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><h2 id="二维数组中的查找"><a href="#二维数组中的查找" class="headerlink" title="二维数组中的查找"></a>二维数组中的查找</h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>矩阵是有序的，从左下角来看，向上数字递减，向右数字递增，</p><p>因此从左下角开始查找：</p><ul><li><p>当要查找数字比左下角数字大时：右移</p></li><li><p>当要查找数字比左下角数字小时：上移</p></li></ul><p>如果超出边界，则说明二维数组中不存在target元素。 </p><h3 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># array 二维列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Find</span><span class="params">(self, target, array)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        rows=len(array)<span class="number">-1</span></span><br><span class="line">        cols=len(array[<span class="number">0</span>])<span class="number">-1</span></span><br><span class="line">        i=rows</span><br><span class="line">        j=<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&gt;=<span class="number">0</span> <span class="keyword">and</span> j&lt;=cols:</span><br><span class="line">            <span class="keyword">if</span> array[i][j]&lt;target:</span><br><span class="line">                j+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> array[i][j]&gt;target:</span><br><span class="line">                i-=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="数组中重复的数字"><a href="#数组中重复的数字" class="headerlink" title="数组中重复的数字"></a>数组中重复的数字</h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。</p><h3 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h3><ul><li><p>方法1：使用count函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 这里要特别注意~找到任意重复的一个值并赋值到duplication[0]</span></span><br><span class="line">    <span class="comment"># 函数返回True/False</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">duplicate</span><span class="params">(self, numbers, duplication)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> numbers:</span><br><span class="line">            <span class="keyword">if</span> numbers.count(i)&gt;<span class="number">1</span>:</span><br><span class="line">                duplication[<span class="number">0</span>]=i</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></li><li><p>方法2：使用Counter函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 这里要特别注意~找到任意重复的一个值并赋值到duplication[0]</span></span><br><span class="line">    <span class="comment"># 函数返回True/False</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">duplicate</span><span class="params">(self, numbers, duplication)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">        <span class="keyword">if</span> len(numbers) == len(set(numbers)): <span class="comment"># 如果不存在重复数字</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        duplication[<span class="number">0</span>] = Counter(numbers).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure></li><li><p>方法3：使用dict（31ms），时间O(1)，空间O(n) </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 这里要特别注意~找到任意重复的一个值并赋值到duplication[0]</span></span><br><span class="line">    <span class="comment"># 函数返回True/False</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">duplicate</span><span class="params">(self, numbers, duplication)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        dic = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> numbers:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> dic <span class="keyword">and</span> dic[i] == <span class="number">1</span>:</span><br><span class="line">                duplication[<span class="number">0</span>] = i</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="构建乘积数组"><a href="#构建乘积数组" class="headerlink" title="构建乘积数组"></a>构建乘积数组</h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个数组<code>A[0,1,...,n-1]</code>，请构建一个数组<code>B[0,1,...,n-1]</code>，其中B中的元素<code>B[i] = A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]</code>。不能使用除法。（注意：规定B[0]和B[n-1] = 1）</p><h3 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h3><ul><li>方法1：剑指offer给出方法</li></ul><p><img src="https://i.loli.net/2020/03/07/37nuMo4KaDfmCRO.jpg" alt="841505_1472459965615_8640A8F86FB2AB3117629E2456D8C652.jpg" style="zoom: 25%;"></p><p> <strong>B[i]的值可以看作上图的矩阵中每行的乘积。</strong> </p><p>下三角用连乘可以很容求得，上三角，从下向上也是连乘。 </p><p>因此我们的思路就很清晰了，先算下三角中的连乘，即我们先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">multiply</span><span class="params">(self, A)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        head = [<span class="number">1</span>]</span><br><span class="line">        tail = [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(A)<span class="number">-1</span>):</span><br><span class="line">            head.append(A[i]*head[i])</span><br><span class="line">            tail.append(A[-i<span class="number">-1</span>]*tail[i])</span><br><span class="line">        <span class="keyword">return</span> [head[j]*tail[-j<span class="number">-1</span>] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(head))]</span><br></pre></td></tr></table></figure><ul><li>方法2：直观方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">multiply</span><span class="params">(self, A)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        B=[i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(A))]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> B:</span><br><span class="line">            B[i]=<span class="number">1</span>  <span class="comment"># 将B中的元素每次初始化为1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> (A[:i]+A[i+<span class="number">1</span>:]):  <span class="comment"># 遍历A中除了i以外的所有元素</span></span><br><span class="line">                B[i]*=j</span><br><span class="line">        <span class="keyword">return</span> B</span><br></pre></td></tr></table></figure><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><h2 id="从尾到头打印链表"><a href="#从尾到头打印链表" class="headerlink" title="从尾到头打印链表"></a>从尾到头打印链表</h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个链表，按链表从尾到头的顺序返回一个ArrayList。</p><h3 id="解答-2"><a href="#解答-2" class="headerlink" title="解答"></a>解答</h3><p>简单列表保存</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回从尾部到头部的列表值序列，例如[1,2,3]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printListFromTailToHead</span><span class="params">(self, listNode)</span>:</span></span><br><span class="line">        res=[]</span><br><span class="line">        <span class="keyword">while</span> listNode:</span><br><span class="line">            res.append(listNode.val)</span><br><span class="line">            listNode=listNode.next</span><br><span class="line">        <span class="keyword">return</span> res[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><h2 id="链表中环的入口结点"><a href="#链表中环的入口结点" class="headerlink" title="链表中环的入口结点"></a>链表中环的入口结点</h2><h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><p>给一个链表，若其中包含环，请找出该链表的环的入口结点，否则，输出null。</p><h3 id="解答-3"><a href="#解答-3" class="headerlink" title="解答"></a>解答</h3><p>遍历这个链表，把链表每个元素记录在list里，然后一旦遇到了重复节点则返回该结点，不然不存在返回None </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">EntryNodeOfLoop</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        stack=[]</span><br><span class="line">        p = pHead</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            <span class="keyword">if</span> p <span class="keyword">in</span> stack:</span><br><span class="line">                <span class="keyword">return</span> p</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stack.append(p)</span><br><span class="line">            p=p.next</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="删除链表中重复的结点"><a href="#删除链表中重复的结点" class="headerlink" title="删除链表中重复的结点"></a>删除链表中重复的结点</h2><h3 id="题目描述-5"><a href="#题目描述-5" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5</p><h3 id="解答-4"><a href="#解答-4" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplication</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="comment"># 如果是空链表或只有一个结点，直接返回原链表</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pHead <span class="keyword">or</span> <span class="keyword">not</span> pHead.next:</span><br><span class="line">            <span class="keyword">return</span> pHead</span><br><span class="line">        <span class="comment"># 如果当前结点值与下个结点值相等，跳到下个结点（以下个结点为起始）</span></span><br><span class="line">        <span class="keyword">if</span> pHead.val==pHead.next.val:</span><br><span class="line">            tmp=pHead.next</span><br><span class="line">            <span class="comment"># 若还与接下来的结点值重复，继续跳到下个结点</span></span><br><span class="line">            <span class="keyword">while</span> tmp <span class="keyword">and</span> pHead.val==tmp.val:</span><br><span class="line">                tmp=tmp.next</span><br><span class="line">            <span class="keyword">return</span> self.deleteDuplication(tmp)</span><br><span class="line">        <span class="comment"># 否则，保留该节点，进行下个结点的递归</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pHead.next=self.deleteDuplication(pHead.next)</span><br><span class="line">            <span class="keyword">return</span> pHead</span><br></pre></td></tr></table></figure><h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><h2 id="替换空格"><a href="#替换空格" class="headerlink" title="替换空格"></a>替换空格</h2><h3 id="题目描述-6"><a href="#题目描述-6" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。</p><h3 id="解答-5"><a href="#解答-5" class="headerlink" title="解答"></a>解答</h3><ul><li><p>方法1：replace函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># s 源字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replaceSpace</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">return</span> s.replace(<span class="string">' '</span>,<span class="string">'%20'</span>)</span><br></pre></td></tr></table></figure></li><li><p>方法2：直接生成新的字符串（如果题目限制在原字符串上修改就GG）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># s 源字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replaceSpace</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        s1=<span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> j==<span class="string">' '</span>:</span><br><span class="line">                s1=s1+<span class="string">'%20'</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                s1=s1+j</span><br><span class="line">        <span class="keyword">return</span> s1</span><br></pre></td></tr></table></figure><p>简化版</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># s 源字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replaceSpace</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        l = [<span class="string">'%20'</span> <span class="keyword">if</span> x == <span class="string">' '</span> <span class="keyword">else</span> x <span class="keyword">for</span> x <span class="keyword">in</span> s]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(l)</span><br></pre></td></tr></table></figure></li></ul><h2 id="正则表达式匹配"><a href="#正则表达式匹配" class="headerlink" title="正则表达式匹配"></a>正则表达式匹配</h2><h3 id="题目描述-7"><a href="#题目描述-7" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数用来匹配包括’.’和’*‘的正则表达式。模式中的字符’.’表示任意一个字符，而’*‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”ab*ac*a”匹配，但是与”aa.a”和”ab*a”均不匹配</p><h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><p>递归的思想：</p><ul><li><p>当模式中的第二个字符是“*”时：</p><ul><li><p>如果字符串第一个字符跟模式第一个字符不匹配，则模式后移2个字符，继续匹配。</p></li><li><p>如果字符串第一个字符跟模式第一个字符匹配，可以有3种匹配方式：</p><ol><li><p>模式后移2字符，相当于x*被忽略；</p></li><li><p>字符串后移1字符，模式后移2字符，相当于x*匹配一位；</p></li><li><p>字符串后移1字符，模式不变，即继续匹配字符下一位，相当于x*匹配多位；</p></li></ol><blockquote><p>情况1：”abcde”与”a*abcde”匹配</p><p>情况2：”abcde”与”a*bcde”匹配</p><p>情况3：”abcde”与”abcd<em>“匹配（递推与”abc\</em>“、”ab*“、”a*“均匹配）</p></blockquote></li></ul></li><li><p>当模式中的第二个字符不是“*”时：</p><ul><li>如果字符串第一个字符和模式中的第一个字符相匹配，那么字符串和模式都后移一个字符，然后匹配剩余的部分。</li><li>如果字符串第一个字符和模式中的第一个字符相不匹配，直接返回False。 </li></ul></li></ul><h3 id="解答-6"><a href="#解答-6" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># s, pattern都是字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">match</span><span class="params">(self, s, pattern)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="comment"># 如果模式和字符串完全相等（包含均为空），则匹配成功</span></span><br><span class="line">        <span class="keyword">if</span> s == pattern:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 如果模式为空，字符串不为空，则匹配不成功</span></span><br><span class="line">        <span class="keyword">elif</span> (s != <span class="string">''</span> <span class="keyword">and</span> pattern == <span class="string">''</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 如果模式不为空，字符串为空</span></span><br><span class="line">        <span class="keyword">elif</span> (s == <span class="string">''</span> <span class="keyword">and</span> pattern != <span class="string">''</span>):</span><br><span class="line">            <span class="keyword">if</span> pattern[<span class="number">-1</span>] == <span class="string">'*'</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 如果模式不为空，字符串不为空</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> len(pattern) == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> pattern == <span class="string">'*'</span> <span class="keyword">or</span> (pattern == <span class="string">'.'</span> <span class="keyword">and</span> len(s) == <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="comment"># 当模式中的第二个字符是'*'时</span></span><br><span class="line">            <span class="keyword">if</span> pattern[<span class="number">1</span>] == <span class="string">'*'</span> <span class="keyword">and</span> len(pattern) &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># 如果字符串第一个字符跟模式第一个字符不匹配</span></span><br><span class="line">                <span class="keyword">if</span> s[<span class="number">0</span>] != pattern[<span class="number">0</span>] <span class="keyword">and</span> pattern[<span class="number">0</span>] != <span class="string">'.'</span> :</span><br><span class="line">                    <span class="keyword">return</span> self.match(s, pattern[<span class="number">2</span>:])</span><br><span class="line">                <span class="comment"># 如果字符串第一个字符跟模式第一个字符匹配</span></span><br><span class="line">                <span class="keyword">elif</span> len(s) &gt; <span class="number">1</span> <span class="keyword">and</span> len(pattern)&gt;<span class="number">1</span>:</span><br><span class="line">                    f1 = self.match(s, pattern[<span class="number">2</span>:]) <span class="comment"># 模式后移2字符</span></span><br><span class="line">                    f2 = self.match(s[<span class="number">1</span>:], pattern[<span class="number">2</span>:]) <span class="comment"># 字符串后移1字符，模式后移2字符</span></span><br><span class="line">                    f3 = self.match(s[<span class="number">1</span>:], pattern) <span class="comment"># 字符串后移1字符</span></span><br><span class="line">                    <span class="keyword">if</span> f1 <span class="keyword">or</span> f2 <span class="keyword">or</span> f3:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> pattern[<span class="number">-1</span>] == <span class="string">'*'</span> <span class="keyword">or</span> pattern[<span class="number">-1</span>] == s[<span class="number">-1</span>]:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="comment"># 当模式中的第二个字符不是'*'时</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果字符串第一个字符和模式中的第一个字符相匹配</span></span><br><span class="line">                <span class="keyword">if</span> s[<span class="number">0</span>] == pattern[<span class="number">0</span>] <span class="keyword">or</span> pattern[<span class="number">0</span>] == <span class="string">'.'</span>:</span><br><span class="line">                    <span class="keyword">return</span> self.match(s[<span class="number">1</span>:], pattern[<span class="number">1</span>:])</span><br><span class="line">                <span class="comment"># 如果字符串第一个字符和模式中的第一个字符相不匹配</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="表示数值的字符串"><a href="#表示数值的字符串" class="headerlink" title="表示数值的字符串"></a>表示数值的字符串</h2><h3 id="题目描述-8"><a href="#题目描述-8" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。</p><h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul><li>正负号<ul><li>第二次出现正负号，则必须紧接在e之后</li><li>第一次出现正负号，且不是在字符串开头，则也必须紧接在e之后</li></ul></li><li>小数点<ul><li>e后面不能接小数点</li><li>小数点不能出现两次</li></ul></li><li>e/E<ul><li>e后面一定要接数字</li><li>不能同时存在两个e</li></ul></li></ul><h3 id="解答-7"><a href="#解答-7" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># s字符串</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isNumeric</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="comment"># 标记符号、小数点、e是否出现过</span></span><br><span class="line">        sign = <span class="literal">False</span></span><br><span class="line">        decimal = <span class="literal">False</span></span><br><span class="line">        hasE = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">            <span class="keyword">if</span> (s[i] == <span class="string">'e'</span> <span class="keyword">or</span> s[i] == <span class="string">'E'</span>):</span><br><span class="line">                <span class="comment"># e后面一定要接数字</span></span><br><span class="line">                <span class="keyword">if</span> (i == len(s)<span class="number">-1</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="comment"># 不能同时存在两个e</span></span><br><span class="line">                <span class="keyword">if</span> (hasE == <span class="literal">True</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                hasE = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> (s[i] == <span class="string">'+'</span> <span class="keyword">or</span> s[i] == <span class="string">'-'</span>):</span><br><span class="line">                <span class="comment"># 第二次出现+-符号，则必须紧接在e之后</span></span><br><span class="line">                <span class="keyword">if</span> (sign <span class="keyword">and</span> s[i<span class="number">-1</span>] != <span class="string">'e'</span> <span class="keyword">and</span> s[i<span class="number">-1</span>] != <span class="string">'E'</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="comment"># 第一次出现+-符号，且不是在字符串开头，则也必须紧接在e之后</span></span><br><span class="line">                <span class="keyword">elif</span> (sign == <span class="literal">False</span> <span class="keyword">and</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> s[i<span class="number">-1</span>] != <span class="string">'e'</span> <span class="keyword">and</span> s[i<span class="number">-1</span>] != <span class="string">'E'</span>):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                sign = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> (s[i] == <span class="string">'.'</span>):</span><br><span class="line">                <span class="comment"># e后面不能接小数点，小数点不能出现两次</span></span><br><span class="line">                <span class="keyword">if</span> (hasE <span class="keyword">or</span> decimal):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                decimal = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 非法字符</span></span><br><span class="line">            <span class="keyword">elif</span>(s[i] &lt; <span class="string">'0'</span> <span class="keyword">or</span> s[i] &gt; <span class="string">'9'</span>):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><h2 id="字符流中第一个不重复的字符"><a href="#字符流中第一个不重复的字符" class="headerlink" title="字符流中第一个不重复的字符"></a>字符流中第一个不重复的字符</h2><h3 id="题目描述-9"><a href="#题目描述-9" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个字符“google”时，第一个只出现一次的字符是”l”。如果当前字符流没有存在出现一次的字符，返回#字符。</p><h3 id="解答-8"><a href="#解答-8" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.s=<span class="string">''</span></span><br><span class="line">        self.dict=&#123;&#125; <span class="comment">#创建字典，key为读取的字符串中的每一个字符，val为每个字符出现的个数的计数值</span></span><br><span class="line">    <span class="comment"># 返回对应char</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FirstAppearingOnce</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.s: <span class="comment"># 遍历字符串s中的字符</span></span><br><span class="line">            <span class="keyword">if</span> self.dict[i]==<span class="number">1</span>: <span class="comment"># 如果某个字符对应的计数为1，则返回该字符</span></span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'#'</span> <span class="comment"># 不存在则返回'#'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Insert</span><span class="params">(self, char)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.s=self.s+char <span class="comment"># 从字符流中读入字符到字符串s中</span></span><br><span class="line">        <span class="keyword">if</span> char <span class="keyword">in</span> self.dict: <span class="comment"># 如果读入的字符在字符串中已存在</span></span><br><span class="line">            self.dict[char]=self.dict[char]+<span class="number">1</span> <span class="comment"># 在字典中对应的字符计数加一</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 如果读入的字符在字符串中不存在</span></span><br><span class="line">            self.dict[char]=<span class="number">1</span> <span class="comment"># 字典中对应的字符计数为一（即新增了一个新的字符）</span></span><br></pre></td></tr></table></figure><h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h2 id="重建二叉树"><a href="#重建二叉树" class="headerlink" title="重建二叉树"></a>重建二叉树</h2><h3 id="题目描述-10"><a href="#题目描述-10" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。</p><h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><blockquote><p>前序遍历：根左右</p><p>中序遍历：左根右</p><p>后序遍历：左右根</p></blockquote><p>步骤：</p><ol><li>根据前序序列第一个结点确定根结点 </li><li>根据根结点在中序序列中的位置分割出左右两个子序列 </li><li>对左子树和右子树分别递归使用同样的方法继续分解 </li></ol><p>例如：<br>前序序列{1,2,4,7,3,5,6,8} = pre<br>中序序列{4,7,2,1,5,3,8,6} = in</p><ol><li>根据当前前序序列的第一个结点确定根结点，为 1 </li><li>找到 1 在中序遍历序列中的位置，为 in[3] </li><li>切割左右子树，则 in[3] 前面的为左子树， in[3] 后面的为右子树 </li><li>则切割后的<strong>左子树前序序列</strong>为：{2,4,7}，切割后的<strong>左子树中序序列</strong>为：{4,7,2}；切割后的<strong>右子树前序序列</strong>为：{3,5,6,8}，切割后的<strong>右子树中序序列</strong>为：{5,3,8,6} </li><li>对子树分别使用同样的方法分解</li></ol><h3 id="解答-9"><a href="#解答-9" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回构造的TreeNode根节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reConstructBinaryTree</span><span class="params">(self, pre, tin)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> len(pre) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        root = TreeNode(pre[<span class="number">0</span>]) <span class="comment"># 用pop会更巧妙</span></span><br><span class="line">        index = tin.index(root.val)</span><br><span class="line">        root.left = self.reConstructBinaryTree(pre[<span class="number">1</span>:index+<span class="number">1</span>],tin[:index])</span><br><span class="line">        root.right = self.reConstructBinaryTree(pre[index+<span class="number">1</span>:],tin[index+<span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><h2 id="二叉树的下一个结点"><a href="#二叉树的下一个结点" class="headerlink" title="二叉树的下一个结点"></a>二叉树的下一个结点</h2><h3 id="题目描述-11"><a href="#题目描述-11" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。</p><h3 id="思路-4"><a href="#思路-4" class="headerlink" title="思路"></a>思路</h3><p>首先明确中序遍历的规则是：左根右，然后作图 </p><p><img src="https://i.loli.net/2020/03/07/G5ANcsvSECuUxP6.png" alt="773262_1514198075109_20151104234034251.png"></p><p>结合图，可分成两大类：</p><ul><li>有右子树的，那么下个结点就是右子树最左边的点；（eg：D，B，E，A，C，G）</li><li>没有右子树的，也可以分成两类：<ul><li>是父节点的左孩子（eg：N，I，L） ，那么父节点就是下一个节点 ； </li><li>是父节点的右孩子（eg：H，J，K，M），不断向根节点遍历，直到当前节点是其父节点的左孩子位置。如果没有（eg：M），那么他就是尾节点。 </li></ul></li></ul><h3 id="解答-10"><a href="#解答-10" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeLinkNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetNext</span><span class="params">(self, pNode)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pNode.right: <span class="comment"># 有右子树，则找右子树最左边的点</span></span><br><span class="line">            p = pNode.right</span><br><span class="line">            <span class="keyword">while</span> p.left:</span><br><span class="line">                p = p.left</span><br><span class="line">            <span class="keyword">return</span> p</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 无右子树</span></span><br><span class="line">            <span class="keyword">while</span> pNode.next: </span><br><span class="line">                <span class="keyword">if</span> (pNode.next.left == pNode): <span class="comment"># 若当前节点是父节点的左孩子</span></span><br><span class="line">                    <span class="keyword">return</span> pNode.next</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                pNode = pNode.next <span class="comment"># 沿着父节点向上遍历</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span> <span class="comment">#到了根节点仍没找到，则返回空</span></span><br></pre></td></tr></table></figure><h2 id="对称的二叉树"><a href="#对称的二叉树" class="headerlink" title="对称的二叉树"></a>对称的二叉树</h2><h3 id="题目描述-12"><a href="#题目描述-12" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。</p><h3 id="解答-11"><a href="#解答-11" class="headerlink" title="解答"></a>解答</h3><p>使用递归</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetrical</span><span class="params">(self, pRoot)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pRoot:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> self.compare(pRoot.left,pRoot.right)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compare</span><span class="params">(self,pRoot1,pRoot2)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pRoot1 <span class="keyword">and</span> <span class="keyword">not</span> pRoot2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pRoot1 <span class="keyword">or</span> <span class="keyword">not</span> pRoot2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> pRoot1.val==pRoot2.val:</span><br><span class="line">            <span class="keyword">return</span> self.compare(pRoot1.left,pRoot2.right) <span class="keyword">and</span> self.compare(pRoot1.right,pRoot2.left)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="按之字形顺序打印二叉树"><a href="#按之字形顺序打印二叉树" class="headerlink" title="按之字形顺序打印二叉树"></a>按之字形顺序打印二叉树</h2><h3 id="题目描述-13"><a href="#题目描述-13" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。</p><h3 id="解答-12"><a href="#解答-12" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Print</span><span class="params">(self, pRoot)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pRoot:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        current = [pRoot] <span class="comment"># 当前层</span></span><br><span class="line">        next_layer = [] <span class="comment"># 当前层子节点</span></span><br><span class="line">        result = [] <span class="comment"># 结果值</span></span><br><span class="line">        count = <span class="number">1</span> <span class="comment"># 用于判断正序或者逆序输出</span></span><br><span class="line">        <span class="keyword">while</span> current:</span><br><span class="line">            <span class="comment"># 把当前层的子节点都添加到下一层</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> current:</span><br><span class="line">                <span class="keyword">if</span> i.left:</span><br><span class="line">                    next_layer.append(i.left)</span><br><span class="line">                <span class="keyword">if</span> i.right:</span><br><span class="line">                    next_layer.append(i.right)</span><br><span class="line">            <span class="comment"># 如果取余2存在，则正序打印，反之亦然</span></span><br><span class="line">            <span class="keyword">if</span> count%<span class="number">2</span>:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                result.append([i.val <span class="keyword">for</span> i <span class="keyword">in</span> current])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                result.append([i.val <span class="keyword">for</span> i <span class="keyword">in</span> current[::<span class="number">-1</span>]])</span><br><span class="line">            <span class="comment">#把下一层换成当前层</span></span><br><span class="line">            current,next_layer = next_layer,[]</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h2 id="把二叉树打印成多行"><a href="#把二叉树打印成多行" class="headerlink" title="把二叉树打印成多行"></a>把二叉树打印成多行</h2><h3 id="题目描述-14"><a href="#题目描述-14" class="headerlink" title="题目描述"></a>题目描述</h3><p>从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。</p><h3 id="解答-13"><a href="#解答-13" class="headerlink" title="解答"></a>解答</h3><p>比上题更简单，不需要对偶数行进行逆序，对上题代码稍加修改即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回二维列表[[1,2],[4,5]]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Print</span><span class="params">(self, pRoot)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pRoot:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        current = [pRoot]</span><br><span class="line">        next_layer = []</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">while</span> current:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> current:</span><br><span class="line">                <span class="keyword">if</span> i.left:</span><br><span class="line">                    next_layer.append(i.left)</span><br><span class="line">                <span class="keyword">if</span> i.right:</span><br><span class="line">                    next_layer.append(i.right)</span><br><span class="line">            result.append([i.val <span class="keyword">for</span> i <span class="keyword">in</span> current])</span><br><span class="line">            current, next_layer = next_layer, []</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h2 id="序列化二叉树"><a href="#序列化二叉树" class="headerlink" title="序列化二叉树"></a>序列化二叉树</h2><h3 id="题目描述-15"><a href="#题目描述-15" class="headerlink" title="题目描述"></a>题目描述</h3><p>请实现两个函数，分别用来序列化和反序列化二叉树</p><p>二叉树的序列化是指：把一棵二叉树按照某种遍历方式的结果以某种格式保存为字符串，从而使得内存中建立起来的二叉树可以持久保存。序列化可以基于先序、中序、后序、层序的二叉树遍历方式来进行修改，序列化的结果是一个字符串，序列化时通过某种符号表示空节点（#），以 ！表示一个结点值的结束（value!）。</p><p>二叉树的反序列化是指：根据某种遍历顺序得到的序列化字符串结果str，重构二叉树。</p><h3 id="思路-5"><a href="#思路-5" class="headerlink" title="思路"></a>思路</h3><p><strong>二叉树的序列化</strong>：将二叉树转换成字符串</p><p><strong>二叉树的反序列化</strong>：通过字符串还原一棵二叉树，返回树的头节点</p><p>例如下面这颗树：</p><p><img src="https://i.loli.net/2020/03/07/xvbok3r1NK7zlSD.png" alt="未命名1583549530.png" style="zoom:67%;"></p><p>先序序列化二叉树：</p><p>上面这棵树的先序序列化结果为：<strong>5!3!2!1!#!#!#!4!#!#!8!7!6!#!#!#!10!9!#!#!11!#!#!</strong> </p><p><img src="https://i.loli.net/2020/03/07/dg17canVFS6EtXo.png" alt="未命名1583549545.png" style="zoom:67%;"></p><p> 从上图中我们可以看出在<strong>节点为空</strong>的位置使用”<strong>#!</strong>“来代替,每个<strong>节点后的数值</strong>都添加一个”<strong>!</strong>“ </p><h3 id="解答-14"><a href="#解答-14" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    ss = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Serialize</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'#!'</span></span><br><span class="line">        <span class="keyword">return</span> str(root.val) +<span class="string">'!'</span>+ self.Serialize(root.left) + self.Serialize(root.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Deserialize</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(s)==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> s[<span class="number">0</span>] == <span class="string">'#'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        self.ss = s.split(<span class="string">'!'</span>)</span><br><span class="line">        <span class="keyword">return</span> self.reconstruct()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reconstruct</span><span class="params">(self)</span>:</span></span><br><span class="line">        val = self.ss[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> val == <span class="string">'#'</span>:</span><br><span class="line">            self.ss = self.ss[<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        val = int(val)</span><br><span class="line">        root = TreeNode(val)</span><br><span class="line">        self.ss = self.ss[<span class="number">1</span>:]</span><br><span class="line">        root.left = self.reconstruct()</span><br><span class="line">        root.right = self.reconstruct()</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><p>(这里反序列化的原字符串没有’!’吗？)</p><h2 id="二叉搜索树的第k个结点"><a href="#二叉搜索树的第k个结点" class="headerlink" title="二叉搜索树的第k个结点"></a>二叉搜索树的第k个结点</h2><h3 id="题目描述-16"><a href="#题目描述-16" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一棵二叉搜索树，请找出其中的第k小的结点。例如，(5,3,7,2,4,6,8)中，按结点数值大小顺序第三小结点的值为4。</p><h3 id="思路-6"><a href="#思路-6" class="headerlink" title="思路"></a>思路</h3><p>二叉搜索树：</p><p>它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。 </p><p>中序遍历就是一个树从小到大的排列顺序，因此只需要求出中序遍历到第k个元素就是所需的节点</p><h3 id="解答-15"><a href="#解答-15" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回对应节点TreeNode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">KthNode</span><span class="params">(self, pRoot, k)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.res=[]</span><br><span class="line">        self.mid(pRoot)</span><br><span class="line">        <span class="keyword">return</span> self.res[k<span class="number">-1</span>] <span class="keyword">if</span> <span class="number">0</span>&lt;k&lt;=len(self.res) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mid</span><span class="params">(self,root)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        self.mid(root.left)</span><br><span class="line">        self.res.append(root)</span><br><span class="line">        self.mid(root.right)</span><br></pre></td></tr></table></figure><h2 id="数据流中的中位数"><a href="#数据流中的中位数" class="headerlink" title="数据流中的中位数"></a>数据流中的中位数</h2><h3 id="题目描述-17"><a href="#题目描述-17" class="headerlink" title="题目描述"></a>题目描述</h3><p>如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。</p><h3 id="解答-16"><a href="#解答-16" class="headerlink" title="解答"></a>解答</h3><p>用一个数组存输入的所有数字，另一个数组存输入的所有数字排序的编号<br>求中位数时，找根据编号数组找中位数位置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    arr = []</span><br><span class="line">    idx = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Insert</span><span class="params">(self, num)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(self.arr) == <span class="number">0</span>:</span><br><span class="line">            self.arr.append(num)</span><br><span class="line">            self.idx.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            idx_tmp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.arr)):</span><br><span class="line">                <span class="keyword">if</span> self.arr[i] &lt; num:</span><br><span class="line">                    idx_tmp += <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> self.arr[i] &gt; num:</span><br><span class="line">                    self.idx[i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    idx_tmp = self.idx[i]</span><br><span class="line">            self.arr.append(num)</span><br><span class="line">            self.idx.append(idx_tmp)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetMedian</span><span class="params">(self, n=None)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        tmp = len(self.arr)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> len(self.arr)%<span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.idx)):</span><br><span class="line">                <span class="keyword">if</span> self.idx[i] == (tmp<span class="number">-1</span>):</span><br><span class="line">                    res += self.arr[i]</span><br><span class="line">                <span class="keyword">elif</span> self.idx[i] == tmp:</span><br><span class="line">                    res += self.arr[i]</span><br><span class="line">            res = res/<span class="number">2.0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.idx)):</span><br><span class="line">                <span class="keyword">if</span> self.idx[i] == tmp:</span><br><span class="line">                    res += self.arr[i]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h1 id="栈和队列"><a href="#栈和队列" class="headerlink" title="栈和队列"></a>栈和队列</h1><h2 id="用两个栈实现队列"><a href="#用两个栈实现队列" class="headerlink" title="用两个栈实现队列"></a>用两个栈实现队列</h2><h3 id="题目描述-18"><a href="#题目描述-18" class="headerlink" title="题目描述"></a>题目描述</h3><p>用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。</p><h3 id="解答-17"><a href="#解答-17" class="headerlink" title="解答"></a>解答</h3><ul><li>栈A用来作入队列</li><li>栈B用来出队列，当栈B为空时，栈A全部出栈到栈B，栈B再出栈（即出队列）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.stackA = []</span><br><span class="line">        self.stackB = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, node)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.stackA.append(node)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># return xx</span></span><br><span class="line">        <span class="keyword">if</span> self.stackB: <span class="comment"># 如果栈B不为空</span></span><br><span class="line">            <span class="keyword">return</span> self.stackB.pop()</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> self.stackA: <span class="comment"># 如果两个都是空的</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 如果栈B为空，栈A不为空</span></span><br><span class="line">            <span class="keyword">while</span> self.stackA:</span><br><span class="line">                self.stackB.append(self.stackA.pop())</span><br><span class="line">            <span class="keyword">return</span> self.stackB.pop()</span><br></pre></td></tr></table></figure><h2 id="滑动窗口的最大值"><a href="#滑动窗口的最大值" class="headerlink" title="滑动窗口的最大值"></a>滑动窗口的最大值</h2><h3 id="题目描述-19"><a href="#题目描述-19" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。</p><h3 id="解答-18"><a href="#解答-18" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxInWindows</span><span class="params">(self, num, size)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res, i = [], <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> size &gt; <span class="number">0</span> <span class="keyword">and</span> i + size - <span class="number">1</span> &lt; len(num):</span><br><span class="line">            res.append(max(num[i:i + size]))</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h1 id="查找和排序"><a href="#查找和排序" class="headerlink" title="查找和排序"></a>查找和排序</h1><h2 id="旋转数组的最小数字"><a href="#旋转数组的最小数字" class="headerlink" title="旋转数组的最小数字"></a>旋转数组的最小数字</h2><h3 id="题目描述-20"><a href="#题目描述-20" class="headerlink" title="题目描述"></a>题目描述</h3><p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。<br>输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。<br>例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。<br>NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。</p><h3 id="思路-7"><a href="#思路-7" class="headerlink" title="思路"></a>思路</h3><p>二分查找变种，没有具体的值用来比较。那么用中间值和高低位进行比较，看处于递增还是递减序列，进行操作缩小范围。 </p><ul><li>处于递增：low上移</li><li>处于递减：high下移（如果是<code>high-1</code>，则可能会错过最小值，因为找的就是最小值）</li><li>其余情况：low++缩小范围</li></ul><p><img src="https://i.loli.net/2020/03/07/LlCRrYUq5Aeo8Qa.png" alt="807319133_1566217781994_E0D8DA4D79E73A35EB4365215E2F13BB.png"></p><p>特殊情况</p><p><img src="https://i.loli.net/2020/03/07/WbNYh9C2FAXErBo.png" alt="807319133_1566442034216_88777DA092B0D79C405886B923CA4344.png"></p><h3 id="解答-19"><a href="#解答-19" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minNumberInRotateArray</span><span class="params">(self, rotateArray)</span>:</span></span><br><span class="line">        <span class="comment"># write code here </span></span><br><span class="line">        low = <span class="number">0</span></span><br><span class="line">        high = len(rotateArray) - <span class="number">1</span></span><br><span class="line">        mid = low + (high - low) / <span class="number">2</span> <span class="comment">#Python2.7可以直接除得到整数，Python3需要加int()</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high:</span><br><span class="line">            <span class="keyword">if</span> rotateArray[low] &lt; rotateArray[high]:</span><br><span class="line">                <span class="keyword">return</span> rotateArray[low]</span><br><span class="line">            <span class="keyword">if</span> rotateArray[mid] &lt; rotateArray[high]:<span class="comment"># 位于递减数组</span></span><br><span class="line">                high = mid</span><br><span class="line">            <span class="keyword">elif</span> rotateArray[mid] &gt; rotateArray[low]: <span class="comment"># 位于递增数组</span></span><br><span class="line">                low = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                low += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> rotateArray[low]</span><br></pre></td></tr></table></figure><h1 id="递归和循环"><a href="#递归和循环" class="headerlink" title="递归和循环"></a>递归和循环</h1><h2 id="斐波那契数列"><a href="#斐波那契数列" class="headerlink" title="斐波那契数列"></a>斐波那契数列</h2><h3 id="题目描述-21"><a href="#题目描述-21" class="headerlink" title="题目描述"></a>题目描述</h3><p>大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。</p><p>n&lt;=39</p><h3 id="解答-20"><a href="#解答-20" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Fibonacci</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            a,b = b, a+b</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><h2 id="跳台阶"><a href="#跳台阶" class="headerlink" title="跳台阶"></a>跳台阶</h2><h3 id="题目描述-22"><a href="#题目描述-22" class="headerlink" title="题目描述"></a>题目描述</h3><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。</p><h3 id="思路-8"><a href="#思路-8" class="headerlink" title="思路"></a>思路</h3><p>前提：只有一次一阶或者两阶的跳法</p><ol><li><p>通过实际的情况可以得出：只有一阶的时候f(1) = 1，只有两阶的时候f(2) = 2  </p></li><li><p>假定第一次跳的是一阶，那么剩下的是n-1个台阶，跳法是f(n-1)</p><p>假定第一次跳的是两阶，那么剩下的是n-2个台阶，跳法是f(n-2)  </p><p>可以得出总跳法为: f(n) = f(n-1) + f(n-2)  </p></li><li><p>可以发现最终得出的是一个斐波那契数列：</p><script type="math/tex; mode=display">f(n)=\left\{\begin{array}{**lr**} 1, &n=1\\2,&n=2\\f(n-1)+f(n-2),&n>2\end{array} \right.</script></li></ol><h3 id="解答-21"><a href="#解答-21" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">jumpFloor</span><span class="params">(self, number)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(number<span class="number">-1</span>):</span><br><span class="line">            a, b = b, a+b</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><p>（与上题的初始条件不同）</p><h2 id="变态跳台阶"><a href="#变态跳台阶" class="headerlink" title="变态跳台阶"></a>变态跳台阶</h2><h3 id="题目描述-23"><a href="#题目描述-23" class="headerlink" title="题目描述"></a>题目描述</h3><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。</p><h3 id="思路-9"><a href="#思路-9" class="headerlink" title="思路"></a>思路</h3><p> 前提：n个台阶会有一次1,2,…,n阶的跳法 </p><ul><li><p>n = 1时，只有1种跳法，f(1) = 1（这里的f(n)代表的是n个台阶的跳法数）</p></li><li><p>n = 2时，会有两个跳的方式，一次1阶或者2阶，这回归到了问题(1)，f(2) = f(2-1) + f(2-2) </p></li><li><p>n = 3时，会有三种跳的方式：1阶、2阶、3阶， 那么就是第一次跳出1阶后面剩下：f(3-1)；第一次跳出2阶，剩下f(3-2)；第一次3阶，那么剩下f(3-3) 。因此，f(3) = f(3-1)+f(3-2)+f(3-3) </p></li><li><p>… </p></li><li><p>n = n时，会有n种跳的方式：1阶、2阶…n阶，得出结论： f(n) = f(n-1)+f(n-2)+…+f(n-(n-1)) + f(n-n) =&gt;  f(0) + f(1) + f(2) + f(3) + … + f(n-1) + f(n) = f(n-1) + f(n-2) + f(n-3) + … + f(n-(n-1)) + f(n-n) </p></li><li><p>可以继续简化： </p><p>f(n-1) = f(0) + f(1)+f(2)+f(3) + … + f((n-1)-1) =  f(0) + f(1) + f(2) + f(3) + … + f(n-2) </p><p>f(n) =[ f(0) + f(1) + f(2) + f(3) + … + f(n-2) ] +  f(n-1) = f(n-1) + f(n-1) = 2 * f(n-1) </p></li><li><p>得出最终结论，n阶台阶总的跳法为： </p><script type="math/tex; mode=display">f(n)=\left\{\begin{array}{**lr**} 1, &n=0\\1,&n=1\\2f(n-1),&n>1\end{array} \right.</script></li></ul><h3 id="解答-22"><a href="#解答-22" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">jumpFloorII</span><span class="params">(self, number)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span>**(number<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><h2 id="矩形覆盖"><a href="#矩形覆盖" class="headerlink" title="矩形覆盖"></a>矩形覆盖</h2><h3 id="题目描述-24"><a href="#题目描述-24" class="headerlink" title="题目描述"></a>题目描述</h3><p>我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？</p><p>比如n=3时，2*3的矩形块有3种覆盖方法：</p><p> <img src="https://uploadfiles.nowcoder.com/images/20200218/6384065_1581999858239_64E40A35BE277D7E7C87D4DCF588BE84" alt="img"> </p><h3 id="思路-10"><a href="#思路-10" class="headerlink" title="思路"></a>思路</h3><p>依旧是斐波那契数列 </p><p>target*2为大矩阵的大小 </p><p>有以下几种情形： </p><ol><li><p>target &lt;= 0，大矩形为&lt;= 2*0，直接return 1； </p></li><li><p>target = 1，大矩形为2*1，只有一种摆放方法，return 1； </p></li><li><p>target = 2，大矩形为2*2，有两种摆放方法，return 2； </p></li><li><p>target = n，分为两步考虑： </p><p>第一次摆放一块 2*1 的小矩阵，则摆放方法总共为 f(target - 1)</p><p>第一次摆放一块 1*2 的小矩阵，则摆放方法总共为 f(target - 2)</p></li></ol><p>得到通项公式为</p><script type="math/tex; mode=display">f(n)=\left\{\begin{array}{**lr**} 1, &n=1\\2,&n=2\\f(n-1)+f(n-2),&n>2\end{array} \right.</script><h3 id="解答-23"><a href="#解答-23" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rectCover</span><span class="params">(self, number)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> number &lt;= <span class="number">0</span>: <span class="comment"># 考虑特殊情况</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(number<span class="number">-1</span>):</span><br><span class="line">            a, b = b,a+b</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h1><h2 id="二进制中1的个数"><a href="#二进制中1的个数" class="headerlink" title="二进制中1的个数"></a>二进制中1的个数</h2><h3 id="题目描述-25"><a href="#题目描述-25" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。</p><h3 id="思路-11"><a href="#思路-11" class="headerlink" title="思路"></a>思路</h3><p>如果一个整数不为0，那么这个整数至少有一位是1。如果我们把这个整数减1，那么原来处在整数最右边的1就会变为0，原来在1后面的所有的0都会变成1(如果最右边的1后面还有0的话)。其余所有位将不会受到影响。 </p><p>举个例子：一个二进制数1100，从右边数起第三位是处于最右边的一个1。减去1后，第三位变成0，它后面的两位0变成了1，而前面的1保持不变，因此得到的结果是1011.我们发现减1的结果是把最右边的一个1开始的所有位都取反了。这个时候如果我们再把原来的整数和减去1之后的结果做与运算，从原来整数最右边一个1那一位开始所有位都会变成0。如1100&amp;1011=1000.也就是说，把一个整数减去1，再和原整数做与运算，会把该整数最右边一个1变成0.那么一个整数的二进制有多少个1，就可以进行多少次这样的操作。</p><h3 id="解答-24"><a href="#解答-24" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">NumberOf1</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">0</span>:</span><br><span class="line">            n = n &amp; <span class="number">0xffffffff</span></span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">            n = (n - <span class="number">1</span>) &amp; n</span><br><span class="line">        <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure><p>【解释一下】n = n &amp; 0xffffffff，在Python中，数的大小是可以无限扩大的，所以对于一个负数而言，进行了这个操作，实际上是提取了负数的后32位（在计算机中以补码形式存在），前面的任意位呢，则变成了0，比如说 -1，一开始是 111…..(n个1)…11111111，进行与运算之后，得到，00….(n个0)….111111111（32个1），变成了含32个1的正数，然后就不用担心负数陷入死循环。 </p><h1 id="代码的完整性"><a href="#代码的完整性" class="headerlink" title="代码的完整性"></a>代码的完整性</h1><h2 id="数值的整数次方"><a href="#数值的整数次方" class="headerlink" title="数值的整数次方"></a>数值的整数次方</h2><h3 id="题目描述-26"><a href="#题目描述-26" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。</p><p>保证base和exponent不同时为0</p><h3 id="思路-12"><a href="#思路-12" class="headerlink" title="思路"></a>思路</h3><p>优化求幂函数：<br>当n为偶数，$a^n =a^{\frac{n}{2}}<em>a^{\frac{n}{2}}$<br>当n为奇数，$a^n = a^{\frac{n-1}{2}}</em>a^{\frac{n-1}{2}}* a$</p><h3 id="解答-25"><a href="#解答-25" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Power</span><span class="params">(self, base, exponent)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res = base</span><br><span class="line">        flag = <span class="number">1</span> <span class="comment"># 判断正负</span></span><br><span class="line">        <span class="keyword">if</span> exponent == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> exponent &lt; <span class="number">0</span>:</span><br><span class="line">            exponent *= <span class="number">-1</span> <span class="comment"># 将负数转化为正数</span></span><br><span class="line">            flag = <span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> exponent == <span class="number">1</span>:</span><br><span class="line">                res *= base</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            res *= res</span><br><span class="line">            exponent = exponent // <span class="number">2</span> <span class="comment"># 整除</span></span><br><span class="line">        <span class="keyword">return</span> res <span class="keyword">if</span> flag == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> / res</span><br></pre></td></tr></table></figure><h2 id="调整数组顺序使奇数位于偶数前面"><a href="#调整数组顺序使奇数位于偶数前面" class="headerlink" title="调整数组顺序使奇数位于偶数前面"></a>调整数组顺序使奇数位于偶数前面</h2><h3 id="题目描述-27"><a href="#题目描述-27" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。</p><h3 id="解法-1"><a href="#解法-1" class="headerlink" title="解法"></a>解法</h3><p>方法1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reOrderArray</span><span class="params">(self, array)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        odd, even = [], []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> array:</span><br><span class="line">            odd.append(i) <span class="keyword">if</span> i%<span class="number">2</span> == <span class="number">1</span> <span class="keyword">else</span> even.append(i)</span><br><span class="line">        <span class="keyword">return</span> odd + even</span><br></pre></td></tr></table></figure><p>方法2（lambda）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reOrderArray</span><span class="params">(self, array)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">return</span> sorted(array, key = <span class="keyword">lambda</span> c:c%<span class="number">2</span>, reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h1 id="代码的鲁棒性"><a href="#代码的鲁棒性" class="headerlink" title="代码的鲁棒性"></a>代码的鲁棒性</h1><h2 id="链表中倒数第k个结点"><a href="#链表中倒数第k个结点" class="headerlink" title="链表中倒数第k个结点"></a>链表中倒数第k个结点</h2><h3 id="题目描述-28"><a href="#题目描述-28" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个链表，输出该链表中倒数第k个结点。</p><h3 id="解答-26"><a href="#解答-26" class="headerlink" title="解答"></a>解答</h3><p>使用list遍历整个链表（Note：题目要求返回的是结点，非结点的值）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindKthToTail</span><span class="params">(self, head, k)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            res.append(head)</span><br><span class="line">            head = head.next</span><br><span class="line">        <span class="keyword">if</span> k &gt; len(res) <span class="keyword">or</span> k &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> res[-k]</span><br></pre></td></tr></table></figure><h2 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h2><h3 id="题目描述-29"><a href="#题目描述-29" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个链表，反转链表后，输出新链表的表头。</p><h3 id="思路-13"><a href="#思路-13" class="headerlink" title="思路"></a>思路</h3><p><img src="https://i.loli.net/2020/03/07/fXnZyFCOW3qE2Hr.png" alt="1583488259173.png"></p><p><img src="https://i.loli.net/2020/03/07/UftMyoHkPpsXhrw.png" alt="1583505544057.png"></p><h3 id="解答-27"><a href="#解答-27" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回ListNode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ReverseList</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pHead <span class="keyword">or</span> <span class="keyword">not</span> pHead.next:</span><br><span class="line">            <span class="keyword">return</span> pHead</span><br><span class="line">        pre = <span class="literal">None</span></span><br><span class="line">        cur = pHead</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            tmp = cur.next</span><br><span class="line">            cur.next = pre</span><br><span class="line">            pre = cur</span><br><span class="line">            cur = tmp</span><br><span class="line">        <span class="keyword">return</span> pre</span><br></pre></td></tr></table></figure><h2 id="合并两个排序的链表"><a href="#合并两个排序的链表" class="headerlink" title="合并两个排序的链表"></a>合并两个排序的链表</h2><h3 id="题目描述-30"><a href="#题目描述-30" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。</p><h3 id="思路-14"><a href="#思路-14" class="headerlink" title="思路"></a>思路</h3><p> <img src="https://uploadfiles.nowcoder.com/images/20170119/3111850_1484789893742_6903DA8DDE03E5B02CCB5F97FC3E53C2" alt="img" style="zoom:67%;"> </p><h3 id="解答-28"><a href="#解答-28" class="headerlink" title="解答"></a>解答</h3><p>方法1：非递归</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回合并后列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Merge</span><span class="params">(self, pHead1, pHead2)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        cur = ListNode(<span class="number">0</span>)</span><br><span class="line">        pHead = cur </span><br><span class="line">        <span class="keyword">while</span> pHead1 <span class="keyword">and</span> pHead2:</span><br><span class="line">            <span class="keyword">if</span> pHead1.val &lt; pHead2.val:</span><br><span class="line">                cur.next = pHead1</span><br><span class="line">                pHead1 = pHead1.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur.next = pHead2</span><br><span class="line">                pHead2 = pHead2.next</span><br><span class="line">            cur = cur.next</span><br><span class="line">        <span class="keyword">if</span> pHead1:</span><br><span class="line">            cur.next = pHead1</span><br><span class="line">        <span class="keyword">elif</span> pHead2:</span><br><span class="line">            cur.next = pHead2</span><br><span class="line">        <span class="keyword">return</span> pHead.next <span class="comment"># pHead始终指向第一个节点</span></span><br></pre></td></tr></table></figure><p>方法2：递归</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Merge</span><span class="params">(self, pHead1, pHead2)</span>:</span></span><br><span class="line">    <span class="comment"># write code here</span></span><br><span class="line">    <span class="keyword">if</span> pHead1 <span class="keyword">and</span> pHead2:</span><br><span class="line">        <span class="keyword">if</span> pHead1.val &gt; pHead2.val:</span><br><span class="line">            pHead1, pHead2 = pHead2, pHead1</span><br><span class="line">        pHead1.next = self.Merge(pHead1.next, pHead2)</span><br><span class="line">    <span class="keyword">return</span> pHead1 <span class="keyword">or</span> pHead2</span><br></pre></td></tr></table></figure><h2 id="树的子结构"><a href="#树的子结构" class="headerlink" title="树的子结构"></a>树的子结构</h2><h3 id="题目描述-31"><a href="#题目描述-31" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构）</p><h3 id="解答-29"><a href="#解答-29" class="headerlink" title="解答"></a>解答</h3><p>使用前序遍历转化为字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">HasSubtree</span><span class="params">(self, pRoot1, pRoot2)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(p)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> p:</span><br><span class="line">                <span class="keyword">return</span> str(p.val) +  convert(p.left) + convert(p.right)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">        <span class="keyword">return</span> convert(pRoot2) <span class="keyword">in</span> convert(pRoot1) <span class="keyword">if</span> pRoot2 <span class="keyword">else</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h1 id="面试思路"><a href="#面试思路" class="headerlink" title="面试思路"></a>面试思路</h1><h2 id="二叉树的镜像"><a href="#二叉树的镜像" class="headerlink" title="二叉树的镜像"></a>二叉树的镜像</h2><h3 id="题目描述-32"><a href="#题目描述-32" class="headerlink" title="题目描述"></a>题目描述</h3><p>操作给定的二叉树，将其变换为源二叉树的镜像。</p><h3 id="输入描述"><a href="#输入描述" class="headerlink" title="输入描述"></a>输入描述</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">二叉树的镜像定义：源二叉树 </span><br><span class="line">        8</span><br><span class="line">       /  \</span><br><span class="line">      6   10</span><br><span class="line">     / \  / \</span><br><span class="line">    5  7 9 11</span><br><span class="line">    镜像二叉树</span><br><span class="line">        8</span><br><span class="line">       /  \</span><br><span class="line">      10   6</span><br><span class="line">     / \  / \</span><br><span class="line">    11 9 7  5</span><br></pre></td></tr></table></figure><h3 id="解答-30"><a href="#解答-30" class="headerlink" title="解答"></a>解答</h3><p>采用递归的思想</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回镜像树的根节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Mirror</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> root:</span><br><span class="line">            root.left,root.right=self.Mirror(root.right),self.Mirror(root.left)</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h1 id="画图让抽象形象化"><a href="#画图让抽象形象化" class="headerlink" title="画图让抽象形象化"></a>画图让抽象形象化</h1><h2 id="顺时针打印矩阵"><a href="#顺时针打印矩阵" class="headerlink" title="顺时针打印矩阵"></a>顺时针打印矩阵</h2><h3 id="题目描述-33"><a href="#题目描述-33" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.</p><h3 id="思路-15"><a href="#思路-15" class="headerlink" title="思路"></a>思路</h3><p>用旋转魔法的方式，一直取出第一行：</p><p>   例如  </p><p>   1 2 3  </p><p>   4 5 6  </p><p>   7 8 9  </p><p>   输出并删除第一行后，变为  </p><p>   4 5 6  </p><p>   7 8 9  </p><p>   再进行一次逆时针旋转，就变成：  </p><p>   6 9  </p><p>   5 8  </p><p>   4 7  </p><p>   继续重复上述操作即可。</p><h3 id="解答-31"><a href="#解答-31" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># matrix类型为二维列表，需要返回列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printMatrix</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        s=[]</span><br><span class="line">        <span class="keyword">while</span> matrix:</span><br><span class="line">            s+=matrix[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">del</span> matrix[<span class="number">0</span>]</span><br><span class="line">            matrix=list(zip(*matrix))[::<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><h1 id="举例让抽象具体化"><a href="#举例让抽象具体化" class="headerlink" title="举例让抽象具体化"></a>举例让抽象具体化</h1><h2 id="包含min函数的栈"><a href="#包含min函数的栈" class="headerlink" title="包含min函数的栈"></a>包含min函数的栈</h2><h3 id="题目描述-34"><a href="#题目描述-34" class="headerlink" title="题目描述"></a>题目描述</h3><p>定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的min函数（时间复杂度应为O(1)）。</p><p>注意：保证测试中不会当栈为空的时候，对栈调用pop()或者min()或者top()方法。</p><h1 id="时间效率"><a href="#时间效率" class="headerlink" title="时间效率"></a>时间效率</h1><h2 id="数组中出现次数超过一半的数字"><a href="#数组中出现次数超过一半的数字" class="headerlink" title="数组中出现次数超过一半的数字"></a>数组中出现次数超过一半的数字</h2><h3 id="题目描述-35"><a href="#题目描述-35" class="headerlink" title="题目描述"></a>题目描述</h3><p> 数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 </p><h3 id="解答-32"><a href="#解答-32" class="headerlink" title="解答"></a>解答</h3><p>用python的标准库collections </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">MoreThanHalfNum_Solution</span><span class="params">(self, numbers)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        c = Counter(numbers).most_common()</span><br><span class="line">        <span class="keyword">if</span> c[<span class="number">0</span>][<span class="number">1</span>] &gt; len(numbers)/<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> c[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><blockquote><p>此处使用了函数Counter().most_common()，使用方法如下</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试1：输入字符串</span></span><br><span class="line">str = <span class="string">"ashduioashfahuoif"</span></span><br><span class="line"></span><br><span class="line">Counter(str)</span><br><span class="line"><span class="comment">#Counter(&#123;'a': 3, 'h': 3, 's': 2, 'u': 2, 'i': 2, 'o': 2, 'f': 2, 'd': 1&#125;)</span></span><br><span class="line"></span><br><span class="line">Counter(str).most_common(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#[('a', 3), ('h', 3), ('s', 2)]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试2：输入list</span></span><br><span class="line">list_test = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">Counter(list_test).most_common(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#[(1, 4), (2, 3), (3, 2)]</span></span><br></pre></td></tr></table></figure><h2 id="最小的K个数"><a href="#最小的K个数" class="headerlink" title="最小的K个数"></a>最小的K个数</h2><h3 id="题目描述-36"><a href="#题目描述-36" class="headerlink" title="题目描述"></a>题目描述</h3><p> 输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 </p><h3 id="解答-33"><a href="#解答-33" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetLeastNumbers_Solution</span><span class="params">(self, tinput, k)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> k &gt; len(tinput):</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        tinput.sort()</span><br><span class="line">        <span class="keyword">return</span> tinput[:k]</span><br></pre></td></tr></table></figure><blockquote><p>主要考察排序算法，常见排序算法整理如下（替换sort()）</p><p>待补充……</p></blockquote><h2 id="连续子数组的最大和"><a href="#连续子数组的最大和" class="headerlink" title="连续子数组的最大和"></a>连续子数组的最大和</h2><h3 id="题目描述-37"><a href="#题目描述-37" class="headerlink" title="题目描述"></a>题目描述</h3><p>HZ偶尔会拿些专业问题来忽悠那些非计算机专业的同学。今天测试组开完会后,他又发话了:在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1) </p><h3 id="思路-16"><a href="#思路-16" class="headerlink" title="思路"></a>思路</h3><p>动态规划：</p><p>dp[i]表示以元素array[i]结尾的最大连续子数组和 </p><p>以[-2,-3,4,-1,-2,1,5,-3]为例，可以发现：</p><p>dp[0] = -2 </p><p>dp[1] = -3 </p><p>dp[2] = 4 </p><p>dp[3] = 3 </p><p>以此类推，会发现 </p><p>dp[i] = max(dp[i-1]+array[i], array[i])</p><h3 id="解答-34"><a href="#解答-34" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindGreatestSumOfSubArray</span><span class="params">(self, array)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        x = [i <span class="keyword">for</span> i <span class="keyword">in</span> array]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(x)):</span><br><span class="line">            x[i] = max(array[i],array[i]+x[i<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">return</span> max(x)</span><br></pre></td></tr></table></figure><h2 id="整数中1出现的次数"><a href="#整数中1出现的次数" class="headerlink" title="整数中1出现的次数"></a>整数中1出现的次数</h2><h3 id="题目描述-38"><a href="#题目描述-38" class="headerlink" title="题目描述"></a>题目描述</h3><p>求出1-13的整数中1出现的次数，并算出100-1300的整数中1出现的次数？为此他特别数了一下1-13中包含1的数字有1、10、11、12、13，因此共出现6次，但是对于后面问题他就没辙了。ACMer希望你们帮帮他，并把问题更加普遍化，可以很快的求出任意非负整数区间中1出现的次数（从1 到 n 中1出现的次数）。 </p><h3 id="解答-35"><a href="#解答-35" class="headerlink" title="解答"></a>解答</h3><p>暴力法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">NumberOf1Between1AndN_Solution</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        cnt = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">            cnt += str(i).count(<span class="string">'1'</span>)</span><br><span class="line">        <span class="keyword">return</span> cnt</span><br></pre></td></tr></table></figure><h2 id="把数组排成最小的数"><a href="#把数组排成最小的数" class="headerlink" title="把数组排成最小的数"></a>把数组排成最小的数</h2><h3 id="题目描述-39"><a href="#题目描述-39" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 </p><h3 id="解答-36"><a href="#解答-36" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">PrintMinNumber</span><span class="params">(self, numbers)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> numbers:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">        numbers = list(map(str,numbers))</span><br><span class="line">        numbers.sort(cmp = <span class="keyword">lambda</span> x,y: cmp(x+y,y+x))</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(numbers).lstrip(<span class="string">'0'</span>)</span><br></pre></td></tr></table></figure><h1 id="时间空间效率的平衡"><a href="#时间空间效率的平衡" class="headerlink" title="时间空间效率的平衡"></a>时间空间效率的平衡</h1><h2 id="丑数"><a href="#丑数" class="headerlink" title="丑数"></a>丑数</h2><h3 id="题目描述-40"><a href="#题目描述-40" class="headerlink" title="题目描述"></a>题目描述</h3><p>把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 </p><h3 id="解答-37"><a href="#解答-37" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetUglyNumber_Solution</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res=[<span class="number">2</span>**i*<span class="number">3</span>**j*<span class="number">5</span>**k <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>) <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">30</span>) <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">30</span>)]</span><br><span class="line">        res.sort()</span><br><span class="line">        <span class="keyword">return</span> res[index<span class="number">-1</span>] <span class="keyword">if</span> index <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h2 id="第一个只出现一次的字符"><a href="#第一个只出现一次的字符" class="headerlink" title="第一个只出现一次的字符"></a>第一个只出现一次的字符</h2><h3 id="题目描述-41"><a href="#题目描述-41" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个字符串（0&lt;=字符串长度&lt;=10000，全部由字母组成）中找到第一个只出现一次的字符，并返回它的位置，如果没有则返回 -1（需要区分大小写）. </p><h3 id="解答-38"><a href="#解答-38" class="headerlink" title="解答"></a>解答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FirstNotRepeatingChar</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> s==<span class="string">''</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> s.count(i)==<span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> s.index(i)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br></pre></td></tr></table></figure><h2 id="数组中的逆序对"><a href="#数组中的逆序对" class="headerlink" title="数组中的逆序对"></a>数组中的逆序对</h2><h3 id="题目描述-42"><a href="#题目描述-42" class="headerlink" title="题目描述"></a>题目描述</h3><p> 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007 </p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Coding </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白板推导系列8——指数族分布</title>
      <link href="/2020/02/11/bai-ban-tui-dao-xi-lie-8-zhi-shu-zu-fen-bu/"/>
      <url>/2020/02/11/bai-ban-tui-dao-xi-lie-8-zhi-shu-zu-fen-bu/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>指数族分布包括：</p><p>正态分布、伯努利分布、二项分布、泊松分布、Beta分布、Gamma分布等</p><h2 id="形式"><a href="#形式" class="headerlink" title="形式"></a>形式</h2><script type="math/tex; mode=display">P(x|\eta)=h(x)\exp(\eta^T\phi(x)-A(\eta))</script><p>其中，包含以下部分：</p><ul><li><p>$\eta$：参数向量</p></li><li><p>$A(\eta)$：对数配分函数log partition function</p><blockquote><p>partition function：配分函数</p><p>如$P(x|\theta)=\frac{1}{z}\hat{P}(x|\theta)$，其中分母$z=\int \hat{P}(x|\theta)dx$是归一化因子，也称配分函数</p><p>此处$P(x|\eta)=h(x)\exp(\eta^T\phi(x)-A(\eta))=\frac{1}{\exp(A(\eta))}[h(x)\exp(\eta^T\phi(x))]$</p><p>可以认为$z=\exp(A(\eta))$，从而$A(\eta)=\log z$，从而称为对数配分函数</p></blockquote></li><li><p>$\phi(x)$：充分统计量</p><blockquote><p>充分统计量：对样本的加工。数学形式上，就是关于样本的一个函数，包括均值，方差等</p><p>该统计量可以完整地包含样本所包含的信息，可以起到压缩数据的作用。</p><p>比如对于正态分布来说，样本均值和样本方差所组成的向量即为充分统计量。</p></blockquote></li></ul><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li><p>充分统计量</p></li><li><p>共轭</p><p>对于$P(z|x)\propto P(x|z)P(z)$，先验$P(z)$与后验$P(z|x)$有相同的形式（如：同是Beta分布但参数不同）</p><p>好处在于：避免通过式$P(z|x)=\frac{P(x|z)P(z)}{\int_z{P(x|z)P(z)}}$去复杂地求分母</p></li><li><p>最大熵：因为先验分布未知，因此通过令熵最大的原则，假定等可能</p><p>如何确定先验$P(z)$：</p><ol><li>共轭（计算上的方便）</li><li>最大熵（无信息先验）</li><li>Jeffreys prior</li></ol></li></ul><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h3><ul><li>线性组合：$w^Tx$</li><li>link function：$(激活函数)^{-1}$</li><li>指数族分布：$y|x\sim 指数族分布$<ul><li>线性回归：$y|x\sim N(\mu,\Sigma)$</li><li>二分类模型：$y|x\sim  Bernoulli $</li><li>泊松回归：$y|x\sim Poisson$</li></ul></li></ul><h3 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h3><ul><li>无向图</li></ul><h3 id="变分推断"><a href="#变分推断" class="headerlink" title="变分推断"></a>变分推断</h3><p>……</p><h1 id="高斯分布的指数族形式"><a href="#高斯分布的指数族形式" class="headerlink" title="高斯分布的指数族形式"></a>高斯分布的指数族形式</h1><p>一维高斯分布</p><script type="math/tex; mode=display">\begin{align}P(x|\theta)&=\frac{1}{\sqrt{2\pi}\sigma}\exp \{-\frac{(x-\mu)^2}{2\sigma^2}\}\\&=\exp \{\log(2\pi\sigma^2)^{-\frac{1}{2}}\}·\exp\{-\frac{1}{2\sigma^2}(x^2-2\mu x)-\frac{\mu^2}{2\sigma^2}\}\\&=\exp\{\begin{pmatrix} \frac{\mu}{\sigma^2} & -\frac{1}{2\sigma^2} \end{pmatrix}\begin{pmatrix} x \\ x^2 \end{pmatrix}-[\frac{\mu^2}{2\sigma^2}+\frac{1}{2}\log(2\pi\sigma^2)]\}\\&=\exp(\eta^T\phi(x)-A(\eta))\end{align}</script><p>因此</p><script type="math/tex; mode=display">\eta=\begin{pmatrix} \eta_1 \\ \eta_2\end{pmatrix}=\begin{pmatrix} \frac{\mu}{\sigma^2} \\ -\frac{1}{2\sigma^2} \end{pmatrix} \quad \phi(x)=\begin{pmatrix} x \\ x^2\end{pmatrix}</script><p>从而</p><script type="math/tex; mode=display">\left\{ \begin{array}{**rcl**}\mu&=\sigma^2\eta_1\\\sigma^2&=-\frac{1}{2\eta_2}\end{array}\right.</script><script type="math/tex; mode=display">A(\eta)=-\frac{\eta_1^2}{4\eta_2^2}+\frac{1}{2}\log(-\frac{\pi}{\eta_2})</script><h1 id="对数配分函数与充分统计量的关系"><a href="#对数配分函数与充分统计量的关系" class="headerlink" title="对数配分函数与充分统计量的关系"></a>对数配分函数与充分统计量的关系</h1><script type="math/tex; mode=display">P(x|\eta)=h(x)\exp(\eta^T\phi(x)-A(\eta))\\=\frac{1}{\exp(A(\eta))}h(x)\exp(\eta^T\phi(x))</script><p>由于对于概率密度函数，对整个概率空间进行积分值为1，因此</p><script type="math/tex; mode=display">\exp(A(\eta))=\int h(x)\exp(\eta^T\phi(x))dx</script><p>两边同时对$\eta$进行求导，得到</p><script type="math/tex; mode=display">\exp(A(\eta))A'(\eta)=\int h(x)\exp(\eta^T\phi(x))\phi(x)dx\\\begin{align}A'(\eta)&=\frac{\int h(x)\exp(\eta^T\phi(x))\phi(x)dx}{\exp(A(\eta))}\\&=\int h(x)\exp(\eta^T\phi(x)-A(\eta))\phi(x)dx\\&=\int P(x|\eta)\phi(x)dx\\&=E_{P(x|\eta)}[\phi(x)]\end{align}</script><p>同理可得</p><script type="math/tex; mode=display">A''(\eta)=Var[\phi(x)]</script><p>由于$A’’(\eta)$大于0，因此$A(\eta)$是凸函数</p><blockquote><p>简单验证：</p><script type="math/tex; mode=display">E[\phi(x)]=\begin{pmatrix} E(x) \\ E(x^2)\end{pmatrix}</script><p>求$\frac{\partial A(\eta)}{\partial \eta_1}$验证其是否等于$\mu$：</p><script type="math/tex; mode=display">\frac{\partial A(\eta)}{\partial \eta_1}=-\frac{2\eta_1}{4\eta_2}=-\frac{\eta_1}{2\eta_2}=-\frac{\frac{\mu}{\sigma^2}}{-2\frac{1}{2\sigma^2}}=\mu</script><p>得证。</p></blockquote><h1 id="极大似然估计与充分统计量"><a href="#极大似然估计与充分统计量" class="headerlink" title="极大似然估计与充分统计量"></a>极大似然估计与充分统计量</h1><p>样本$D=\{x_1,x_2.\cdots,x_N\}$，参数$\eta$的极大似然估计为</p><script type="math/tex; mode=display">\begin{align}\eta_{MLE}&=\arg\max\log P(D|\eta)\\&=\arg\max\log \prod_{i=1}^{N}P(x_i|\eta)\\&=\arg\max\sum_{i=1}^{N}[\log h(x_i)+\eta^T\phi(x_i)-A(\eta)]\\&=\arg\max\sum_{i=1}^{N}[\eta^T\phi(x_i)-A(\eta)]\end{align}</script><p>为了求最大值，对其进行求导</p><script type="math/tex; mode=display">\frac{\partial}{\partial\eta}\sum_{i=1}^{N}[\eta^T\phi(x_i)-A(\eta)]=\sum_{i=1}^{N}[\phi(x_i)-A'(\eta)]=\sum_{i=1}^{N}\phi(x_i)-NA'(\eta)=0\\A'(\eta_{MLE})=\frac{1}{N}\sum_{i=1}^{N}\phi(x_i)</script><p>因此，已知$A(\eta)$，可以对其求导得到$A’(\eta)$，从而得到$\eta_{MLE}=A^{(-1)}{‘}(\eta)$</p><p>可以看出：不需要整个样本，只需要$\phi(x_i)$（充分统计量）就能得到$\eta_{MLE}$</p><h1 id="最大熵角度"><a href="#最大熵角度" class="headerlink" title="最大熵角度"></a>最大熵角度</h1><p>信息量：$-\log(p)$，与概率$p$成反比</p><p>熵：$E_{p(x)}[-\log(p)]=\int -p(x)\log p(x)dx=-\sum_{x}p(x)\log p(x)$</p><p>最大熵$\Longleftrightarrow$等可能（定量地表达等可能的概念）</p><p>假设$x$是离散的，熵$H(P)=-\sum_{x}p(x)\log p(x)$</p><p>若取值分布是未知的（没有任何已知的情况下），使熵取最大的求解问题为</p><script type="math/tex; mode=display">\max H(P)=\min\sum_{i=1}^{K}p_i\log p_i\\s.t. \sum_{i=1}^{K}p_i=1</script><script type="math/tex; mode=display">\hat{p}_i=\arg\max H(P)=\arg\min\sum_{i=1}^{K}p_i\log p_i</script><p>定义拉格朗日函数</p><script type="math/tex; mode=display">L(p,\lambda)=\sum_{i=1}^{K}p_i\log p_i+\lambda(1-\sum_{i=1}^{K}p_i)\\\frac{\part L}{\part p_i}=\log p_i+p_i\frac{1}{p_i}-\lambda=0\\\hat{p}_i=\exp(\lambda-1)</script><p>因此$\hat{p}_i$为常数，$\hat{p}_1=\hat{p}_2=\cdots=\hat{p}_K=\frac{1}{K}$，$p(x)$是均匀分布。即在没有任何已知的情况下，均匀分布可以使熵达到最大。</p><h2 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h2><p>样本$D=\{x_1,x_2.\cdots,x_N\}$</p><p>最大熵原理：在满足已知事实（约束）的情况下，使熵达到最大</p><p>经验分布：</p><script type="math/tex; mode=display">\hat{P}(X=x)=\hat{P}(x)=\frac{count(x)}{N}</script><p>（相当于频率视为概率？）</p><p>满足已知事实（即数据），但仅有数据难以形成约束，而经验分布又是对于数据的描述</p><script type="math/tex; mode=display">E_{\hat{p}}[f(x)]=\Delta</script><p>其中$f(x)$是任意关于$x$的函数向量，$f(x)=(f_1,f_2,\cdots,f_Q)^T$，因此满足已知事实可以转化为满足上式约束（为了定量地描述已知事实），求解可以表达为</p><script type="math/tex; mode=display">\min \sum_{x}p(x)\log p(x)\\s.t. \sum_{x}p(x)=1, E_{p}[f(x)]=E_{\hat{p}}[f(x)]=\Delta</script><p>拉格朗日函数定义为</p><script type="math/tex; mode=display">L(p,\lambda_0,\lambda)=\sum_{x}p(x)\log p(x)+\lambda_0(1-\sum_{x}p(x))+\lambda^T(\Delta-E_{p}[f(x)])</script><script type="math/tex; mode=display">\frac{\part L}{\part p(x)}=\sum_{x}[\log p(x)+1]-\sum_{x}\lambda_0-\sum_{x}\lambda^Tf(x)=0\\\log p(x)+1-\lambda_0-\lambda^Tf(x)=0\\\log p(x)=\lambda^Tf(x)+\lambda_0-1\\p(x)=\exp\{\lambda^Tf(x)-(1-\lambda_0)\}=\exp\{\eta^T\phi(x)-A(\eta)\}</script><p>其中$\lambda=\eta,f(x)=\phi(x),A(\eta)=1-\lambda_0$</p><p>因此$p(x)$满足指数族分布</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive基础知识及调优</title>
      <link href="/2020/02/09/hive-ji-chu-zhi-shi-ji-diao-you/"/>
      <url>/2020/02/09/hive-ji-chu-zhi-shi-ji-diao-you/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考：尚硅谷大数据技术之Hive（<a href="https://www.bilibili.com/video/av65556024?from=search&amp;seid=1273196552526002153" target="_blank" rel="noopener">b站教学视频</a>）</p></blockquote><h1 id="Hive入门"><a href="#Hive入门" class="headerlink" title="Hive入门"></a>Hive入门</h1><h2 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h2><ul><li><p>概述：Hive是<strong>基于Hadoop</strong>的一个<strong>数据仓库工具</strong>，可以将结构化的数据文件映射为一张表，并提供<strong>类SQL</strong>查询功能</p></li><li><p>本质：<strong>将HiveQL转化为MapReduce程序</strong>，是一个分析引擎，相当于一个客户端</p><p>SQL与MapReduce的关系：</p><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200209/QhHPHWrRFcws.png" alt="mark"></p></li><li><p>Hive是基于Hadoop的体现在：</p><ol><li>数据存储在HDFS上</li><li>数据底层实现用MapReduce（默认使用MR，也可以使用Spark）</li><li>执行程序运行在Yarn上</li></ol></li></ul><h2 id="Hive的优缺点"><a href="#Hive的优缺点" class="headerlink" title="Hive的优缺点"></a>Hive的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>操作接口采用<strong>类SQL语法</strong>，<strong>提供快速开发的能力</strong>（简单、容易上手）。提供 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行，使不熟悉MapReduce 的用户也能很方便地对数据进行查询、汇总、分析。</li><li>Hive优势在于处理大数据，因此Hive常用于数据分析，对实时性要求不高的场合。  </li><li>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li><p><strong>Hive的HQL表达能力有限</strong>。迭代式算法无法表达，因此数据挖掘方面不擅长（需要不断地对结果进行迭代，但MR在迭代方面很慢）。</p></li><li><p><strong>Hive的效率比较低</strong>。Hive自动生成的MapReduce作业，通常情况下不够智能化；Hive调优（包含SQL代码调优、资源调优）比较困难，粒度较粗（依赖模板，无法像MR精细化管理）；Hive因为Hive的执行延迟比较高，对于处理小数据没有优势。</p></li></ol><h2 id="Hive和数据库比较"><a href="#Hive和数据库比较" class="headerlink" title="Hive和数据库比较"></a>Hive和数据库比较</h2><h3 id="查询语言"><a href="#查询语言" class="headerlink" title="查询语言"></a>查询语言</h3><p>由于SQL被广泛的应用在数据仓库中，因此，专门针对Hive的特性设计了类SQL的查询语言HQL。熟悉SQL开发的开发者可以很方便的使用Hive进行开发。</p><blockquote><p><strong>Hive与SQL的区别</strong></p><p>Hive是一种基于Hadoop的数据仓库架构，定义了简单的类SQL查询语句（HQL），当输入HQL时，Hive会处理SQL将其转换为MapReduce。</p><p>Hive的表其实是HDFS的目录，Hive的数据对应目录下的文件。</p><p>SQL是一种查询语言的标准，Hive是基于Hadoop的数据仓库架构，提供了类SQL的查询接口。</p></blockquote><h3 id="数据存储位置"><a href="#数据存储位置" class="headerlink" title="数据存储位置"></a>数据存储位置</h3><ul><li>Hive是建立在 Hadoop 之上的，所有Hive 的数据都是存储在 HDFS 中的。</li><li>数据库可以将数据保存在块设备或者本地文件系统中。</li></ul><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><ul><li>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此Hive中不建议对数据的改写，所有的数据都是在加载的时候确定好的。</li><li>数据库中的数据通常是需要经常进行修改的，需要实时地进行增删改查。</li></ul><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul><li>Hive在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些Key建立索引。Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。但由于 MapReduce 的引入，Hive可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。</li><li>数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。</li></ul><h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><ul><li>Hive中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的。</li><li>数据库通常有自己的执行引擎。</li></ul><h3 id="执行延迟"><a href="#执行延迟" class="headerlink" title="执行延迟"></a>执行延迟</h3><ul><li>Hive在查询数据的时候，由于没有索引需要扫描整个表，因此延迟较高。另外一个导致Hive执行延迟高的因素是 MapReduce框架。由于MapReduce本身具有较高的延迟，因此在利用MapReduce执行Hive查询时，也会有较高的延迟。</li><li>数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive的并行计算显然能体现出优势。</li></ul><h3 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h3><ul><li>由于Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的。</li><li>数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库Oracle在理论上的扩展能力也只有100台左右。</li></ul><h3 id="数据规模"><a href="#数据规模" class="headerlink" title="数据规模"></a>数据规模</h3><ul><li>由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据。</li><li>数据库可以支持的数据规模较小。</li></ul><h1 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h1><h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><div class="table-container"><table><thead><tr><th>Hive数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TINYINT</td><td>1byte有符号整数</td><td>20</td></tr><tr><td>SMALINT</td><td>2byte有符号整数</td><td>20</td></tr><tr><td><strong>INT</strong></td><td>4byte有符号整数</td><td>20</td></tr><tr><td><strong>BIGINT</strong></td><td>8byte有符号整数</td><td>20</td></tr><tr><td>BOOLEAN</td><td>布尔类型，true或者false</td><td>TRUE FALSE</td></tr><tr><td>FLOAT</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td><strong>DOUBLE</strong></td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td><strong>STRING </strong></td><td>字符系列。可以使用单引号或者双引号。</td><td>‘now is the time’ “for all good men”</td></tr><tr><td>TIMESTAMP</td><td>时间类型</td><td></td></tr><tr><td>BINARY</td><td>字节数组</td></tr></tbody></table></div><h2 id="集合数据类型"><a href="#集合数据类型" class="headerlink" title="集合数据类型"></a>集合数据类型</h2><div class="table-container"><table><thead><tr><th>数据类型</th><th>描述</th><th>语法示例</th></tr></thead><tbody><tr><td>STRUCT</td><td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td><td>struct()</td></tr><tr><td>MAP</td><td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td><td>map()</td></tr><tr><td>ARRAY</td><td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’,  ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td><td>Array()</td></tr></tbody></table></div><h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><p>Hive的原子数据类型是可以进行隐式转换的，例如某表达式使用INT类型，TINYINT会自动转换为INT类型，</p><p>但是Hive不会进行反向转化，例如，某表达式使用TINYINT类型，INT不会自动转换为TINYINT类型，它会返回错误，除非使用CAST操作。</p><ul><li><p><strong>隐式类型转换规则如下</strong></p><ol><li>任何整数类型都可以隐式地转换为一个范围更广的类型，如TINYINT可以转换成INT，INT可以转换成BIGINT。</li><li>所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。</li><li>TINYINT、SMALLINT、INT都可以转换为FLOAT。</li><li>BOOLEAN类型不可以转换为任何其它的类型。</li></ol></li><li><p><strong>可以使用CAST()操作显式地进行数据类型转换</strong></p><p>例如CAST(‘1’ AS INT)将把字符串’1’ 转换成整数1；</p><p>如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式<strong>返回空值 NULL</strong>。</p></li></ul><h1 id="DDL数据定义"><a href="#DDL数据定义" class="headerlink" title="DDL数据定义"></a>DDL数据定义</h1><p>DDL(Data Definition Language)，数据定义语言</p><p>适用范围：对数据库中的某些对象（例如: database,table）进行管理（不会对具体的数据进行操作），如Create,Alter, Drop</p><ul><li><p><strong>DDL的操作对象</strong>： 包括数据库本身，以及数据库对象，如表、视图等等 </p></li><li><p><strong>DDL的主要语句</strong>： </p><ul><li>Create语句：可以创建数据库和数据库的一些对象。</li><li>Drop语句：可以删除数据表、索引、触发程序、条件约束以及数据表的权限等。</li><li>Alter语句：修改数据表定义及属性。</li></ul></li></ul><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>默认存储路径是/user/hive/warehouse/*.db </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> db_hive;</span><br></pre></td></tr></table></figure><h2 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">databases</span>;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">databases</span> <span class="keyword">like</span> <span class="string">'db_hive*'</span>;</span><br><span class="line">desc database db_hive;</span><br><span class="line">desc database extended db_hive;  <span class="comment">--显示数据库详细信息</span></span><br></pre></td></tr></table></figure><h2 id="切换当前数据库"><a href="#切换当前数据库" class="headerlink" title="切换当前数据库"></a>切换当前数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> db_hive;</span><br></pre></td></tr></table></figure><h2 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h2><p>用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。</p><p><strong>数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置。</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">database</span> db_hive <span class="keyword">set</span> dbproperties(<span class="string">'createtime'</span>=<span class="string">'20170830'</span>);</span><br></pre></td></tr></table></figure><h2 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name </span><br><span class="line">[(col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] </span><br><span class="line">[<span class="keyword">COMMENT</span> table_comment] <span class="comment">--为表和列添加注释</span></span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] <span class="comment">--创建分区表</span></span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) <span class="comment">--创建分桶表</span></span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] <span class="comment">--不常用</span></span><br><span class="line">[<span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="built_in">char</span>] <span class="comment">--列分隔符</span></span><br><span class="line">[<span class="keyword">STORED</span> <span class="keyword">AS</span> file_format] <span class="comment">--指定存储文件类型</span></span><br><span class="line">[LOCATION hdfs_path] <span class="comment">--指定表在HDFS上的存储位置</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><h3 id="内部表与外部表"><a href="#内部表与外部表" class="headerlink" title="内部表与外部表"></a>内部表与外部表</h3><p>默认创建的表都是内部表。<br>Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(如/user/hive/warehouse)所定义的目录的子目录下。<br>当我们删除一个内部表时，Hive也会删除这个表中数据。内部表不适合和其他工具共享数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> xxx.xxxx</span><br><span class="line">(</span><br><span class="line"><span class="keyword">id</span> <span class="keyword">string</span>,</span><br><span class="line"><span class="built_in">number</span> <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;  <span class="comment">--以'\t'结尾的行格式分隔字段</span></span><br></pre></td></tr></table></figure><p><strong>被external修饰的为外部表（external table）</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">EXTERNAL</span> <span class="keyword">table</span> xxx.xxxx</span><br><span class="line">(</span><br><span class="line"><span class="keyword">id</span> <span class="keyword">string</span>,</span><br><span class="line"><span class="built_in">number</span> <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>  <span class="comment">--以'\t'结尾的行格式分隔字段 </span></span><br><span class="line">location <span class="string">'/user/t2'</span>;</span><br></pre></td></tr></table></figure><p><strong>区别：</strong> </p><ol><li>内部表数据由Hive自身管理，外部表数据由HDFS管理 </li><li>内部表数据存储的位置默认是/user/hive/warehouse，会将数据移动到数据仓库指向的路径；外部表数据的存储位置由自己制定，仅记录数据所在的路径，不移动数据</li><li>删除内部表会直接删除元数据及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除，这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。</li></ol><p><strong>相互转换：</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'TRUE'</span>); <span class="comment">--转为外部表</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'FALSE'</span>); <span class="comment">--转为内部表</span></span><br></pre></td></tr></table></figure><p>注意：(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！</p><h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><p>分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，按分区键的列值存储在表目录的子目录中，针对的是<strong>数据的存储路径</strong>，提供一个隔离数据和优化查询的便利方式。</p><p>Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集（通常会按照时间日/月进行分区）。</p><p>好处：<strong>可以更快地执行查询</strong>。使用分区列的名称创建一个子目录，当使用where子句进行查询时，<strong>只扫描特定子目录，而不是扫描整个表</strong>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建分区表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition   </span><br><span class="line">(</span><br><span class="line">deptno <span class="built_in">int</span>, </span><br><span class="line">dname <span class="keyword">string</span>, </span><br><span class="line">loc <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">month</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建二级分区表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition2</span><br><span class="line">(</span><br><span class="line">deptno <span class="built_in">int</span>, </span><br><span class="line">    dname <span class="keyword">string</span>, </span><br><span class="line">    loc <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">month</span> <span class="keyword">string</span>, <span class="keyword">day</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入数据</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/module/datas/dept.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> default.dept_partition <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201709'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 增加（多个）分区</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201705'</span>) <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201704'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除分区</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span> (<span class="keyword">month</span>=<span class="string">'201704'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看分区</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> dept_partition;</span><br><span class="line"></span><br><span class="line"><span class="comment">--查看分区表结构</span></span><br><span class="line">desc formatted dept_partition;</span><br></pre></td></tr></table></figure><h2 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h2><p>将表中记录按分桶键的哈希值分散进多个文件中，针对的是<strong>数据文件</strong>，将数据集分解成更容易管理的若干部分</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建分桶表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu_buck(<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (<span class="keyword">id</span>) </span><br><span class="line"><span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 设置参数（否则导入数据后不分桶）</span></span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu_buck <span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用分桶抽样查询（对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。）</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> stu_buck <span class="keyword">tablesample</span>(<span class="keyword">bucket</span> <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> <span class="keyword">id</span>);</span><br></pre></td></tr></table></figure><p>注：tablesample是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y) 。</p><p>y必须是table总bucket数的倍数或者因子。hive根据y的大小，<strong>决定抽样的比例</strong>。例如，table总共分了4份，当y=2时，抽取(4/2=)2个bucket的数据，当y=8时，抽取(4/8=)1/2个bucket的数据。</p><p>x表示<strong>从哪个bucket开始抽取</strong>，如果需要取多个分区，以后的分区号为当前分区号加上y。例如，table总bucket数为4，tablesample(bucket 1 out of 2)，表示总共抽取（4/2=）2个bucket的数据，抽取第1(x)个和第3(x+y)个bucket的数据。</p><p>注意：x的值必须小于等于y的值，否则报错</p><p>FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu_buck</p><blockquote><p><strong>分区与分桶的区别</strong></p><p>分区和分桶的区别除了存储的格式不同外，最主要的是作用：</p><ul><li>分区表：细化数据管理，缩小MapReduce程序需要<strong>扫描的数据量</strong>。</li><li>分桶表：<strong>提高join查询的效率</strong>，在一份数据会被经常用来做连接查询的时候建立分桶，分桶字段就是连接字段，从而<strong>提高采样的效率</strong>。</li></ul></blockquote><h2 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 重命名表</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> old_table <span class="keyword">RENAME</span> <span class="keyword">TO</span> new_table;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 添加列</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">add</span> <span class="keyword">columns</span>(deptdesc <span class="keyword">string</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 更新列</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">change</span> <span class="keyword">column</span> dept_old dept_new <span class="built_in">int</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 替换列</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">replace</span> <span class="keyword">columns</span>(deptno <span class="keyword">string</span>, dname</span><br><span class="line"> <span class="keyword">string</span>, loc <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure><h2 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> dept_partition;</span><br></pre></td></tr></table></figure><h1 id="DML数据操作"><a href="#DML数据操作" class="headerlink" title="DML数据操作"></a>DML数据操作</h1><p>DML(Data Manipulation Language，数据操控语言)</p><p>用于操作数据库对象中包含的数据，也就是说操作的单位是记录。</p><ul><li><p><strong>DML的操作对象：记录</strong></p></li><li><p><strong>DML的主要语句</strong>：</p><ul><li>Insert：向数据表张插入一条记录。</li><li>Delete：删除数据表中的一条或多条记录，也可以删除数据表中的所有记录，但操作对象仍是记录。</li><li>Update：用于修改已存在表中的记录的内容。</li></ul></li></ul><h2 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h2><ul><li><strong>方法1：使用load语句向表中装载数据</strong></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> [<span class="keyword">local</span>] inpath <span class="string">'/opt/module/datas/student.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> student [<span class="keyword">partition</span> (partcol1=val1,…)];</span><br></pre></td></tr></table></figure><ol><li>load data：表示加载数据</li><li>local：表示从本地加载数据到hive表；否则从HDFS加载数据到hive表</li><li>inpath：表示加载数据的路径</li><li>overwrite：表示覆盖表中已有数据，否则表示追加</li><li>into table：表示加载到哪张表</li><li>student：表示具体的表</li><li>partition：表示上传到指定分区</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建一张空表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student(<span class="keyword">id</span> <span class="keyword">string</span>, <span class="keyword">name</span> <span class="keyword">string</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 加载本地文件到hive</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/module/datas/student.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> default.student;</span><br></pre></td></tr></table></figure><ul><li><strong>方法2：通过查询语句向表中插入数据（Insert）</strong> </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建一张分区表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student(<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>) partitioned <span class="keyword">by</span> (<span class="keyword">month</span> <span class="keyword">string</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 基本插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span>  student <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201709'</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">'wangwu'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 基本模式插入（根据单张表查询结果）</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201708'</span>)</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> student <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201709'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 多插入模式（根据多张表查询结果）</span></span><br><span class="line">from student</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201707'</span>)</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201709'</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201706'</span>)</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201709'</span>;</span><br></pre></td></tr></table></figure><ul><li><strong>方法3：创建表时通过Location指定加载数据路径</strong></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建表，并指定在hdfs上的位置</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> student5(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">location <span class="string">'/user/hive/warehouse/student5'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 上传数据到上述hdfs的指定位置</span></span><br><span class="line">dfs -put /opt/module/datas/student.txt /user/hive/warehouse/student5;</span><br></pre></td></tr></table></figure><ul><li><p><strong>方法4：Import数据到指定Hive表中</strong>  </p><p>注意：先用export导出后，再将数据导入</p></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import table student2 partition(month='201709') from '/user/hive/warehouse/export/student';</span><br></pre></td></tr></table></figure><h2 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h2><ul><li><strong>方法1：Hive Shell 命令导出</strong>  </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在linux环境下执行</span></span><br><span class="line">hive -e <span class="string">'select * from default.student;'</span> &gt;/opt/module/datas/<span class="built_in">export</span>/student4.txt</span><br></pre></td></tr></table></figure><ul><li><strong>方法2：Insert导出</strong>  </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 三种导出方式：</span></span><br><span class="line"><span class="comment">-- 将查询的结果导出到本地</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'/opt/module/datas/export/student'</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> student;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将查询的结果格式化导出到本地</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'/opt/module/datas/export/student1'</span></span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> student;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将查询的结果导出到HDFS上(没有local)</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/user/atguigu/student2'</span></span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span> </span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure><ul><li><strong>方法3：Hadoop命令导出到本地</strong>  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfs -get /user/hive/warehouse/student/month=201709/000000_0</span><br><span class="line">/opt/module/datas/export/student3.txt;</span><br></pre></td></tr></table></figure><ul><li><strong>方法4：Export导出到HDFS上</strong>  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export table default.student to &apos;/user/hive/warehouse/export/student&apos;;</span><br></pre></td></tr></table></figure><h2 id="清除表中数据"><a href="#清除表中数据" class="headerlink" title="清除表中数据"></a>清除表中数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure><p>注意：Truncate只能删除管理表，不能删除外部表中数据</p><blockquote><p><strong>DROP、TRUNCATE和DELETE的区别</strong></p><ol><li><p>TRUNCATE和DELETE只删除数据，DROP则删除整个表（结构和数据）。</p></li><li><p>表和索引所占空间。当表被TRUNCATE后，这个表和索引所占用的空间会恢复到初始大小；DELETE操作不会减少表或索引所占用的空间；DROP语句将表所占用的空间全释放掉。</p></li><li><p>DELETE语句为DML，这个操作会被放到rollback segment中，事务提交后才生效。如果有相应的tigger，执行的时候将被触发；TRUNCATE、DROP是DDL，操作立即生效，原数据不放到rollback segment中，不能回滚。</p></li><li><p>在没有备份情况下，谨慎使用DROP与TRUNCATE。删除部分数据行采用DELETE时，要注意结合where来约束影响范围。删除整个表用DROP。若想保留表而将表中数据删除，用TRUNCATE即可实现。</p></li><li><p>TRUNCATE TABLE 表名速度快，而且效率高，因为TRUNCATE TABLE在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。 </p></li></ol></blockquote><h1 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">WITH</span> CommonTableExpression (, CommonTableExpression)*] </span><br><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> | <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line"><span class="keyword">FROM</span> table_reference</span><br><span class="line">[<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">  | [<span class="keyword">DISTRIBUTE</span> <span class="keyword">BY</span> col_list] [<span class="keyword">SORT</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">]</span><br><span class="line">[<span class="keyword">LIMIT</span> <span class="built_in">number</span>]</span><br></pre></td></tr></table></figure><h2 id="基本查询"><a href="#基本查询" class="headerlink" title="基本查询"></a>基本查询</h2><p>注意：</p><ol><li>SQL 语言大小写不敏感</li><li>SQL 可以写在一行或者多行</li><li>关键字不能被缩写也不能分行</li><li>各子句一般要分行写，使用缩进提高语句的可读性</li></ol><h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><div class="table-container"><table><thead><tr><th>运算符</th><th>描述</th></tr></thead><tbody><tr><td>A+B</td><td>A和B相加</td></tr><tr><td>A-B</td><td>A减去B</td></tr><tr><td>A*B</td><td>A和B相乘</td></tr><tr><td>A/B</td><td>A除以B</td></tr><tr><td>A%B</td><td>A对B取余</td></tr><tr><td>A&amp;B</td><td>A和B按位取与</td></tr><tr><td>A\</td><td>B</td><td>A和B按位取或</td></tr><tr><td>A^B</td><td>A和B按位取异或</td></tr><tr><td>~A</td><td>A按位取反</td></tr></tbody></table></div><h3 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h3><div class="table-container"><table><thead><tr><th>操作符</th><th>支持的数据类型</th><th>描述</th></tr></thead><tbody><tr><td>A=B</td><td>基本数据类型</td><td>如果A等于B则返回TRUE，反之返回FALSE</td></tr><tr><td>A&lt;=&gt;B</td><td>基本数据类型</td><td>如果A和B都为NULL，则返回TRUE，其他的和等号(=)操作符的结果一致，如果任一为NULL则结果为NULL</td></tr><tr><td>A&lt;&gt;B, A!=B</td><td>基本数据类型</td><td>A或者B为NULL则返回NULL；如果A不等于B，则返回TRUE，反之返回FALSE</td></tr><tr><td>A&lt;(=)B</td><td>基本数据类型</td><td>A或者B为NULL，则返回NULL；如果A小于B，则返回TRUE，反之返回FALSE</td></tr><tr><td>A [NOT] BETWEEN B AND C</td><td>基本数据类型</td><td>如果A，B或者C任一为NULL，则结果为NULL。如果A的值<strong>大于等于</strong>B而且<strong>小于或等于</strong>C，则结果为TRUE，反之为FALSE。如果使用NOT关键字则可达到相反的效果。</td></tr><tr><td>A IS [NOT] NULL</td><td>所有数据类型</td><td>如果A等于NULL，则返回TRUE，反之返回FALSE</td></tr><tr><td>IN(数值1, 数值2)</td><td>所有数据类型</td><td>使用IN运算显示列表中的值</td></tr><tr><td>A [NOT] LIKE B</td><td>STRING 类型</td><td>B是一个SQL下的简单正则表达式，如果A与其匹配的话，则返回TRUE；反之返回FALSE。B的表达式说明如下：‘x%’表示A必须以字母‘x’开头，‘%x’表示A必须以字母’x’结尾，而‘%x%’表示A包含有字母’x’,可以位于开头，结尾或者字符串中间。如果使用NOT关键字则可达到相反的效果。</td></tr><tr><td>A RLIKE B, A REGEXP B</td><td>STRING 类型</td><td>B是一个正则表达式，如果A与其匹配，则返回TRUE；反之返回FALSE。匹配使用的是JDK中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串A相匹配，而不是只需与其字符串匹配。</td></tr></tbody></table></div><h3 id="Like和RLike"><a href="#Like和RLike" class="headerlink" title="Like和RLike"></a>Like和RLike</h3><ol><li>使用LIKE运算选择类似的值。</li><li>选择条件可以包含字符或数字：% 代表零个或多个字符(任意个字符)，_ 代表一个字符。</li><li>RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查找薪水中含有2的员工信息</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">RLIKE</span> <span class="string">'[2]'</span>;</span><br></pre></td></tr></table></figure><h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><h3 id="Having语句"><a href="#Having语句" class="headerlink" title="Having语句"></a>Having语句</h3><p>having与where不同点：</p><ol><li>where针对表中的列发挥作用，查询数据；having针对查询结果中的列发挥作用，筛选数据。</li><li>where后面不能写分组函数，而having后面可以使用分组函数。</li><li>having只用于group by分组统计语句。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 求每个部门的平均薪水大于2000的部门</span></span><br><span class="line"><span class="keyword">select</span> deptno, <span class="keyword">avg</span>(sal) avg_sal </span><br><span class="line"><span class="keyword">from</span> emp </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> deptno </span><br><span class="line"><span class="keyword">having</span> avg_sal &gt; <span class="number">2000</span>;</span><br></pre></td></tr></table></figure><h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p>Hive支持通常的SQL JOIN语句，但是：</p><ul><li><p>只支持等值连接，<strong>不支持非等值连接</strong></p></li><li><p>连接谓词中<strong>不支持or</strong>，如</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line"><span class="keyword">from</span> emp e </span><br><span class="line"><span class="keyword">join</span> dept d </span><br><span class="line"><span class="keyword">on</span> e.deptno= d.deptno <span class="keyword">or</span> e.ename=d.ename; <span class="comment">--错误</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="多种连接"><a href="#多种连接" class="headerlink" title="多种连接"></a>多种连接</h3><ol><li><p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。    </p></li><li><p>左（右）外连接：JOIN操作符左（右）边表中符合WHERE子句的所有记录将会被返回。</p></li><li><p>满外连接：将会返回所有表中符合WHERE语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用NULL值替代。</p></li></ol><h3 id="多表连接"><a href="#多表连接" class="headerlink" title="多表连接"></a>多表连接</h3><p>注意：连接 n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1.创建位置表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> default.location</span><br><span class="line">(</span><br><span class="line">    loc <span class="built_in">int</span>,  </span><br><span class="line">    loc_name <span class="keyword">string</span>  </span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2.导入数据</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/module/datas/location.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> default.location;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3.多表连接查询</span></span><br><span class="line"><span class="keyword">SELECT</span> e.ename, d.deptno, l. loc_name</span><br><span class="line"><span class="keyword">FROM</span> emp e </span><br><span class="line"><span class="keyword">JOIN</span> dept d</span><br><span class="line"><span class="keyword">ON</span> d.deptno = e.deptno </span><br><span class="line"><span class="keyword">JOIN</span> location l</span><br><span class="line"><span class="keyword">ON</span> d.loc = l.loc;</span><br></pre></td></tr></table></figure><p>大多数情况下，Hive会对每对JOIN连接对象启动一个MapReduce任务。本例中会首先启动一个MapReduce job对表e和表d进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表l;进行连接操作。</p><p>注意：为什么不是表d和表l先进行连接操作呢？这是因为<strong>Hive总是按照从左到右的顺序执行的</strong>。</p><h3 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h3><p>笛卡尔集会在下面条件下产生：</p><ol><li>省略连接条件</li><li>连接条件无效</li><li>所有表中的所有行互相连接</li></ol><p><strong>在大型数据集上使用笛卡尔积会造成非常严重的生产事故！</strong></p><p>可使用以下选项进行限制（切换严格模式）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapred.mode=<span class="keyword">strict</span>;</span><br></pre></td></tr></table></figure><blockquote><p>严格模式：</p><p>防止用户执行那些可能意想不到的不好的影响的查询，开启严格模式可以禁止3种类型的查询。</p><ol><li><strong>对于分区表，分区表必须指定要查询的分区，否则不允许执行。</strong>换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</li><li><strong>对于使用了order by语句的查询，要求必须使用limit语句。</strong>因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</li><li><strong>限制笛卡尔积的查询。</strong></li></ol></blockquote><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="全局排序（Order-By）"><a href="#全局排序（Order-By）" class="headerlink" title="全局排序（Order By）"></a>全局排序（Order By）</h3><p>Order By：全局排序，一个Reducer</p><ul><li><p>ASC（ascend）: 升序（默认）</p></li><li><p>DESC（descend）: 降序</p></li></ul><p>ORDER BY 子句在SELECT语句的<strong>结尾</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 可以按照别名排序：按照员工薪水的2倍降序排序</span></span><br><span class="line"><span class="keyword">select</span> ename, sal*<span class="number">2</span> twosal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> twosal <span class="keyword">desc</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 多个列排序：按照部门和工资升序排序</span></span><br><span class="line"><span class="keyword">select</span> ename, deptno, sal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> deptno, sal;</span><br></pre></td></tr></table></figure><h3 id="每个MapReduce内部排序（Sort-By）"><a href="#每个MapReduce内部排序（Sort-By）" class="headerlink" title="每个MapReduce内部排序（Sort By）"></a>每个MapReduce内部排序（Sort By）</h3><p>Sort By：每个Reducer内部进行排序，对全局结果集来说不是排序。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1.设置reduce个数(可以通过set mapreduce.job.reduces;查看设定的reduce个数)</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces=<span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2.根据部门编号降序查看员工信息</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp <span class="keyword">sort</span> <span class="keyword">by</span> empno <span class="keyword">desc</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3.将查询结果导入到文件中（按照部门编号降序排序）</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'/opt/module/datas/sortby-result'</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp <span class="keyword">sort</span> <span class="keyword">by</span> deptno <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><h3 id="分区排序（Distribute-By）"><a href="#分区排序（Distribute-By）" class="headerlink" title="分区排序（Distribute By）"></a>分区排序（Distribute By）</h3><p>Distribute By：类似MR中partition，进行分区，结合sort by使用。</p><p>注意，Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前。</p><p>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 先按照部门编号分区，再按照员工编号降序排序</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces=<span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'/opt/module/datas/distribute-result'</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp <span class="keyword">distribute</span> <span class="keyword">by</span> deptno <span class="keyword">sort</span> <span class="keyword">by</span> empno <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><h3 id="Cluster-By"><a href="#Cluster-By" class="headerlink" title="Cluster By"></a>Cluster By</h3><p>当distribute by和sorts by字段相同时，可以使用cluster by方式。</p><p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</p><p>以下两种写法等价</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp cluster <span class="keyword">by</span> deptno;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp <span class="keyword">distribute</span> <span class="keyword">by</span> deptno <span class="keyword">sort</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure><p>注意：按照部门编号分区，不一定就是固定的数值，可以是20号和30号部门分到一个分区里面去。</p><blockquote><p><strong>order by，sort by，distribute by，cluster by 的区别</strong></p><ul><li><p>order by会对输入做全局排序，因此只有一个Reducer(多个Reducer无法保证全局有序)，会导致当输入规模较大时，消耗较长的计算时间。 </p></li><li><p>sort by不是全局排序，其在数据进入reducer前完成排序，因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则<strong>sort by只会保证同一个reducer的输出有序，并不保证全局有序</strong>。sort by不同于order by，它不受hive.mapred.mode属性的影响。使用sort by你可以指定执行的reduce个数(通过set mapred.reduce.tasks=n来指定)，对输出的数据再执行归并排序，即可得到全部结果。</p></li><li><p>distribute by是控制在map端如何拆分数据给reduce端的。hive会根据distribute by后面列，对应reduce的个数进行分发，默认是采用hash算法。sort by再为每个reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此，distribute by经常和sort by配合使用。  </p><ul><li><p>Distribute by和sort by的使用场景：</p><p>Map输出的文件大小不均/Reduce输出文件大小不均/小文件过多/文件超大</p></li></ul><ul><li>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。 如果distribute by和sort by中所指定的列相同，可以缩写为cluster by该列以便同时指定两者所用的列。</li></ul></li></ul></blockquote><h2 id="其他查询"><a href="#其他查询" class="headerlink" title="其他查询"></a>其他查询</h2><h3 id="union和union-all"><a href="#union和union-all" class="headerlink" title="union和union all"></a>union和union all</h3><p>1、对<strong>重复</strong>结果的处理：union在进行表链接后会筛选掉重复的记录，union all不会去除重复记录。</p><p>2、对<strong>排序</strong>的处理：union将会按照字段的顺序进行排序；union all只是简单的将两个结果合并后就返回。</p><p>3、从<strong>效率</strong>上说，union all要比union快很多，所以，如果可以确认合并的两个结果集中不包含重复数据且不需要排序时的话，那么就使用union all。 </p><h3 id="count-count-1-和count-字段-的区别"><a href="#count-count-1-和count-字段-的区别" class="headerlink" title="count(*), count(1)和count(字段)的区别"></a>count(*), count(1)和count(字段)的区别</h3><ul><li><p><strong>count(1)和count(*)</strong>：都会对全表进行扫描，统计所有记录的条数，包括那些为null的记录，count(1)会比count(*)更快，查询结果是完全一致的。</p></li><li><p><strong>count(1) and count(字段)</strong>：</p><ul><li>count(1)会统计表中的所有的记录数，包含字段为null的记录</li><li>count(字段)会统计该字段在表中出现的次数，不统计字段为null的记录。</li></ul></li></ul><h1 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h1><h2 id="空字段赋值"><a href="#空字段赋值" class="headerlink" title="空字段赋值"></a>空字段赋值</h2><p>NVL：给值为NULL的数据赋值，它的格式是<code>NVL(string1, replace_with)</code>。它的功能是如果string1为NULL，则NVL函数返回replace_with的值，否则返回string1的值，如果两个参数都为NULL ，则返回NULL。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询：如果员工的comm为NULL，则用-1代替</span></span><br><span class="line"><span class="keyword">select</span> nvl(comm,<span class="number">-1</span>) <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询：如果员工的comm为NULL，则用领导id代替</span></span><br><span class="line"><span class="keyword">select</span> nvl(comm,mgr) <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure><h2 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h2><p><code>CONCAT(string A/col, string B/col…)</code>：返回输入字符串连接后的结果，支持任意个输入字符串;</p><p><code>CONCAT_WS(separator, str1, str2,...)</code>：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;</p><p><code>COLLECT_SET(col)</code>：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段。（COLLECT_LIST类似，不去重）</p><p><strong>e.g. </strong></p><p>原数据：</p><div class="table-container"><table><thead><tr><th>name</th><th>constellation</th><th>blood_type</th></tr></thead><tbody><tr><td>孙悟空</td><td>白羊座</td><td>A</td></tr><tr><td>大海</td><td>射手座</td><td>A</td></tr><tr><td>宋宋</td><td>白羊座</td><td>B</td></tr><tr><td>猪八戒</td><td>白羊座</td><td>A</td></tr><tr><td>凤姐</td><td>射手座</td><td>A</td></tr></tbody></table></div><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    t1.base,</span><br><span class="line">    <span class="keyword">concat_ws</span>(<span class="string">','</span>, collect_set(t1.name)) <span class="keyword">name</span></span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span></span><br><span class="line">        <span class="keyword">name</span>,</span><br><span class="line">        <span class="keyword">concat</span>(constellation, <span class="string">","</span>, blood_type) base</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        person_info) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    t1.base;</span><br></pre></td></tr></table></figure><p>结果：</p><div class="table-container"><table><thead><tr><th>base</th><th>name</th></tr></thead><tbody><tr><td>射手座,A</td><td>大海,凤姐</td></tr><tr><td>白羊座,A</td><td>孙悟空,猪八戒</td></tr><tr><td>白羊座,B</td><td>宋宋</td></tr></tbody></table></div><h2 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h2><p><code>EXPLODE(col)</code>：将hive一列中复杂的array或者map结构拆分成多行。</p><p>LATERAL VIEW</p><p>用法：<code>LATERAL VIEW udtf(expression) tableAlias AS columnAlias</code></p><p>解释：用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p><p><strong>e.g.</strong></p><p>原数据：</p><div class="table-container"><table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑,动作,科幻,剧情</td></tr><tr><td>《Lie  to me》</td><td>悬疑,警匪,动作,心理,剧情</td></tr><tr><td>《战狼2》</td><td>战争,动作,灾难</td></tr></tbody></table></div><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    movie,</span><br><span class="line">    category_name</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">    movie_info <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(<span class="keyword">category</span>) table_tmp <span class="keyword">as</span> category_name;</span><br></pre></td></tr></table></figure><p>结果：</p><div class="table-container"><table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑</td></tr><tr><td>《疑犯追踪》</td><td>动作</td></tr><tr><td>《疑犯追踪》</td><td>科幻</td></tr><tr><td>《疑犯追踪》</td><td>剧情</td></tr><tr><td>《Lie to me》</td><td>悬疑</td></tr><tr><td>《Lie to me》</td><td>警匪</td></tr><tr><td>《Lie to me》</td><td>动作</td></tr><tr><td>《Lie to me》</td><td>心理</td></tr><tr><td>《Lie to me》</td><td>剧情</td></tr><tr><td>《战狼2》</td><td>战争</td></tr><tr><td>《战狼2》</td><td>动作</td></tr><tr><td>《战狼2》</td><td>灾难</td></tr></tbody></table></div><h2 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h2><p>OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变而变化</p><p>CURRENT ROW：当前行</p><p>n PRECEDING：往前n行数据</p><p>n FOLLOWING：往后n行数据</p><p>UNBOUNDED：起点，UNBOUNDED PRECEDING 表示从前面的起点， UNBOUNDED FOLLOWING表示到后面的终点</p><p>LAG(col,n)：往前第n行数据</p><p>LEAD(col,n)：往后第n行数据</p><p>NTILE(n)：把有序分区中的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组的编号。<strong>注意：n必须为int类型</strong>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">  <span class="keyword">name</span>,</span><br><span class="line">  orderdate,</span><br><span class="line">  <span class="keyword">cost</span>, </span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>() <span class="keyword">as</span> sample1,<span class="comment">--所有行相加 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span>) <span class="keyword">as</span> sample2,<span class="comment">--按name分组，组内数据相加 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate) <span class="keyword">as</span> sample3,<span class="comment">--按name分组，组内数据累加 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate <span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">PRECEDING</span> <span class="keyword">and</span> <span class="keyword">current</span> <span class="keyword">row</span>) <span class="keyword">as</span> sample4 ,<span class="comment">--和sample3一样,由起点到当前行的聚合 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> <span class="keyword">PRECEDING</span> <span class="keyword">and</span> <span class="keyword">current</span> <span class="keyword">row</span>) <span class="keyword">as</span> sample5, <span class="comment">--当前行和前面一行做聚合 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="number">1</span> <span class="keyword">FOLLOWING</span> ) <span class="keyword">as</span> sample6,<span class="comment">--当前行和前边一行及后面一行 </span></span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">cost</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate <span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="keyword">row</span> <span class="keyword">and</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">FOLLOWING</span> ) <span class="keyword">as</span> sample7 <span class="comment">--当前行及后面所有行 </span></span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">  business;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看顾客上次购买时间</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">  <span class="keyword">name</span>,</span><br><span class="line">  orderdate,</span><br><span class="line">  <span class="keyword">cost</span>, </span><br><span class="line">  lag(orderdate,<span class="number">1</span>,<span class="string">'1900-01-01'</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate ) <span class="keyword">as</span> time1,     </span><br><span class="line">  lag(orderdate,<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> orderdate) <span class="keyword">as</span> time2 </span><br><span class="line"><span class="keyword">from</span> business;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询前20%时间的订单信息</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">  * </span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span> </span><br><span class="line">    <span class="keyword">name</span>,orderdate,<span class="keyword">cost</span>,ntile(<span class="number">5</span>) <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> orderdate) sorted</span><br><span class="line">  <span class="keyword">from</span></span><br><span class="line">    business</span><br><span class="line">) t</span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">  sorted = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h2 id="rank函数"><a href="#rank函数" class="headerlink" title="rank函数"></a>rank函数</h2><p>RANK()：排序相同时会重复，总数不会变</p><p>DENSE_RANK()：排序相同时会重复，总数会减少</p><p>ROW_NUMBER()：会根据顺序计算</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line"><span class="keyword">name</span>,subject,score,</span><br><span class="line"><span class="keyword">rank</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) <span class="keyword">rank</span>,</span><br><span class="line"><span class="keyword">dense_rank</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) <span class="keyword">dense_rank</span>,</span><br><span class="line">row_number() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) row_number</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">score;</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>name</th><th>subject</th><th>score</th><th>rank</th><th>dense_rank</th><th>row_number</th></tr></thead><tbody><tr><td>宋宋</td><td>英语</td><td>84</td><td><strong>1</strong></td><td><strong>1</strong></td><td><strong>1</strong></td></tr><tr><td>大海</td><td>英语</td><td>84</td><td><strong>1</strong></td><td><strong>1</strong></td><td><strong>2</strong></td></tr><tr><td>婷婷</td><td>英语</td><td>78</td><td><strong>3</strong></td><td><strong>2</strong></td><td><strong>3</strong></td></tr><tr><td>孙悟空</td><td>英语</td><td>68</td><td><strong>4</strong></td><td><strong>3</strong></td><td><strong>4</strong></td></tr></tbody></table></div><h1 id="Hive调优"><a href="#Hive调优" class="headerlink" title="Hive调优"></a>Hive调优</h1><h2 id="Fetch抓取"><a href="#Fetch抓取" class="headerlink" title="Fetch抓取"></a>Fetch抓取</h2><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：<code>SELECT * FROM employees;</code>在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p><p>在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.fetch.task.conversion=more;</span><br><span class="line"><span class="keyword">select</span> ename <span class="keyword">from</span> emp <span class="keyword">limit</span> <span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h2><p>有时Hive的输入数据量是非常小的。在这种情况下，<strong>为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多</strong>。对于大多数这种情况，<strong>Hive可以通过本地模式在单台机器上处理所有的任务</strong>。对于小数据集，执行时间可以明显被缩短。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--开启本地MR</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto=<span class="literal">true</span>;  </span><br><span class="line"></span><br><span class="line"><span class="comment">--设置local MR的最大输入数据量，当输入数据量小于这个值时采用local MR的方式，默认为134217728，即128M</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.inputbytes.max=<span class="number">50000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> ename <span class="keyword">from</span> emp <span class="keyword">limit</span> <span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2 id="表的优化"><a href="#表的优化" class="headerlink" title="表的优化"></a>表的优化</h2><h3 id="小表、大表join"><a href="#小表、大表join" class="headerlink" title="小表、大表join"></a>小表、大表join</h3><p><strong>将key相对分散，并且数据量小的表放在join的左边</strong>，这样可以有效减少内存溢出错误发生的几率；</p><p>再进一步，可以使用MapJoin让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。</p><p><strong>实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</strong></p><h3 id="大表join小表"><a href="#大表join小表" class="headerlink" title="大表join小表"></a>大表join小表</h3><h4 id="空KEY过滤"><a href="#空KEY过滤" class="headerlink" title="空KEY过滤"></a>空KEY过滤</h4><p>有时join超时是因为<strong>某些key对应的数据太多</strong>，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable </span><br><span class="line"><span class="keyword">select</span> n.* <span class="keyword">from</span> nullidtable n <span class="keyword">left</span> <span class="keyword">join</span> ori o <span class="keyword">on</span> n.id = o.id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable </span><br><span class="line"><span class="keyword">select</span> n.* <span class="keyword">from</span> (<span class="keyword">select</span> * <span class="keyword">from</span> nullidtable <span class="keyword">where</span> <span class="keyword">id</span> <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">null</span> ) n  <span class="keyword">left</span> <span class="keyword">join</span> ori o <span class="keyword">on</span> n.id = o.id; <span class="comment">-- 更快</span></span><br></pre></td></tr></table></figure><h4 id="空KEY转换"><a href="#空KEY转换" class="headerlink" title="空KEY转换"></a>空KEY转换</h4><p>有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以<strong>表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上</strong>。  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> n.* <span class="keyword">from</span> nullidtable n <span class="keyword">full</span> <span class="keyword">join</span> ori o <span class="keyword">on</span> </span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> n.id <span class="keyword">is</span> <span class="literal">null</span> <span class="keyword">then</span> <span class="keyword">concat</span>(<span class="string">'hive'</span>, <span class="keyword">rand</span>()) <span class="keyword">else</span> n.id <span class="keyword">end</span> = o.id;</span><br></pre></td></tr></table></figure><h3 id="MapJoin"><a href="#MapJoin" class="headerlink" title="MapJoin"></a>MapJoin</h3><p>如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成join。容易发生数据倾斜。<strong>可以用MapJoin把小表全部加载到内存在map端进行join</strong>，避免reducer处理。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 设置自动选择Mapjoin</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 大表小表的阈值设置（默认25M一下认为是小表）</span></span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize=<span class="number">25000000</span>;</span><br></pre></td></tr></table></figure><blockquote><p><strong>MapJoin工作机制</strong></p><p>Hive的Join连接总是按照<strong>从前到后</strong>的顺序执行的。</p><p>当Hive执行Join时，需要选择哪个表被流式传输(steam)，哪个表被缓存(cache)。Hive将Join语句中最后一个表用于流式传输，因此我们需要确保这个流表在两者之间是最大的。</p><p>如果要在不同的key上Join更多的表，那么对于每个Join集，只需在on条件右侧指定较大的表。</p><p>将小表放在左边，大表放到join的右边，这样可以提高性能。更准确的说法：把重复关联键少的表放在join前面，做关联可以提高join的效率。写在关联左侧的表每有1条重复的关联键时底层就会多1次运算处理。</p></blockquote><h3 id="Group-By"><a href="#Group-By" class="headerlink" title="Group By"></a>Group By</h3><p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p><p>并不是所有的聚合操作都需要在Reduce端完成，<strong>很多聚合操作都可以先在Map端进行部分聚合</strong>，最后在Reduce端得出最终结果。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 是否在Map端进行聚合，默认为True</span></span><br><span class="line">hive.map.aggr = true</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 在Map端进行聚合操作的条目数目</span></span><br><span class="line">hive.groupby.mapaggr.checkinterval = 100000</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 有数据倾斜的时候进行负载均衡（默认是false）</span></span><br><span class="line">hive.groupby.skewindata = true</span><br></pre></td></tr></table></figure><p>当选项设定为 true，生成的查询计划会有两个MR Job。</p><p>第一个MR Job中，<strong>Map的输出结果会随机分布到Reduce中</strong>，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是<strong>相同的Group By Key有可能被分发到不同的Reduce中</strong>，从而达到负载均衡的目的；</p><p>第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证<strong>相同的Group By Key被分布到同一个Reduce中</strong>），最后完成最终的聚合操作。  </p><h3 id="Count-Distinct"><a href="#Count-Distinct" class="headerlink" title="Count(Distinct)"></a>Count(Distinct)</h3><p>数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用<strong>先GROUP BY再COUNT</strong>的方式替换  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 原始</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">id</span>) <span class="keyword">from</span> bigtable;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 改进</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">id</span>) <span class="keyword">from</span> (<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> bigtable <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">id</span>) a;</span><br></pre></td></tr></table></figure><p>虽然会多用一个Job来完成，但在数据量大的情况下，绝对是值得的。</p><h3 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h3><p>对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 开启动态分区功能（默认true，开启）</span></span><br><span class="line">hive.exec.dynamic.partition=true</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</span></span><br><span class="line">hive.exec.dynamic.partition.mode=nonstrict</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 在所有执行MR的节点上，最大一共可以创建多少个动态分区。</span></span><br><span class="line">hive.exec.max.dynamic.partitions=1000</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</span></span><br><span class="line">hive.exec.max.dynamic.partitions.pernode=100</span><br></pre></td></tr></table></figure><h2 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h2><p>数据倾斜：由于数据分布不均匀，造成数据大量的集中到一点，造成数据热点</p><p>主要表现：任务进度长时间维持在99%的附近，只有少量reduce子任务未完成，因为其处理的数据量和其他的 reduce 差异过大。 </p><p>数据倾斜的原因：</p><ul><li>key 分布不均匀</li><li>业务数据本身的特性（小表join大表）</li><li>建表考虑不周全</li><li>某些 HQL 语句本身就存在数据倾斜（count(distinct)，group by不和聚集函数搭配使用的时候）</li></ul><p><strong>目的：使map的输出数据更均匀的分布到reduce中去</strong></p><p><strong>在hive中产生数据倾斜的原因和解决方法：</strong></p><ul><li><strong>group by</strong><ul><li>使用Hive对数据做一些类型统计的时候遇到过<strong>某种类型的数据量特别多，而其他类型数据的数据量特别少</strong>。当按照类型进行group by的时候，会将相同的group by字段的reduce任务<strong>需要的数据拉取到同一个节点进行聚合</strong>，而当其中每一组的数据量过大时，会出现其他组的计算已经完成而这里还没计算完成，其他节点的一直等待这个节点的任务执行完成，所以会看到一直map 100% reduce 99%的情况。</li><li>解决方法：设置参数<code>set hive.map.aggr=true; set hive.groupby.skewindata=true;</code></li><li>原理：<code>set hive.map.aggr=true;</code>这个配置项代表<strong>是否在map端进行聚合</strong>。<code>set hive.groupby.skwindata=true;</code> 当选项设定为 true，生成的查询计划会有两个 MR Job。第一个 MR Job 中，<strong>Map 的输出结果集合会随机分布到Reduce中</strong>，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是<strong>相同的Group By Key有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的</strong>；第二个 MR Job 再根据预处理的数据结果按照 Group By Key分布到 Reduce 中（这个过程可以<strong>保证相同的Group By Key被分布到同一个Reduce中</strong>），最后完成最终的聚合操作。</li></ul></li><li><strong>map和reduce优化</strong></li><li>当出现小文件过多，需要合并小文件。可以通过<code>set hive.merge.mapfiles=true</code>来解决。<ul><li>单个文件大小稍稍大于配置的block块的大写，此时需要适当增加map的个数。解决方法：set mapred.map.tasks个数</li></ul></li><li>文件大小适中，但map端计算量非常大，如select id,count(*),sum(case when…),sum(case when…)…需要增加map个数。解决方法：set mapred.map.tasks个数，set mapred.reduce.tasks个数<ul><li>大表和小表join。解决方法：使用<strong>MapJoin</strong> 将小表加载到内存中（在Map阶段进行表之间的连接。而不需要进入到Reduce阶段才进行连接。这样就节省了在Shuffle阶段时要进行的大量数据传输。从而起到了优化作业的作用）。set hive.auto.convert.join=true;</li></ul></li><li><p><strong>count(distinct)</strong></p><ul><li>如果数据量非常大，执行如<code>select a, count(distinct b) from t group by a;</code>类型的SQL时，会出现数据倾斜的问题。</li><li>解决方法：使用sum…group by代替。如select a, sum(1) from (select a, b from t group by a, b) group by a;</li></ul></li><li><p><strong>遇到需要进行join的但是关联字段有数据为空</strong></p><ul><li>解决方法1：id为空的不参与关联</li><li>解决方法2：给空值分配随机的key值，其核心是将这些引起倾斜的值随机分发到Reduce</li></ul></li></ul><h3 id="合理设置Map数"><a href="#合理设置Map数" class="headerlink" title="合理设置Map数"></a>合理设置Map数</h3><ul><li><p>如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。因此需要<strong>减少map数</strong>。</p></li><li><p>比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。因此<strong>增加map数</strong>。</p></li><li><p>复杂文件增加Map数</p><ul><li>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</li><li>增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</li></ul></li></ul><h3 id="合理设置Reduce数"><a href="#合理设置Reduce数" class="headerlink" title="合理设置Reduce数"></a>合理设置Reduce数</h3><ul><li><p>调整reduce个数方法一</p><ul><li>每个Reduce处理的数据量默认是256MB。<code>hive.exec.reducers.bytes.per.reducer=256000000</code></li><li>每个任务最大的reduce数默认为1009。<code>hive.exec.reducers.max=1009</code></li><li>计算reducer数的公式：N=min(参数2，总输入数据量/参数1)</li></ul></li><li><p>调整reduce个数方法二</p><ul><li>在hadoop的mapred-default.xml文件中修改</li><li>设置每个job的Reduce个数<code>set mapreduce.job.reduces = 15;</code></li></ul></li><li><p>reduce个数并不是越多越好</p><ul><li>过多的启动和初始化reduce也会消耗时间和资源；</li><li>另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</li><li>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</li></ul></li></ul><h3 id="小文件进行合并"><a href="#小文件进行合并" class="headerlink" title="小文件进行合并"></a>小文件进行合并</h3><p>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p><p>set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</p><h3 id="并行执行"><a href="#并行执行" class="headerlink" title="并行执行"></a>并行执行</h3><p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p><p><strong>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。</strong></p><p>不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。在系统资源比较空闲的时候才有优势。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;       <span class="comment">-- 打开任务并行执行</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number=<span class="number">16</span>; <span class="comment">-- 同一个sql允许最大并行度，默认为8。</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白板推导系列3——线性回归</title>
      <link href="/2020/02/07/bai-ban-tui-dao-xi-lie-3-xian-xing-hui-gui/"/>
      <url>/2020/02/07/bai-ban-tui-dao-xi-lie-3-xian-xing-hui-gui/</url>
      
        <content type="html"><![CDATA[<ul><li>最小二乘法（矩阵表达，几何意义）</li><li>概率角度：最小二乘法$\Longleftrightarrow$noise为正态分布的MLE</li><li>正则化（L1:Lasso；L2：Ridge）</li></ul><h1 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h1><p>Data：$\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in R,i=1,\cdots,N$</p><p>$X_{N<em>p}=(x_1,x_2,…,x_N)^T,Y_{N</em>1}=(y_1,y_2,…,y_N)^T$</p><p>定义最小二乘法的损失函数</p><script type="math/tex; mode=display">\begin{align}L(w)&=\sum_{i=1}^{N}(w^Tx_i-y_i)^2\\&=(w^Tx_1-y_1,\cdots,w^Tx_N-y_N)(w^Tx_1-y_1,\cdots,w^Tx_N-y_N)^T\\&=[w^T(x_1,\cdots,x_N)-(y_1,\cdots,y_N)][w^T(x_1,\cdots,x_N)-(y_1,\cdots,y_N)]^T\\&=(w^TX^T-Y^T)(Xw-Y)\\&=w^TX^TXw-w^TX^TY-Y^TXw+Y^TY\\&=w^TX^TXw-2w^TX^TY+Y^TY\end{align}</script><p>求解参数$w$</p><script type="math/tex; mode=display">\hat{w}=\arg\min L(w)\\\frac{\partial L(w)}{\partial w}=2X^TXw-2X^TY=0\\\Rightarrow w=(X^TX)^{-1}X^TY</script><h2 id="几何意义"><a href="#几何意义" class="headerlink" title="几何意义"></a>几何意义</h2><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200208/UJ34aJcsDTUb.jpg" alt="mark"></p><h2 id="概率角度"><a href="#概率角度" class="headerlink" title="概率角度"></a>概率角度</h2><p>假定</p><script type="math/tex; mode=display">\varepsilon \sim N(0,\sigma^2)\\y=f(w)+\varepsilon=w^Tx+\varepsilon\\y|x;w\sim N(w^Tx,\sigma^2)\\P(y|x;w)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\frac{-(y_i-w^Tx_i)^2}{2\sigma^2}}</script><p>定义对数似然函数为</p><script type="math/tex; mode=display">l(w)=\log P(Y|X;w)=\log \prod_{i=1}^{N}P(y_i|x_i;w)=\sum_{i=1}^{N}\log P(y_i|x_i;w)\\=\sum_{i=1}^{N}[\log\frac{1}{\sqrt{2\pi}\sigma}-\frac{(y_i-w^Tx_i)^2}{2\sigma^2}]</script><script type="math/tex; mode=display">\begin{align}\hat{w}&=\arg\max \limits_{w}l(w)\\&=\arg\max \limits_{w}\sum_{i=1}^{N}[-\frac{(y_i-w^Tx_i)^2}{2\sigma^2}]\\&=\arg\min \limits_{w}\sum_{i=1}^{N}(y_i-w^Tx_i)^2\end{align}</script><p>可以得到极大似然估计（noise服从正态分布的条件下）与最小二乘估计等价</p><p>即LSE $\Longleftrightarrow$ MLE​(noise is Gaussian Dist)</p><h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>过拟合解决方法：</p><ol><li>加数据</li><li>特征选择/特征提取（如PCA）</li><li>正则化（对参数空间的约束）</li></ol><h2 id="正则化框架"><a href="#正则化框架" class="headerlink" title="正则化框架"></a>正则化框架</h2><script type="math/tex; mode=display">\arg\min \limits_{w}J(w)=\arg\min \limits_{w}[L(w)+\lambda P(w)]</script><p>其中$L(w)$代表损失函数，$P(w)$代表penalty</p><ul><li>L1：Lasso，$P(w)=||w||$</li><li>L2：Ridge岭回归（权值衰减），$P(w)=w^Tw$</li></ul><h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>令</p><script type="math/tex; mode=display">\begin{align}J(w)&=L(w)+\lambda P(w)\\&=\sum_{i=1}^{N}||w^Tx_i-y_i||^2+\lambda w^Tw\\&=(w^TX^T-Y^T)(XW-Y)+\lambda w^Tw\\&=w^TX^TXW-w^TX^TY-Y^TXW+Y^TY+\lambda w^Tw\\&=w^TX^TXW-2w^TX^TY+Y^TY+\lambda w^Tw\\&=w^T(X^TX+\lambda I)W-2w^TX^TY+Y^TY\end{align}</script><script type="math/tex; mode=display">\hat{w}=\arg\max \limits_{w}J(w)\\\frac{\partial J(w)}{\partial w}=2(X^TX+\lambda I)W-2X^TY=0\\\hat{w}=(X^TX+\lambda I)^{-1}X^TY</script><p>$X^TX$是半正定矩阵，从而保证$X^TX+\lambda I$一定是一个可逆矩阵，从而一定程度抑制过拟合</p><h2 id="贝叶斯角度"><a href="#贝叶斯角度" class="headerlink" title="贝叶斯角度"></a>贝叶斯角度</h2><script type="math/tex; mode=display">w \sim N(0,\sigma_0^2)\\P(w|y)=\frac{P(y|w)P(w)}{P(y)}</script><p>从MAP（最大后验估计）来估计$w$：</p><script type="math/tex; mode=display">\hat{w}=\arg\max \limits_{w}P(w|y)=\arg\max \limits_{w}P(y|w)P(w)</script><p>其中，由于$y|x;w\sim N(w^Tx,\sigma^2)$（条件同最小二乘法-概率角度，即noise服从$N(0,\sigma^2)$），则</p><script type="math/tex; mode=display">P(y|x;w)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\frac{-(y_i-w^Tx_i)^2}{2\sigma^2}}</script><p>又因为$w \sim N(0,\sigma_0^2)$，则</p><script type="math/tex; mode=display">P(w)=\frac{1}{\sqrt{2\pi}\sigma_0}\exp{\frac{-||w||^2}{2\sigma^2_0}}</script><p>从而（为简化过程省略求和符号）</p><script type="math/tex; mode=display">\begin{align}\hat{w}&=\arg\max \limits_{w}P(y|w)P(w)\\&=\arg\max \limits_{w}\log [P(y|w)P(w)]\\&=\arg\max \limits_{w}\log\exp[-\frac{(y_i-w^Tx_i)^2}{2\sigma^2}-\frac{||w||^2}{2\sigma^2_0}]\\&=\arg\min \limits_{w}[\frac{(y_i-w^Tx_i)^2}{2\sigma^2}+\frac{||w||^2}{2\sigma^2_0}]\\&=\arg\min \limits_{w}[(y_i-w^Tx_i)^2+\frac{\sigma^2}{\sigma^2_0}||w||^2]\end{align}</script><p>因此最终的MAP估计为</p><script type="math/tex; mode=display">\hat{w}=\arg\min \limits_{w}[\sum_{i=1}^{N}(y_i-w^Tx_i)^2+\frac{\sigma^2}{\sigma^2_0}||w||^2]</script><p>因此加上正则化的最小二乘估计 $\Longleftrightarrow$ MAP(noise服从高斯分布，先验也服从高斯分布)</p><blockquote><p>总结：</p><p>LSE $\Longleftrightarrow$ MLE(noise is Gaussian Dist)</p><p>Regularized LSE $\Longleftrightarrow$ MAP(noise is Gaussian Dist, prior is Gaussian Dist)</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
            <tag> Regression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白板推导系列6——支持向量机SVM</title>
      <link href="/2020/02/06/bai-ban-tui-dao-xi-lie-6-zhi-chi-xiang-liang-ji-svm/"/>
      <url>/2020/02/06/bai-ban-tui-dao-xi-lie-6-zhi-chi-xiang-liang-ji-svm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>b站up主： <strong>shuhuai008</strong> </p><p><a href="https://www.bilibili.com/video/av70839977" target="_blank" rel="noopener">机器学习-白板推导系列-合集</a> 学习笔记</p></blockquote><p>SVM有三宝：间隔，对偶，核技巧~</p><ul><li>hard-margin SVM</li><li>soft-margin SVM</li><li>kernel SVM</li></ul><h1 id="硬间隔SVM"><a href="#硬间隔SVM" class="headerlink" title="硬间隔SVM"></a>硬间隔SVM</h1><h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><p>找到一个超平面$w^Tx+b=0$，使得两类能够完全分开，且间隔最大。</p><p>Data：$\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in \{+1,-1\}$</p><p>最大间隔分类器</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \max margin(w,b)\\s.t.y_i(w^Tx+b)>0,\forall i=1,…,N\end{array} \right.</script><p>其中定义$N$个样本点到直线的最小距离为</p><script type="math/tex; mode=display">margin(w,b)=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}distance=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}\frac{1}{||w||}|w^Tx_i+b|=\mathop{\min}\limits_{w,b,x_i\\i=1,\cdots,N}\frac{1}{||w||}y_i(w^Tx_i+b)</script><blockquote><p>上式用到了点到直线的距离公式</p><script type="math/tex; mode=display">distance=\frac{1}{||w||}|w^Tx_i+b|</script></blockquote><p>因此最大间隔分类器可以表达为</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \max\limits_{w,b} \mathop{\min}\limits_{x_i,i=1,\cdots,N}\frac{1}{||w||}y_i(w^Tx_i+b) \\s.t.y_i(w^Tx+b)>0,\forall i=1,…,N\end{array} \right.</script><p>可以转化为</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \max\limits_{w,b} \frac{1}{||w||}\mathop{\min}\limits_{x_i,i=1,\cdots,N}y_i(w^Tx_i+b)\\\exists \gamma>0,s.t.\mathop{\min}\limits_{x_i,y_i,i=1,\cdots,N}y_i(w^Tx_i+b)=\gamma\end{array} \right.</script><p>可以令$\gamma=1$（无论$\gamma$为多少都可以进行缩放至1）</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{w,b} \frac{1}{2}w^Tw\\s.t.y_i(w^Tx_i+b)\ge1,\forall i=1,…,N\end{array} \right.</script><p>（使用$\frac{1}{2}$作为系数仅为了求导方便）</p><p>可以看出该模型是凸二次规划问题，有$N$个约束。</p><h2 id="模型求解"><a href="#模型求解" class="headerlink" title="模型求解"></a>模型求解</h2><h3 id="原问题primal-problem"><a href="#原问题primal-problem" class="headerlink" title="原问题primal problem"></a>原问题primal problem</h3><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{w,b} \frac{1}{2}w^Tw\\s.t. 1-y_i(w^Tx_i+b)\le0,\forall i=1,…,N\end{array} \right.</script><p>使用拉格朗日乘子法，定义拉格朗日函数为</p><script type="math/tex; mode=display">L(w,b,\lambda)=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b))</script><p>其中$\lambda_i\ge0$，将求解问题转化为</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)\\s.t. \lambda_i\ge0\end{array} \right.</script><p>从而将带约束的问题转化成无约束的（对$w,b$无约束）</p><blockquote><p><strong>Q：如何证明带约束的和无约束的是等价的？</strong></p><p>如果$1-y_i(w^Tx_i+b)&gt;0$，则$\max\limits_{\lambda } L(w,b,\lambda)=\frac{1}{2}w^Tw+\infty=\infty$</p><p>如果$1-y_i(w^Tx_i+b)\le0$，则$\max\limits_{\lambda } L(w,b,\lambda)=\frac{1}{2}w^Tw+0=\frac{1}{2}w^Tw$，$\min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)=\min\limits_{w,b}\frac{1}{2}w^Tw$</p><p>因此$\min\limits_{w,b} \max\limits_{\lambda } L(w,b,\lambda)=\min\limits_{w,b}\{\infty,\frac{1}{2}w^Tw\}=\min\limits_{w,b}\frac{1}{2}w^Tw $</p><p>且去除了$1-y_i(w^Tx_i+b)&gt;0$部分，即最优解一定满足$1-y_i(w^Tx_i+b)\le0$</p><p>（奇妙！！）</p></blockquote><h3 id="对偶问题dual-problem"><a href="#对偶问题dual-problem" class="headerlink" title="对偶问题dual problem"></a>对偶问题dual problem</h3><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \max\limits_{\lambda }\min\limits_{w,b}  L(w,b,\lambda)\\s.t. \lambda_i\ge0\end{array} \right.</script><p>经过某种神秘的证明再结合本身成立的“凤尾$\ge$鸡头”弱对偶关系（$\min\max L\ge\max\min L$），可以证明该情况下（凸优化二次问题）满足强对偶关系，即弱对偶关系“$\ge$”等价于强对偶关系“$=$”（$\min\max L=\max\min L$），因此原问题等价于对偶问题。</p><p>对$b$求偏导</p><script type="math/tex; mode=display">\frac{\partial L}{\partial b}=\frac{\partial }{\partial b}[\sum_{i=1}^{N}\lambda_i-\sum_{i=1}^{N}\lambda_iy_i(w^Tx_i+b)]=-\sum_{i=1}^{N}\lambda_iy_i=0\\\Rightarrow\sum_{i=1}^{N}\lambda_iy_i=0</script><p>代入到拉格朗日函数中，从而转化为</p><script type="math/tex; mode=display">L(w,b,\lambda)=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b))=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)</script><p>再对$w$求偏导</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w}=\frac{\partial }{\partial w}[\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)]=w-\sum_{i=1}^{N}\lambda_iy_ix_i=0\\\Rightarrow w=\sum_{i=1}^{N}\lambda_iy_ix_i</script><p>再代入到拉格朗日函数中，从而转化为</p><script type="math/tex; mode=display">\begin{align}L(w,b,\lambda)&=\frac{1}{2}w^Tw+\sum_{i=1}^{N}\lambda_i(1-y_iw^Tx_i)\\&=\frac{1}{2}(\sum_{i=1}^{N}\lambda_iy_ix_i)^T(\sum_{j=1}^{N}\lambda_jy_jx_j)+\sum_{i=1}^{N}\lambda_i-\sum_{i=1}^{N}\lambda_iy_i(\sum_{i=1}^{N}\lambda_iy_ix_i)^Tx_i\\&=-\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\lambda_i\lambda_jy_iy_jx_i^Tx_j+\sum_{i=1}^{N}\lambda_i\end{align}</script><p>最终的优化问题可以表达为</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{\lambda } \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\lambda_i\lambda_jy_iy_jx_i^Tx_j-\sum_{i=1}^{N}\lambda_i\\s.t. \lambda_i\ge0,\sum_{i=1}^{N}\lambda_iy_i=0\end{array} \right.</script><h3 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h3><script type="math/tex; mode=display">\left\{\begin{array}{**lr**}  \frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0,\frac{\partial L}{\partial \lambda}=0\\\lambda_i(1-y_i(w^Tx_i+b))=0\\\lambda_i \ge 0\\1-y_i(w^Tx_i+b)\le0\end{array} \right.</script><p>原对偶问题具有强对偶关系（默认情况下满足弱对偶关系且是凸二次规划问题且约束是线性的）$\Longleftrightarrow$满足KKT条件</p><blockquote><p>KKT条件（后有详细）</p><p>第一行：梯度条件</p><p>第二行$\lambda_i(1-y_i(w^Tx_i+b))=0$：松弛互补条件</p><p>第三四行：可行条件</p></blockquote><p>已经求出最优的$w$解为</p><script type="math/tex; mode=display">w^*=\sum_{i=1}^{N}\lambda_iy_ix_i</script><p>又因为松弛互补条件，一定存在一个样本点$(x_k,y_k)$使得$1-y_k(w^Tx_k+b)=0$</p><blockquote><p>若不存在，则只能所有$\lambda_i=0$，则目标函数$L(w,b,\lambda)=\frac{1}{2}w^Tw$，没有任何限制</p><p>对于少数$\lambda_i\neq 0$的样本称为支持向量 ，实际上只有这些样本在真正起作用</p></blockquote><p>对其进行化简得到$b^*$</p><script type="math/tex; mode=display">y_k(w^Tx_k+b)=1\\y_k^2(w^Tx_k+b)=y_k\\\Rightarrow b^*=y_k-w^Tx_k=y_k-\sum_{i=1}^{N}\lambda_iy_ix_i^Tx_k</script><p>因此决策超平面为</p><script type="math/tex; mode=display">f(x)=sign({w^*}^Tx+b^*)</script><h1 id="软间隔SVM"><a href="#软间隔SVM" class="headerlink" title="软间隔SVM"></a>软间隔SVM</h1><p>数据是不可分的，或数据是可分的但存在一定噪声，此时应使用软间隔SVM</p><p>soft：允许一点点错误，用loss来表达，加到损失函数上</p><ul><li>定义$loss=\sum_{i=1}^{N}I\{y_i(w^Tx_i+b)&lt;1\}$，但缺点在于该loss function不连续，不能求导，因此不使用该loss function</li><li>定义loss为距离（合页损失hinge loss），$loss=\sum_{i=1}^{N}\max\{0,1-y_i(w^Tx_i+b)\}$，函数是连续的√<ul><li>如果$y_i(w^Tx_i+b)\ge1,loss=0$</li><li>如果$y_i(w^Tx_i+b)&lt;1,loss=1-y_i(w^Tx_i+b)$</li></ul></li></ul><p>引入$\xi_i=1-y_i(w^Tx_i+b),\xi_i\ge0$，得到软间隔SVM的最终形式</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{\lambda } \frac{1}{2}w^Tw+C\sum_{i=1}^{N}\xi_i\\s.t. y_i(w^Tx_i+b)\ge1-\xi_i\end{array} \right.</script><h1 id="约束优化问题"><a href="#约束优化问题" class="headerlink" title="约束优化问题"></a>约束优化问题</h1><blockquote><p>这一节实际和SVM没有直接关系，是最优化的内容</p></blockquote><ul><li>原问题（Primal Problem）</li></ul><p>原问题的一般表达形式（原问题的有约束形式）</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{x\in R^p }f(x)\\s.t. &m_i(x)\le0, i=1,\cdots,M\\&n_j(x)\le0, j=1,\cdots,N\end{array} \right.</script><p>写成拉格朗日函数的形式</p><script type="math/tex; mode=display">L(x,\lambda,\eta)=f(x)+\sum_{i=1}^{M}\lambda_im_i(x)+\sum_{j=1}^{N}\eta_in_i(x)</script><p>可以将原问题转化为（原问题的无约束形式）</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{x}\max\limits_{\lambda,\eta} L(x,\lambda,\eta)\\s.t. \lambda_i\ge0\end{array} \right.</script><blockquote><p>Q：为何两者是等价的？</p><p>如果$x_i$违反约束$m_i(x)\le0$，即$m_i(x)\gt0$，则$\max\limits_{\lambda} L\rightarrow\infty$</p><p>如果$x_i$符合约束$m_i(x)\le0$，则$\max\limits_{\lambda} L\nrightarrow\infty$</p><p>$\min\limits_{x}\max\limits_{\lambda} L=\min\limits_{x}\{\max\limits_{\lambda} L,\infty\}=\min\limits_{x}\max\limits_{\lambda}  L$</p><p>实际上是进行了过滤，其中蕴含了约束$m_i(x)\le0$，自动去掉了$m_i(x)\gt0$的部分</p></blockquote><ul><li>对偶问题（Dual Problem）</li></ul><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \max\limits_{\lambda,\eta} \min\limits_{x}L(x,\lambda,\eta)\\s.t. \lambda_i\ge0\end{array} \right.</script><blockquote><p>原问题是关于$x$的函数，对偶问题是关于$\lambda,\eta$的函数</p></blockquote><h2 id="弱对偶性"><a href="#弱对偶性" class="headerlink" title="弱对偶性"></a>弱对偶性</h2><p>弱对偶性：对偶问题(d)$\le$原问题(p)</p><p>之前使用了“凤尾$\ge$鸡头”的比喻来说明，此处在理论上进行证明：</p><script type="math/tex; mode=display">\max\limits_{\lambda,\eta} \min\limits_{x} L(x,\lambda,\eta)\le \min\limits_{x}\max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><p>证：</p><p>由于</p><script type="math/tex; mode=display">\min\limits_{x} L(x,\lambda,\eta) \le L(x,\lambda,\eta) \le \max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><blockquote><p>可以理解为下面只是变量而已，好比一个多元函数，在某处取最大值还是最小值时，这时你可以只看成关于不同变量的也是可以的，因为函数最大最小值是确定的</p></blockquote><p>设</p><script type="math/tex; mode=display">A(\lambda,\eta)=\min\limits_{x} L(x,\lambda,\eta) \\B(x)=\max\limits_{\lambda,\eta} L(x,\lambda,\eta)</script><p>则上式转化为</p><script type="math/tex; mode=display">A(\lambda,\eta) \le B(x)\\\Rightarrow A(\lambda,\eta) \le \min\limits_{x}  B(x)\\\Rightarrow \max\limits_{\lambda,\eta} A(\lambda,\eta) \le \min\limits_{x}  B(x)\\\Rightarrow \max\limits_{\lambda,\eta} \min\limits_{x} L(x,\lambda,\eta) \le \min\limits_{x}  \max\limits_{\lambda,\eta} L(x,\lambda,\eta)\\</script><p>从而得证。</p><h2 id="对偶性的几何解释"><a href="#对偶性的几何解释" class="headerlink" title="对偶性的几何解释"></a>对偶性的几何解释</h2><p>简化后的优化问题可以表达为</p><script type="math/tex; mode=display">\left\{\begin{array}{**lr**} \min\limits_{x\in R^p }f(x)\\s.t. m_i(x)\le0, i=1,\cdots,M\end{array} \right.</script><p>其中定义域$D=\mathrm{dom}f\cap \mathrm{dom} m_i$</p><p>拉格朗日函数定义为</p><script type="math/tex; mode=display">L(x,\lambda)=f(x)+\lambda m_1(x),\lambda\ge0</script><p>原问题最优解定义为</p><script type="math/tex; mode=display">p^*=\min f(x)</script><p>对偶问题最优解定义为</p><script type="math/tex; mode=display">d^*=\max\limits_{\lambda} \min\limits_{x} L(x,\lambda)</script><p>定义区域$G$为（一般化区域$G$认为其为非凸集）</p><script type="math/tex; mode=display">G=\{(m_1(x),f(x))|x\in D\}=\{(u,t)|x\in D\}</script><p>因此$p^*$可以表达为</p><script type="math/tex; mode=display">p^*=\inf\{t|(u,t)\in G,u\le 0\}</script><p>（集合中的下确界相当于集合中的最小值）</p><p>$d^*$可以表达为</p><script type="math/tex; mode=display">\begin{align}d^*&=\max\limits_{\lambda} \min\limits_{x} L(x,\lambda)\\&= \max\limits_{\lambda} \min\limits_{x} (t+\lambda u)\\&= \max\limits_{\lambda} g(\lambda)\end{align}</script><p>其中$g(\lambda)=\min\limits_{x} (t+\lambda u)=\inf\{t+\lambda u|(u,t)\in G\}$</p><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200207/dEyLlYLvko39.jpg" alt="mark"></p><h2 id="slater-condition"><a href="#slater-condition" class="headerlink" title="slater condition"></a>slater condition</h2><p>凸优化 + slater条件 $\Rightarrow$ 强对偶条件</p><p>slater condition定义：</p><script type="math/tex; mode=display">\exists \hat{x} \in reliant D\\s.t. \forall i=1,\cdots,M, m_i(\hat{x})<0</script><p>其中reliant为relative interior（相对内部），去除边界的部分，内点的集合</p><ol><li>对于大多数凸优化，slater条件成立</li><li>放松的slater条件：如果$M$中有$K$个仿射函数，只需要校验剩余的$M-K$个函数是否满足上述条件。（仿射函数：一阶的多项式函数）</li></ol><p>凸二次规划：目标函数$f$是凸函数，限制条件$m_i$是仿射函数（线性函数一定是仿射函数），$n_j$是仿射函数。</p><p><strong>SVM是凸二次规划问题，满足强对偶条件，因此可以使用KKT条件直接求解。</strong></p><h2 id="KKT条件-1"><a href="#KKT条件-1" class="headerlink" title="KKT条件"></a>KKT条件</h2><ul><li><p><strong>可行条件</strong></p><script type="math/tex; mode=display">m_i(x^{*})\le0, n_j(x^{*})=0, \lambda^{*} \ge0</script></li><li><p><strong>互补松弛条件</strong>：$\lambda^*_im_i=0, \forall i=1,\cdots,M$</p></li></ul><script type="math/tex; mode=display">\begin{align}d^*&=\max\limits_{\lambda,\eta}g(\lambda,\eta)=g(\lambda^*,\eta^*)\\&=\min\limits_{x}L(x,\lambda^*,\eta^*)\\&\le L(x^*,\lambda^*,\eta^*)\\&=f(x^*)+\sum_{i}\lambda^*_im_i+\sum_{j}\eta^*_jn_j\\&\le f(x^*)=p^*\end{align}</script><p>且又因为强对偶关系</p><script type="math/tex; mode=display">d^*=p^*</script><p>因此不等号只能取等号，且$\sum_{j}\eta^*_jn_j=0$，因此由(10)-(11)得</p><script type="math/tex; mode=display">\sum_{i}\lambda^*_im_i=0\\\Rightarrow \lambda^*_im_i=0, \forall i=1,\cdots,M</script><p>（若存在有一个$\lambda^*_im_i&lt;0$，由于不存在小于0的部分，无法抵消，和无法等于0）</p><ul><li><strong>梯度为0</strong>：<script type="math/tex; mode=display">\frac{\partial L(x,\lambda^{*},\eta^{*})}{\partial x}|_{x=x^{*}}=0</script>由(8)-(9)可得<script type="math/tex; mode=display">\min\limits_{x}L(x,\lambda^*,\eta^*)=L(x^*,\lambda^*,\eta^*)</script>因此<script type="math/tex; mode=display">\frac{\partial L}{\partial x}|_{x=x^*}=0</script></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
            <tag> Classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Decision Tree 决策树算法及其应用</title>
      <link href="/2020/02/05/decision-tree-jue-ce-shu-suan-fa-ji-qi-ying-yong/"/>
      <url>/2020/02/05/decision-tree-jue-ce-shu-suan-fa-ji-qi-ying-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="分类树理论"><a href="#分类树理论" class="headerlink" title="分类树理论"></a>分类树理论</h1><p>递归地选择最优特征，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类的过程。</p><ul><li><strong>信息熵</strong>：表示随机变量不确定性的度量</li></ul><script type="math/tex; mode=display">Info(D)=-\sum_{i=1}^{n}{p_ilog_2p_i}</script><p>​        其中$p_i$指样本集合$D$中第$i$类样本所占比例。</p><p>​        信息熵描述样本集合$D$携带的信息量。 信息量越大（值变化越多），则越不确定，越不容易被预测。</p><ul><li><strong>信息熵特点</strong>： <ol><li>不同类别的概率分布越均匀，信息熵越大</li><li>类别个数越多，信息熵越大</li><li>信息熵越大，越不容易被预测（变化个数多，变化之间区分小，则越不容易被预测；对于确定性问题，信息熵为0）</li></ol></li></ul><h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><p><strong>特征选择</strong>：从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何该选择特征有着很多不同评估标准，从而衍生出不同的决策树算法。</p><p>特征选择的关键是如何选择最优特征对数据集进行划分，随着划分过程的进行，希望决策树的分支结点所包含的样本尽可能属于同一类别，即节点的纯度越来越高。</p><p>根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分此时决策树停止生长。</p><p>有三种选择最优特征的标准：信息增益、增益率和基尼指数，分别对应了三种决策树算法：ID3，C4.5，CART。</p><h3 id="ID3算法：信息增益"><a href="#ID3算法：信息增益" class="headerlink" title="ID3算法：信息增益"></a>ID3算法：信息增益</h3><p>计算每个特征的信息增益，并比较它们的大小，每一次都选择使得<strong>信息增益最大</strong>的特征进行分裂，递归地构建决策树。信息增益越大，意味着使用某个特征进行划分所获得的纯度的提升越大。</p><p>信息增益$Gain(A)$：由于特征$A$使数据集$D$的分类不确定性减少的程度</p><script type="math/tex; mode=display">Gain(A)=Info(D)-Info_A(D)</script><p>缺点：</p><ol><li><p>选择取值较多的特征往往会具有较大的信息增益（取值越多意味着确定性更高，条件熵越小，信息增益越大），所以<strong>ID3偏向于选择取值较多的特征</strong>。</p></li><li><p>仅支持分类不支持回归、不支持连续型变量、只有树的生成没有剪枝（容易过拟合）、没有缺失值处理方法。</p></li></ol><h3 id="C4-5算法：信息增益率"><a href="#C4-5算法：信息增益率" class="headerlink" title="C4.5算法：信息增益率"></a>C4.5算法：信息增益率</h3><p>针对ID3算法的不足，C4.5算法根据信息增益比来选择特征</p><p>以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比可以对这一问题进行校正。</p><p>信息增益率$GainRate(A)$：特征$A$的信息增益$Gain(A)$与训练数据集$D$关于特征$A$的值的熵$SplitInfo(A)$之比</p><script type="math/tex; mode=display">GainRate(A)=\frac{Gain(A)}{SplitInfo(A)}</script><p>其中$SplitInfo(A)=-\sum_{k=1}^{K}\frac{|D_k|}{|D|}\log_2\frac{|D_k|}{|D|}$，其中$K$是特征$A$取值的个数，$|D|$表示样本$D$的样本个数。</p><p>特征数越多的特征对应的特征熵越大，它作为分母，一定程度上对取值较多的特征进行惩罚，避免ID3出现过拟合的特性，提升泛化能力。</p><p>信息增益率准则<strong>对可取值数目较少</strong>的特征有所偏好，因此C4.5算法不是直接选取增益率最大的候选划分特征，<strong>而是先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的</strong>。</p><p>过拟合策略：C4.5引入了正则化系数进行剪枝</p><h3 id="CART算法：基尼指数"><a href="#CART算法：基尼指数" class="headerlink" title="CART算法：基尼指数"></a>CART算法：基尼指数</h3><p>基尼指数也是度量数据集纯度的指标，CART是使用基尼指数来选择最优特征的。基尼指数越小，代表数据集的纯度越高。</p><p>假设有$K$个类，第$k$个类别的概率为$p_k$，对于样本$D$，基尼指数定义为</p><script type="math/tex; mode=display">Gini(D)=1-\sum_{k=1}^{K}p_k^2</script><p>对于样本$D$，样本个数为$|D|$。根据特征$A$的某个值$a$，把$D$分成$D_1$和$D_2$，则在特征$A$的条件下，样本$D$的基尼系数表达式为</p><script type="math/tex; mode=display">Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)</script><p>表示经过特征$A$分割之后集合$D$的不确定性，因此选<strong>基尼指数最小</strong>的特征的作为最优划分特征。</p><p>CART分类树算法每次仅对某个特征的值进行二分，而不是多分，这样<strong>CART分类树算法所建立起来的是二叉树，而不是多叉树</strong>。</p><blockquote><p><strong>CART分类树对连续特征和离散特征的处理</strong></p><ul><li>CART分类树对连续特征的处理：连续特征离散化</li></ul><p>$m$个样本的连续特征$A$从小到大排列$a_1,a_2,\cdots,a_m$，CART取相邻两样本值的平均数作为划分点，一共有$m-1$个，其中第$i$个划分点$T_i$表示为：$T_i=(a_i+a_{i+1})/2$。</p><p>分别计算这$m-1$个划分点作为二元分类点时的基尼系数，选择基尼系数最小的点为该连续特征的划分点。比如取到使基尼系数最小的点为$a_t$，则小于$a_t$的值为类别1，大于$a_t$的值为类别2，这样就做到了连续特征的离散化。</p><ul><li>CART分类树对离散特征的处理：不停地二分离散特征</li></ul><p>在ID3、C4.5算法中，比如特征$A$被选取建立决策树节点，若它有三个取值$A_1,A_2,A_3$，会在决策树上建立一个三叉点，这样的决策树是多叉树。</p><p>CART采用的是不停地二分。对于特征$A$会考虑把其分成$\{A_1\}$和$\{A_2,A_3\}$、$\{A_2\}$和$\{A_1,A_3\}$、$\{A_3\}$和$\{A_1,A_2\}$三种情况，找到基尼系数最小的组合，比如$\{A_1\}$和$\{A_2,A_3\}$，一个节点是特征$A$取值为$A_1$对应的样本，另一个节点是取值为$A_2$或$A_3$对应的样本。</p><p>由于CART分类树是二叉树，与ID3和C4.5不同，在对某特征进行划分后，该特征在后面还可以参与子节点的划分过程。</p></blockquote><h2 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h2><p>剪枝是将子树删除，用一个叶子结点代替，节点类别取多数类。为缓解决策树过拟合，需要对决策树进行剪枝。往往通过极小化决策树整体的损失函数或代价函数来实现。决策树生成学习局部的模型，而决策树剪枝学习整体的模型。</p><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>在生成决策树的过程中提前停止树的增长。核心思想是在树中节点进行扩展之前，先计算当前的划分是否能带来模型泛化性能的提升，如果不能则不再继续生成子树。</p><p>预剪枝停止决策树生长的几种方法：</p><ol><li><p>当树达到一定深度时停止生长。</p></li><li><p>当到达当前节点的样本数量小于某个阈值时停止生长。</p></li><li><p>计算每次分类对测试集的准确率提升，当小于某个阈值时停止生长。</p></li></ol><p>预剪枝的优缺点：</p><p>优点：简单高效，适合解决大规模问题。</p><p>缺点：深度和阈值这些参数很难准确估计，针对不同问题会有很大差别。前剪枝存在一定局限性，有<strong>欠拟合的风险</strong>。</p><h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>核心思想是让算法生成一棵完全生长的决策树，然后从底层向上计算是否剪枝。如果剪枝之后准确率有提升，则剪枝。</p><p>后剪枝的优缺点：</p><p>优点：通常可以得到泛化能力更强的决策树。</p><p>缺点：时间开销大。</p><h4 id="代价复杂性剪枝算法-CCP"><a href="#代价复杂性剪枝算法-CCP" class="headerlink" title="代价复杂性剪枝算法(CCP)"></a>代价复杂性剪枝算法(CCP)</h4><p>CART决策树所采用的剪枝方法，是后剪枝方法的一个实例。</p><p>算法分为两步：</p><ol><li>先从自由生成的决策树$T_0$底端开始不断剪枝，直到$T_0$的根节点，形成一个子树序列$\{T_0,T_1,\cdots,T_n\}$。</li><li>通过交叉验证的方式，在验证集中对这$n$个树序列进行评价，选择最优的子树作为最终剪枝结果。</li></ol><p>因此关键问题在于：如何构造步骤1中的子树序列$\{T_0,T_1,\cdots,T_n\}$。</p><p>首先给出子树$T$的损失函数</p><script type="math/tex; mode=display">C_\alpha(T)=C(T)+\alpha|T|</script><p>其中$C(T)$为训练集的预测误差，误差率的计算是认为较少的一部分样本数量作为误差样本（对每个叶子节点中的两个分类，个数少的是误差），$|T|$为叶节点个数，$\alpha$为剪枝系数（作为平衡代价和复杂度两者的参数），$\alpha=0$时，损失函数等于预测误差，相当于不进行剪枝；$\alpha$越大，惩罚越大，会得到更简单的树，即剪枝幅度更大。</p><p><strong>对于固定的$\alpha$，一定存在一个使得损失函数达到最小的子树$T_\alpha$，即对于$\alpha$序列$\{\alpha_0,\alpha_1,\cdots,\alpha_n\}$，有最优子树序列$\{T_0,T_1,\cdots,T_n\}$与其一一对应</strong>，因此我们只需要在最优子树系列中寻找交叉验证集效果最好的那个作为最终的剪枝结果即可。因此子树序列$\{T_0,T_1,\cdots,T_n\}$的构造可以转变为$\alpha$序列$\{\alpha_0,\alpha_1,\cdots,\alpha_n\}$的构造。</p><p>将$\alpha$序列构造为递增的序列，则子树序列$T$是满树到根节点树的递减树序列。 </p><p>首先令$\alpha_0=0$，决策树本身为$T_0$，在$T_0$上进行第一次剪枝（构造$\alpha_1$），只需要将问题聚焦于节点$t$以及对应的子树$T_t$上：</p><ul><li><p>若在节点$t$处进行剪枝，则节点$t$就变成了单节点树，对应的损失函数为</p><script type="math/tex; mode=display">C_\alpha(t)=C(t)+\alpha</script></li><li><p>若不进行剪枝，节点$t$及以下部分构成的子树$T_t$的损失函数为</p><script type="math/tex; mode=display">C_\alpha(T_t)=C(T_t)+\alpha|T_t|</script></li></ul><p>已知剪枝后的损失函数$\le$剪枝前的损失函数，则有</p><script type="math/tex; mode=display">\begin{align}C_\alpha(t) &\le C_\alpha(T_t)\\C(t)+\alpha &\le C(T_t)+\alpha|T_t|\\\alpha &\ge \frac{C(t)-C(T_t)}{|T_t|-1}\end{align}</script><p>因此对于$T_0$，能够在节点$t$处剪枝的最小$\alpha$为$\alpha_{min}=\frac{C(t)-C(T_t)}{|T_t|-1}$；当$\alpha\in[0,\frac{C(t)-C(T_t)}{|T_t|-1})$时，此时进行剪枝会使损失函数增大，不能进行剪枝。</p><p>自下而上地对每个内部节点$t$计算可以剪枝的最小$\alpha$（即$\alpha_{min}$），取$\alpha_{min}$中最小的值作为$\alpha_1$（$\alpha$序列逐渐增大，树序列逐渐更简单；最小的$\alpha_{min}$</p><p>|NTt|表示子树包含的叶子节点个数</p><p>R(T)训练数据的预测误差（如基尼指数）=节点 t 上的数据占所有数据的比例*节点 t 的误差率</p><p>R(Tt)R(Tt)是子树TtTt的预测误差=子树TtTt上所有叶子节点的预测误差之和；</p><h1 id="Sklearn中树模型输出的特征重要程度"><a href="#Sklearn中树模型输出的特征重要程度" class="headerlink" title="Sklearn中树模型输出的特征重要程度"></a>Sklearn中树模型输出的特征重要程度</h1><p>决策树中节点分裂不纯度的改变量的归一化值</p><h1 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h1><p>优点：</p><p>易于理解和解释，可视化分析，容易提取出规则</p><p>可同时处理分类型和数值型变量</p><p>缺点：</p><p>容易过拟合</p><p>通常情况下精确度不如其他算法好</p><h1 id="ID3-C4-5-CART对比"><a href="#ID3-C4-5-CART对比" class="headerlink" title="ID3/C4.5/CART对比"></a>ID3/C4.5/CART对比</h1><div class="table-container"><table><thead><tr><th>算法</th><th>支持模型</th><th>树结构</th><th>特征选择</th><th>连续值处理</th><th>缺失值</th><th>剪枝</th></tr></thead><tbody><tr><td>ID3</td><td>分类</td><td>多叉树</td><td>信息增益</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr><td>C4.5</td><td>分类</td><td>多叉树</td><td>信息增益比</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>CART</td><td>分类，回归</td><td>二叉树</td><td>基尼指数，均方误差</td><td>支持</td><td>支持</td><td>支持</td></tr></tbody></table></div><p>CART指的是分类回归树，它既可以用来分类，又可以被用来进行回归。</p><p>回归树：用平方误差最小化作为选择特征的准则</p><p>分类树：采用基尼指数最小化原则进行特征选择，递归地生成二叉树。</p><p>也提供了优化的剪枝策略</p><p><strong>从样本类型的角度：</strong></p><p>ID3只能处理离散型变量，而C4.5和CART都可以处理连续型变量。</p><p>C4.5会排序找到切分点，将连续变量转换为多个取值区间的离散型变量；</p><p>CART每次会对特征进行二值划分，适用于连续变量。</p><p><strong>从应用角度：</strong></p><p>ID3和C4.5只能用于分类，CART树可以用于分类和回归。</p><p><strong>从细节、优化过程角度：</strong></p><p>ID3对样本特征缺失值比较敏感，而C4.5和CART树都可以对缺失值进行不同方式的处理。</p><p>ID3和C4.5可以产生多叉分支，且每个特征在层级之间不会复用。CART树是二叉树，<strong>每个特征可以被重复利用</strong>。</p><p>ID3和C4.5通过剪枝来权衡树的准确性和泛化性能，CART树枝节利用全部数据发现所有可能的树结构进行对比。</p>]]></content>
      
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MachineLearning </tag>
            
            <tag> Classification </tag>
            
            <tag> DecisionTree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白板推导系列5——降维</title>
      <link href="/2020/02/05/bai-ban-tui-dao-xi-lie-5-jiang-wei/"/>
      <url>/2020/02/05/bai-ban-tui-dao-xi-lie-5-jiang-wei/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>ML中相比训练误差，更加关注的是泛化误差。过拟合问题就是造成泛化误差大的一个原因。</p><p>解决过拟合的方法：</p><ul><li><p>增加样本数量</p></li><li><p>正则化（Ridge/Lasso）</p></li><li><p>降维</p><ul><li>直接降维——特征选择<em>（不是本节的关注点，本节关注线性和非线性降维）</em></li><li>线性降维——PCA，MDS（多维空间缩放）</li><li>非线性降维——流形（Isomap，LLE）</li></ul><blockquote><p>特征维度高往往会造成<strong>维度灾难( Curse of Dimensionality )</strong></p><ul><li>从数学角度来看，每增加一个特征（属性），为了布满它所有的样本空间，所需要的样本数量呈指数级增长（例如对于一个二值变量，则至少需要$2^n$个样本数）</li><li>从几何角度来看，比如对于一个体积为1的超立方体，内接一个超球体，$V_{超球体}=C(0.5)^d$，其中$d$为维度，当$d\rightarrow\infty $时，超球体的体积无限趋于0，那么会造成<strong>数据的稀疏性</strong>，且大部分集中在一起，很难进行分类。</li></ul></blockquote></li></ul><h1 id="概率相关知识"><a href="#概率相关知识" class="headerlink" title="概率相关知识"></a>概率相关知识</h1><p>Data：$X=(x_1,x_2,…,x_N)^T_{N*P}$，$N$个样本，每个样本是$P$维的</p><p>样本均值和样本方差的矩阵表示：</p><script type="math/tex; mode=display">\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_i=\frac{1}{N}(x_1,x_2,…,x_N)1_N=\frac{1}{N}X^T1_N\\\begin{align}S_{p*p}&=\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})(x_i-\bar{x})^T\\&=\frac{1}{N}(X^T-\bar{x}1_N^T)(X^T-\bar{x}1_N^T)^T\\&=\frac{1}{N}(X^T-\frac{1}{N}X^T1_N1_N^T)(X^T-\frac{1}{N}X^T1_N1_N^T)^T\\&=\frac{1}{N}X^T(I_N-\frac{1}{N}1_N1_N^T)(I_N-\frac{1}{N}1_N1_N^T)^TX\\&=\frac{1}{N}X^THH^TX\\&=\frac{1}{N}X^THX\end{align}</script><p>其中$H=I_N-\frac{1}{N}1_N1_N^T$，且具有性质$H^T=H,H^n=H$，称为中心矩阵( centering matrix )</p><h1 id="主成分分析PCA"><a href="#主成分分析PCA" class="headerlink" title="主成分分析PCA"></a>主成分分析PCA</h1><ul><li><p>一个中心：<strong>原始特征空间的重构</strong>（将一组可能<strong>线性相关</strong>的变量通过正交变换，变换成<strong>线性无关</strong>的变量）</p></li><li><p>两个基本点（两个角度是一个方法）：<strong>最大投影方差，最小重构距离</strong>（在该方向上投影的方差最大，把投影上的点重构回去的代价最小）</p></li></ul><h2 id="最大投影方差"><a href="#最大投影方差" class="headerlink" title="最大投影方差"></a>最大投影方差</h2><ol><li><p>中心化（将中心平移到原点，即减去均值$x_i-\bar{x}$）</p></li><li><p>令被投影的向量的模为1，$||u_1||=1$</p></li><li><p>投影方差为（向量$a$在向量$b$上的投影为$a^Tb$）</p><script type="math/tex; mode=display">J=\frac{1}{N}\sum_{i=1}^{N}((x_i-\bar{x})^Tu_1)^2=u_1^T[\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})(x_i-\bar{x})^T]u_1=u_1^TSu_1</script><p>从而求解目标为</p><script type="math/tex; mode=display">\hat{u}_1=\mathop{\arg\max}\limits_{u_1} u_1^TSu_1\\s.t. u_1^Tu_1=1</script><p>使用拉格朗日乘子法</p><script type="math/tex; mode=display">L(u_1,\lambda)=u_1^TSu_1+\lambda(1-u_1^Tu_1)\\\frac{\partial L}{\partial u_1}=2Su_1-\lambda2u_1=0\\Su_1=\lambda u_1</script><p>从而$\lambda$是特征值，$u_1$是特征向量（主成分）</p></li></ol><h2 id="最小重构距离"><a href="#最小重构距离" class="headerlink" title="最小重构距离"></a>最小重构距离</h2><p>PCA可以视为以下两个部分：</p><ul><li>先进行特征空间的重构，得到$\{u_1,u_2,…,u_p\}$共$p$个特征向量</li><li>再对这$p$个特征向量进行筛选，选出前$q$个特征向量，从而实现降维</li></ul><p>原先样本为（用新的坐标轴去重构，并认为$x_i$已经是中心化后的）</p><script type="math/tex; mode=display">x_i=\sum_{k=1}^{p}(x_i^Tu_k)u_k</script><p>重构回来的样本为</p><script type="math/tex; mode=display">\hat{x}_i=\sum_{k=1}^{q}(x_i^Tu_k)u_k</script><p>重构代价为（目标是希望重构代价最小）</p><script type="math/tex; mode=display">\begin{align}J&=\frac{1}{N}\sum_{i=1}^{N}||x_i-\hat{x}_i||^2\\&=\frac{1}{N}\sum_{i=1}^{N}||\sum_{k=q+1}^{p}(x_i^Tu_k)u_k||^2\\&=\frac{1}{N}\sum_{i=1}^{N}\sum_{k=q+1}^{p}(x_i^Tu_k)^2\\&=\frac{1}{N}\sum_{i=1}^{N}\sum_{k=q+1}^{p}((x_i-\bar{x})^Tu_k)^2\\&=\sum_{k=q+1}^{p}[\sum_{i=1}^{N}\frac{1}{N}((x_i-\bar{x})^Tu_k)^2]\\&=\sum_{k=q+1}^{p}u_k^T·S·u_k\end{align}</script><p>其中坐标轴为$u_{q+1},…,u_{p}$，坐标为$x_i^Tu_{q+1},…,x_i^Tu_{p}$，对向量求模的平方即对各个坐标轴下的坐标求平方和</p><p>因此目标函数为</p><script type="math/tex; mode=display">\hat{u}_k=\mathop{\arg\max}\limits_{u_k} u_k^TSu_k\\s.t. u_k^Tu_k=1</script><h2 id="从SVD角度看PCA"><a href="#从SVD角度看PCA" class="headerlink" title="从SVD角度看PCA"></a>从SVD角度看PCA</h2><p>奇异值分解SVD：</p><script type="math/tex; mode=display">S=GKG^T\\G^TG=I</script><p>$K$为由特征值从大到小排列构成的对角矩阵</p><p>对中心化后的数据矩阵（原数据矩阵$X_{N·p}$）进行奇异值分解（任何实数矩阵可以进行奇异值分解）</p><script type="math/tex; mode=display">HX=U\Sigma V^T</script><p>样本方差矩阵为（忽略$\frac{1}{N}$）</p><script type="math/tex; mode=display">S=X^THX=X^TH^THX=V\Sigma U ^TU\Sigma V^T</script><p>由于SVD的性质</p><script type="math/tex; mode=display">U^TU=I\\V^TV=VV^T=I</script><p>且$\Sigma$为对角矩阵</p><p>则可以转换为</p><script type="math/tex; mode=display">S=V\Sigma U ^TU\Sigma V^T=V\Sigma ^2 V^T</script><p>因此不需要求样本方差矩阵$S$，可以对中心化后的数据矩阵$HX$进行奇异值分解，同样可以求得$V$和$\Sigma$，从而得到特征向量和特征值。</p><p>定义矩阵</p><script type="math/tex; mode=display">T=HXX^TH=U\Sigma V^TV\Sigma U^T=U\Sigma^2 U^T</script><p>因此$T$和$S$有相同的特征值（$\Sigma^2$）</p><ul><li><p>对$S$做特征分解，得到方向（主成分）$V$，然后通过将数据矩阵乘以方向$V$</p><script type="math/tex; mode=display">HX·V=U\Sigma V^TV=U\Sigma</script><p>从而得到在新的方向下的坐标矩阵$U\Sigma$</p></li><li><p>对$T$做特征分解（<strong>主坐标分析</strong>，Principle Coordinate Analysis，PCoA），可以直接得到坐标</p><script type="math/tex; mode=display">T=U\Sigma^2 U^T\\TU\Sigma=U\Sigma^2 U^TU\Sigma=U\Sigma^3=U\Sigma\Sigma^2</script><p>得到特征向量组成的矩阵$U\Sigma$和特征值组成的矩阵$\Sigma^2$</p></li></ul><blockquote><p>Q：为什么$U\Sigma$是$T$的特征向量组成的矩阵？$T$的特征向量组成的矩阵不应该直接是$U$吗？ </p><p>$U\Sigma$是将$T$的每个特征向量依据$HX$的相应特征值大小做缩放之后的矩阵 </p><p><strong>？？？……没懂</strong></p><p>PCA的目的是求出在新的投影方向上的坐标。PCA先通过SVD找到主成分（方向）$u_1$ ，然后对于样本点$x_i$来说，先进行中心化再乘上主成分$(x_i-\bar{x})u_i=z_i$，从而得到该样本点在新坐标轴$u_1$上的坐标$z_i$。即先求的是方向，再对样本进行投影才能得到坐标。</p><p>PCoA没有通过求方向再进行投影得到坐标的方式，而是通过对矩阵$T$进行分解，直接求出坐标</p></blockquote><p>PCoA好处：</p><p>维度方面：$S_{p<em>p},T_{N</em>N}$，当维度高时可以简化运算</p><h1 id="概率角度P-PCA"><a href="#概率角度P-PCA" class="headerlink" title="概率角度P-PCA"></a>概率角度P-PCA</h1><p>原始样本$x\in R^p$(observed data)，降维后的样本$z\in R^q$(latent data)，且$q&lt;p$</p><p>令</p><script type="math/tex; mode=display">z \sim N(0_q,I_q)\\x=w_{p*q}z+\mu+\varepsilon\\\varepsilon \sim N(0,\sigma^2I_p)</script><p>是线性高斯模型(Linear Gaussian Model)，$\sigma^2I_p$矩阵各向同性。</p><p>P-PCA关注两个问题：</p><ul><li>Inference：$P(z|x)$</li><li>Learning：$w,\mu,\sigma^2$——可使用EM算法求解，较复杂，此处省略</li></ul><p>条件：</p><script type="math/tex; mode=display">z \sim N(0,I)\\x=wz+\mu+\varepsilon\\\varepsilon \sim N(0,\sigma^2I)，\varepsilon \perp x\\E[x|z]=E[wz+\mu+\varepsilon|z]=wz+\mu\\Var[x|z]=Var[wz+\mu+\varepsilon|z]=\sigma^2I \\\Rightarrow x|z \sim N(wz+\mu,\sigma^2I)</script><p>则</p><script type="math/tex; mode=display">E[x]=E[wz+\mu+\varepsilon]=E[wz+\mu]+E[\varepsilon]=\mu\\Var[x]=Var[wz+\mu+\varepsilon]=Var[wz]+Var[\varepsilon]=ww^T+\sigma^2I\\\Rightarrow x \sim N(\mu,ww^T+\sigma^2I)</script><p>构造$x$和$z$的联合概率：</p><script type="math/tex; mode=display">Cov(x,z)=E[(x-\mu)z^T]=E[(wz+\varepsilon)z^T]=wE[zz^T]+E[\varepsilon]E[z^T]=w</script><p>则</p><script type="math/tex; mode=display">\begin{pmatrix} x  \\ z  \end{pmatrix}\sim N\begin{pmatrix} ww^T+\sigma^2I & w \\ w & I \end{pmatrix}</script><p>再由公式$x_b|x_a \sim N(\mu_b+\Sigma_{ba}\Sigma_{aa}^{-1}(x_a-\mu_a),\Sigma_{bb·a})$，从而得到$z|x$的条件概率分布</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白板推导系列4——线性分类</title>
      <link href="/2020/02/04/bai-ban-tui-dao-xi-lie-4-xian-xing-fen-lei/"/>
      <url>/2020/02/04/bai-ban-tui-dao-xi-lie-4-xian-xing-fen-lei/</url>
      
        <content type="html"><![CDATA[<blockquote><p>b站up主： <strong>shuhuai008</strong> </p><p><a href="https://www.bilibili.com/video/av70839977" target="_blank" rel="noopener">机器学习-白板推导系列-合集</a> 学习笔记</p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>对线性回归的条件逐一打破，从而引申到其它模型：</p><ul><li><p>线性：</p><ul><li>属性非线性：特征转换（多项式回归）</li><li>全局非线性（激活函数是非线性，如逻辑回归）</li><li>系数非线性：神经网络，感知机</li></ul></li><li><p>全局性（全部是由一条线拟合）：线性样条回归、决策树</p></li><li>数据未加工：PCA，流形</li></ul><p>线性回归通过激活函数进行降维，达到线性分类。</p><script type="math/tex; mode=display">y=f(w^Tx+b),x\in R^p</script><p>$f$是激活函数（activation function），$f^{-1}$是链接函数（link function）。</p><p>激活函数$f$将数据的线性组合作为输入，映射到{0,1}或[0,1]区间上；</p><p>链接函数$f^{-1}$将{0,1}或[0,1]区间映射到线性组合上。</p><p>线性分类分为两大类：</p><ol><li>硬分类：$y\in \{0,1\}$，代表模型有线性判别分析(Fisher判别分析)、感知机</li><li>软分类：$y\in [0,1]$，分为生成式模型和判别式模型。判别式直接对$P(Y|X)$进行求解，如逻辑回归；生成式不直接求解$P(Y|X)$，而是通过贝叶斯定理，即通过式$P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}$进行求解，如高斯判别分析(GDA)（假设数据本身是连续的），朴素贝叶斯（假设数据本身是离散的）。</li></ol><h1 id="感知机-Perceptron"><a href="#感知机-Perceptron" class="headerlink" title="感知机(Perceptron)"></a>感知机(Perceptron)</h1><p>思想：错误驱动——不断向正确分类的方向移动</p><p>模型</p><script type="math/tex; mode=display">f(x)=sign(w^Tx),x\in R^p,w\in R^p\\</script><p>前提：假定模型是线性可分的（若不满足可使用pocket algorithm）</p><p>策略：假设样本集$\{(x_i,y_i)\}_{i=1}^{N}$，将损失函数定义为</p><script type="math/tex; mode=display">L(w)=\sum_{i=1}^{N}I\{y_iw^Tx_i\lt 0\}</script><p>但该损失函数不可导不连续，难以求解</p><p>因此采用新的损失函数</p><script type="math/tex; mode=display">L(w)=\sum_{x_i\in D}-y_iw^Tx_i</script><p>是连续函数且可导，对其进行求导$\triangledown_wL=\sum_{x_i\in D}-y_ix_i$，可采用算法SGD（随机梯度下降）求解</p><script type="math/tex; mode=display">w^{t+1}\leftarrow w^t-\lambda\triangledown_wL=w^t+\lambda y_ix_i</script><h1 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h1><p><strong>思想：类内小，类间大。</strong>（高类聚，低耦合）</p><p>将点投影到一维的坐标轴上，每个点都对应该坐标轴上的一个值，并设定一个阈值，根据值与阈值大小进行分类。</p><p>重点：找到一个合适的投影方向，使得类内方差小，类间方差大</p><h2 id="目标函数推导"><a href="#目标函数推导" class="headerlink" title="目标函数推导"></a>目标函数推导</h2><p>给定样本$X=(x_1,x_2,…,x_N)^T,Y=(y_1,y_2,…,y_N)^T,\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in \{+1,-1\}$</p><p>定义样本集合$x_{c_1}=\{x_i|y_i=+1\},x_{c_2}=\{x_i|y_i=-1\}$</p><p>令$x_i$在$w$方向上的投影为$z_i=w^Tx_i$(假设$||w||=1)$</p><script type="math/tex; mode=display">\begin{align} \bar{z}&=\frac{1}{N}\sum_{i=1}^{N}z_i=\frac{1}{N}\sum_{i=1}^{N}w^Tx_i\\S_z  &=\frac{1}{N}\sum_{i=1}^{N}(z_i-\bar{z})(z_i-\bar{z})^T     =\frac{1}{N}\sum_{i=1}^{N}(w^Tx_i-\bar{z})(w^Tx_i-\bar{z})^T\\c_1: \bar{z}_1&=\frac{1}{N_1}\sum_{i=1}^{N_1}z_i=\frac{1}{N_1}\sum_{i=1}^{N_1}w^Tx_i\\S_1  &=\frac{1}{N_1}\sum_{i=1}^{N_1}(z_i-\bar{z}_1)(z_i-\bar{z}_1)^T     =\frac{1}{N_1}\sum_{i=1}^{N_1}(w^Tx_i-\bar{z}_1)(w^Tx_i-\bar{z}_1)^T\\     c_2: \bar{z}_2&=\frac{1}{N_2}\sum_{i=1}^{N_2}z_i=\frac{1}{N_2}\sum_{i=1}^{N_2}w^Tx_i\\S_2  &=\frac{1}{N_2}\sum_{i=1}^{N_2}(z_i-\bar{z}_2)(z_i-\bar{z}_2)^T     =\frac{1}{N_2}\sum_{i=1}^{N_2}(w^Tx_i-\bar{z}_2)(w^Tx_i-\bar{z}_2)^T\end{align}</script><p>则类间用$(\bar{z}_1-\bar{z}_2)^2$来表达，类内用$S_1+S_2$来表达</p><p>目标函数为</p><script type="math/tex; mode=display">J(w)=\frac{(\bar{z}_1-\bar{z}_2)^2}{S_1+S_2}\\\hat{w}=\mathop{\arg\max}\limits_{w} J(w)</script><p>则分子部分为</p><script type="math/tex; mode=display">(\bar{z_1}-\bar{z_2})^2=(\frac{1}{N_1}\sum_{i=1}^{N_1}w^Tx_i-\frac{1}{N_2}\sum_{i=1}^{N_2}w^Tx_i)^2=(w^T(\bar{x}_{c_1}-\bar{x}_{c_2}))^2=w^T(\bar{x}_{c_1}-\bar{x}_{c_2})(\bar{x}_{c_1}-\bar{x}_{c_2})^Tw</script><p>由于$S_1$可表达为</p><script type="math/tex; mode=display">\begin{align}S_1 &=\frac{1}{N_1}\sum_{i=1}^{N_1}(w^Tx_i-\bar{z}_1)(w^Tx_i-\bar{z}_1)^T\\&=w^T[\frac{1}{N_1}\sum_{i=1}^{N_1}(x_i-\bar{x}_{c_1})(x_i-\bar{x}_{c_2})^T]w\\&=w^T*S_{c_1}*w\end{align}</script><p>则分母部分为</p><script type="math/tex; mode=display">S_1+S_2=w^TS_{c_1}w+w^TS_{c_2}w=w^T(S_{c_1}+S_{c_2})w</script><p>因此</p><script type="math/tex; mode=display">\begin{align}J(w) &=\frac{w^T(\bar{x}_{c_1}-\bar{x}_{c_2})(\bar{x}_{c_1}-\bar{x}_{c_2})^Tw}{w^T(S_{c_1}+S_{c_2})w}\\     &=\frac{w^TS_bw}{w^TS_ww}=w^TS_bw(w^TS_ww)^{-1}\end{align}</script><p>其中$S_b=(\bar{x}_{c_1}-\bar{x}_{c_2})(\bar{x}_{c_1}-\bar{x}_{c_2})^T$为类间方差（between-class），$S_w=S_{c_1}+S_{c_2}$为类内方差（within-class），再对$w$求偏导</p><script type="math/tex; mode=display">\frac{\partial J(w)}{\partial w}=2S_bw(w^TS_ww)^{-1}+w^TS_bw(-1)(w^TS_ww)^{-2}2S_ww=0\\S_bw(w^TS_ww)=(w^TS_bw)S_ww\\S_ww=\frac{w^TS_ww}{w^TS_bw}S_bw</script><p>只需要求$w$的方向不需要求大小，因此常数不影响，因此</p><script type="math/tex; mode=display">\begin{align}w=\frac{w^TS_ww}{w^TS_bw}{S_w}^{-1}S_bw & \propto{S_w}^{-1}S_bw={S_w}^{-1}(\bar{x}_{c_1}-\bar{x}_{c_2})[(\bar{x}_{c_1}-\bar{x}_{c_2})^Tw]\\&\propto{S_w}^{-1}(\bar{x}_{c_1}-\bar{x}_{c_2})\end{align}</script><p>若$S_w^{-1}$是对角矩阵，且各向同性，则$S_w^{-1}\propto I$，那么</p><script type="math/tex; mode=display">w\propto(\bar{x}_{c_1}-\bar{x}_{c_2})</script><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>是判别式模型，直接对$P(Y|X)$进行建模，采用极大似然估计求解参数。</p><p>sigmoid函数：</p><script type="math/tex; mode=display">\sigma(z)=\frac{1}{1+e^{-z}}\\\sigma:R \longmapsto (0,1)\\w^Tx \longmapsto Probability</script><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200130/hMNRkXsKheJ9.png" alt="mark" style="zoom:67%;"></p><script type="math/tex; mode=display">\begin{align}p_1&:P(y=1|x)=\sigma(w^Tx)=\frac{1}{1+e^{-w^Tx}},y=1\\p_0&:P(y=0|x)=1-P(y=1|x)=\frac{e^{-w^Tx}}{1+e^{-w^Tx}},y=0\\\end{align}</script><script type="math/tex; mode=display">\Rightarrow P(y|x)=p_1^yp_0^{1-y}</script><p>给定样本$\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in \{0,1\}$</p><p>MLE:</p><script type="math/tex; mode=display">\begin{align} \hat{w}&=\mathop{\arg\max}\limits_{w} \log P(Y|X)\\&=\mathop{\arg\max}\limits_{w} \log \prod_{i=1}^{N}P(y_i|x_i) \\&=\mathop{\arg\max}\limits_{w} \sum_{i=1}^{N}\log P(y_i|x_i)\\&=\mathop{\arg\max}\limits_{w} \sum_{i=1}^{N}(y_i\log p_i+(1-y_i)\log p_0)\\&=\mathop{\arg\max}\limits_{w} \sum_{i=1}^{N}(y_i\log \psi(x_i;w)+(1-y_i)\log (1-\psi(x_i;w)))\end{align}</script><p>MLE是最大化问题，可以导出一个Loss function，转化为最小化问题，等价于最小化cross entropy</p><h1 id="高斯判别分析"><a href="#高斯判别分析" class="headerlink" title="高斯判别分析"></a>高斯判别分析</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>给定样本$\{(x_i,y_i)\}_{i=1}^{N},x_i\in R^p,y_i\in \{0,1\}$</p><p>高斯判别分析是生成式模型，<strong>生成式模型并不是求取$P(Y|X)$，而是利用贝叶斯定理，比较$P(y=0|x)$与$P(y=1|x)$的大小，选择较大者作为预测的类</strong>。</p><p>由贝叶斯定理</p><script type="math/tex; mode=display">P(y|x)=\frac{P(x|y)P(y)}{P(x)}\propto P(x|y)P(y)</script><p>由于$P(x|y)P(y)=P(x,y)$，因此我们主要是对于联合概率进行建模。</p><p>其中$P(y)$是先验（prior），$p(x|y)$是似然（likelihood），$P(y|x)$是后验（posterior），因此求解可以表达为</p><script type="math/tex; mode=display">\hat{y}=\mathop{\arg\max}\limits_{y\in \{0,1\}} P(y|x)=\mathop{\arg\max}\limits_{y\in \{0,1\}} P(y)P(x|y)</script><p><strong>假设$y$服从伯努利分布$Bernoulli(\phi)$，$x|y$服从高斯分布</strong></p><script type="math/tex; mode=display">\begin{align}&x|y=1 \sim N(\mu_1,\Sigma)\\&x|y=0 \sim N(\mu_2,\Sigma)\\\Rightarrow &x|y \sim N(\mu_1,\Sigma)^y*N(\mu_2,\Sigma)^{1-y}\end{align}</script><p>令参数部分</p><script type="math/tex; mode=display">\theta = (\mu_1,\mu_2,\Sigma,\phi)\\\hat{\theta}=\mathop{\arg\max}\limits_{\theta} l(\theta)</script><p>定义对数似然函数为</p><script type="math/tex; mode=display">\begin{align}l(\theta)&=\log \prod_{i=1}^{N}p(x_i,y_i)\\&=\sum_{i=1}^{N}\log(P(x_i|y_i)P(y_i))\\&=\sum_{i=1}^{N}[\log P(x_i|y_i)+\log P(y_i)]\\&=\sum_{i=1}^{N}[\log N(\mu_1,\Sigma)^{y_i}*N(\mu_2,\Sigma)^{1-y_i}+\log \phi^{y_i}(1-\phi)^{1-y_i}]\\&=\sum_{i=1}^{N}[\log N(\mu_1,\Sigma)^{y_i}+\log N(\mu_2,\Sigma)^{1-y_i}+\log \phi^{y_i}(1-\phi)^{1-y_i}]\\\end{align}</script><h2 id="参数求解"><a href="#参数求解" class="headerlink" title="参数求解"></a>参数求解</h2><p>将上式分为三个部分①+②+③，且有$N_1$个样本标签为1，有$N_2$个样本标签为0（$N_1+N_2=N$）</p><p>求$\phi$：</p><script type="math/tex; mode=display">③=\sum_{i=1}^{N}[y_i\log \phi+(1-y_i)\log(1-\phi)]\\\frac{\partial ③}{\partial \phi}=\sum_{i=1}^{N}[\frac{y_i}{\phi}-\frac{1-y_i}{1-\phi}]=0\\\phi=\frac{1}{N}\sum_{i=1}^{N}y_i=\frac{N_1}{N}</script><p>求$\mu_1$：</p><script type="math/tex; mode=display">\begin{align}①&=\sum_{i=1}^{N}\log N(\mu_1,\Sigma)^{y_i}\\&=\sum_{i=1}^{N}y_i\log\frac{1}{(2\pi)^\frac{p}{2}|\Sigma|^\frac{1}{2}}\exp[-\frac{1}{2}(x_i-\mu_1)^T\Sigma^{-1}(x_i-\mu_1)]\end{align}</script><p>去除与$\mu_1$无关的常数</p><script type="math/tex; mode=display">\hat{\mu}_1=\mathop{\arg\max}\limits_{\mu_1} ①=\mathop{\arg\max}\limits_{\mu_1}\sum_{i=1}^{N}y_i[-\frac{1}{2}(x_i-\mu_1)^T\Sigma^{-1}(x_i-\mu_1)]\\-\frac{1}{2}\sum_{i=1}^{N}y_i[(x_i-\mu_1)^T\Sigma^{-1}(x_i-\mu_1)]=-\frac{1}{2}\sum_{i=1}^{N}y_i[x_i^T\Sigma^{-1}x_i-2\mu_1^T\Sigma^{-1}x_i+\mu_1^T\Sigma^{-1}\mu_1=\bigtriangleup\\\frac{\partial \bigtriangleup}{\partial \mu_1}=\sum_{i=1}^{N}y_i(\Sigma^{-1}x_i-\Sigma^{-1}\mu_1)=0\\\hat{\mu}_1=\frac{\sum_{i=1}^{N}y_ix_i}{\sum_{i=1}^{N}y_i}=\frac{\sum_{i=1}^{N}y_ix_i}{N_1}</script><p>求$\Sigma$：</p><p>首先令</p><script type="math/tex; mode=display">C_1=\{x_i|y_i=1,i=1,…,N\}\\C_2=\{x_i|y_i=0,i=1,…,N\}\\|C_1|=N_1,|C_2|=N_2,N_1+N_2=N</script><p>则</p><script type="math/tex; mode=display">\hat{\Sigma}_1=\mathop{\arg\max}\limits_{\Sigma}(①+②)\\①+②=\sum_{x_i\in C_1}\log N(\mu_1,\Sigma)+\sum_{x_i\in C_2}\log N(\mu_2,\Sigma)\\\begin{align}\log N(\mu,\Sigma)&=\sum_{i=1}^{N}\log\frac{1}{(2\pi)^\frac{p}{2}|\Sigma|^\frac{1}{2}}\exp[-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)]\\&=\sum_{i=1}^{N}[\log\frac{1}{(2\pi)^\frac{p}{2}}+\log{|\Sigma|^\frac{1}{2}}-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)]\\&=\sum_{i=1}^{N}[C-\frac{1}{2}\log|\Sigma|-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)]\\&=C-\frac{N}{2}\log|\Sigma|-\frac{1}{2}\sum_{i=1}^{N}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)\\&=C-\frac{N}{2}\log|\Sigma|-\frac{1}{2}\sum_{i=1}^{N}tr[(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)]\\&=C-\frac{N}{2}\log|\Sigma|-\frac{1}{2}tr[\sum_{i=1}^{N}(x_i-\mu)(x_i-\mu)^T\Sigma^{-1}]\\&=C-\frac{N}{2}\log|\Sigma|-\frac{1}{2}Ntr(S\Sigma^{-1})\\\end{align}</script><p>其中$S=\frac{1}{N}\sum_{i=1}^{N}(x_i-\mu)(x_i-\mu)^T$为样本方差</p><p>则</p><script type="math/tex; mode=display">\begin{align}①+②&=-\frac{N_1}{2}\log|\Sigma|-\frac{1}{2}N_1tr(S_1\Sigma^{-1})-\frac{N_2}{2}\log|\Sigma|-\frac{1}{2}N_2tr(S_2\Sigma^{-1})+C\\&=-\frac{1}{2}[N\log|\Sigma|+N_1tr(S_1\Sigma^{-1})+N_2tr(S_2\Sigma^{-1})]+C\\\frac{\partial (①+②)}{\partial \Sigma}&=-\frac{1}{2}(N\Sigma^{-1}-N_1S_1\Sigma^{-2}-N_2S_2\Sigma^{-2})=0\\\end{align}</script><script type="math/tex; mode=display">N\Sigma-N_1S_1-N_2S_2=0\\ \Sigma=\frac{1}{N}(N_1S_1+N_2S_2)</script><p>其中用到求导$\frac{tr(\Sigma^{-1}S)}{\partial \Sigma}=S^T(-1)\Sigma^{-2}$</p><h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p>朴素贝叶斯假设：条件独立性假设</p><script type="math/tex; mode=display">x_i \perp x_j | y(i\neq j)\\P(x|y)=\prod_{j=1}^{p}P(x_j|y)</script><p>最简单的概率图（有向图）模型</p><p>动机：简化运算</p><script type="math/tex; mode=display">\hat{y}=\mathop{\arg\max}\limits_{y\in \{0,1\}} P(y|x)=\mathop{\arg\max}\limits_{y\in \{0,1\}} P(y)P(x|y)</script><p>若$x$离散，则认为$x_j$服从伯努利分布/多项分布</p><p>若$x$连续，则认为$x_j$服从正态分布$x_j\sim N(\mu_j,\sigma^2_j)$</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Notes </tag>
            
            <tag> MachineLearning </tag>
            
            <tag> Classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logistic Regression 逻辑回归算法及实现</title>
      <link href="/2020/02/02/logistic-regression-suan-fa-ji-qi-ying-yong/"/>
      <url>/2020/02/02/logistic-regression-suan-fa-ji-qi-ying-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><p>假设数据服从伯努利分布，通过极大化似然函数的方法，运用梯度下降来求解参数，来达到二分类的目的。</p><h2 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h2><p>逻辑回归是在线性回归的基础上，利用sigmoid函数（或称为logistic函数）</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>进行映射，代入线性回归部分</p><script type="math/tex; mode=display">z=\theta^Tx=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n</script><p>得到二元逻辑回归模型的一般形式：</p><script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}</script><p>得到的$h_\theta(x)$就是逻辑回归返回的值，介于0到1之间，可以将其当做样本取正类的“概率”。因此对于样本$x$分类结果为正类1和负类0的概率分别为</p><script type="math/tex; mode=display">\begin{cases}P(y=1|x;\theta)=h_\theta(x)\\P(y=0|x;\theta)=1-h_\theta(x)\end{cases}</script><p>对$h_\theta(x)$进行变换可以得到对数几率的表达式</p><script type="math/tex; mode=display">ln\frac{h_\theta(x)}{1-h_\theta(x)}=ln(\frac{\frac{1}{1+e^{-\theta^Tx}}}{1-\frac{1}{1+e^{-\theta^Tx}}})=ln(\frac{\frac{1}{1+e^{-\theta^Tx}}}{\frac{e^{-\theta^Tx}}{1+e^{-\theta^Tx}}})=ln(\frac{1}{e^{-\theta^Tx}})=ln(e^{\theta^Tx})=\theta^Tx</script><p>从上式可以看出，<strong>逻辑回归的本质是在对线性回归模型的预测去逼近真实标记的对数几率</strong>。求解的关注点在于求解参数$\theta$上，通常使用极大似然估计的方法对$\theta$进行估计。</p><p>令</p><script type="math/tex; mode=display">h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}</script><p>得到的似然函数为</p><script type="math/tex; mode=display">L(\theta)=\prod_{i=1}^{m}P(y^i|x^i;\theta)=\prod_{i=1}^{m}h_\theta(x^i)^{y^i}*(1-h_\theta(x^i))^{1-y^i}</script><p>其中，$x^i$为第$i$个样本的特征做构成的向量（每个向量$n+1$维，共$m$个向量），$y^i$为第$i$个样本的标签，$m$为样本量。实际中为了简化计算，同时防止连乘所造成的浮点数下溢，通常会转化为对数似然函数</p><script type="math/tex; mode=display">l(\theta)=\sum_{i=1}^{m}[y^ilog(h_\theta(x^i))+(1-y^i)log(1-h_\theta(x^i))]</script><p>逻辑回归所要解决的问题即为找到参数$\theta$，使得对数似然函数达到最大。</p><p>令损失函数为（忽略正则化项）</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}l(\theta)=-\frac{1}{m}\sum_{i=1}^{m}[y^ilog(h_\theta(x^i))+(1-y^i)log(1-h_\theta(x^i))]</script><p>利用梯度下降求解参数</p><script type="math/tex; mode=display">\begin{align}\frac{∂J(\theta)}{∂\theta_j}& =-\frac{1}{m}\sum_{i=1}^{m}[\frac{y^i}{h_\theta(x^i)}-\frac{1-y^i}{1-h_\theta(x^i)}]\frac{∂h_\theta(x^i)}{∂\theta_j}\\& =-\frac{1}{m}\sum_{i=1}^{m}[\frac{y^i}{g(\theta^Tx^i)}-\frac{1-y^i}{1-g(\theta^Tx^i)}]\frac{∂g(\theta^Tx^i)}{∂\theta_j}\\& =-\frac{1}{m}\sum_{i=1}^{m}[\frac{y^i}{g(\theta^Tx^i)}-\frac{1-y^i}{1-g(\theta^Tx^i)}]g(\theta^Tx^i)(1-g(\theta^Tx^i))\frac{∂\theta^Tx^i}{∂\theta_j}\\& =-\frac{1}{m}\sum_{i=1}^{m}[\frac{y^i}{g(\theta^Tx^i)}-\frac{1-y^i}{1-g(\theta^Tx^i)}]g(\theta^Tx^i)(1-g(\theta^Tx^i))x^i_j\\& =-\frac{1}{m}\sum_{i=1}^{m}[y^i(1-g(\theta^Tx^i))-(1-y^i)g(\theta^Tx^i)]x^i_j\\& =-\frac{1}{m}\sum_{i=1}^{m}[y^i-g(\theta^Tx^i)]x^i_j\\& =\frac{1}{m}\sum_{i=1}^{m}[h_\theta(x^i)-y^i]x^i_j\\\end{align}</script><p>因此最终得到参数迭代式</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\eta\frac{1}{m}\sum_{i=1}^{m}[h_\theta(x^i)-y^i]x^i_j</script><p>（参考：<a href="https://www.cnblogs.com/Luv-GEM/p/10674719.html" target="_blank" rel="noopener">Logistic回归（逻辑回归）和softmax回归</a>）</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p><strong>优点：</strong></p><ol><li><p>速度快，在时间和内存需求上相当高效，它可以应用于分布式数据和在线算法实现，用较少的资源处理大型数据</p></li><li><p>对线性分类问题拟合很好</p></li><li>简单易于理解，直接看到各个特征的权重</li></ol><p><strong>缺点：</strong></p><ol><li>分类精度可能不高，在非线性分类问题上表现不好</li><li>数据特征有缺失或者特征空间很大时表现效果并不好，受异常值影响大</li></ol><h2 id="与线性回归的异同"><a href="#与线性回归的异同" class="headerlink" title="与线性回归的异同"></a>与线性回归的异同</h2><p>本质是线性的，只是特征到结果映射用的是sigmoid函数，属于广义线性模型（GLM）</p><ul><li><p>相同</p><ol><li><p>都使用极大似然估计对训练样本进行建模；求解超参数时都可以使用梯度下降。</p></li><li><p>都是广义线性模型，逻辑回归本质上是一个线性回归模型，LR是以线性回归为理论支持的。</p></li></ol></li><li><p>不同</p><ol><li>本质：逻辑回归是分类，线性回归是回归，逻辑回归中$y$是因变量而非$\frac{p}{1-p}$，因变量是离散而非连续</li><li>LR形式上是线性回归，实质上是在求取输入空间到输出空间的非线性函数映射（对率函数起到将线性回归模型的预测值与真实标记联系起来的作用）</li><li>LR是直接对分类可能性进行建模，无需事先假设数据分布，而线性回归需要假设数据分布</li></ol></li></ul><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p><strong>损失函数是它的极大似然函数取对数再除以样本量的相反数</strong></p><p>极大似然函数：</p><script type="math/tex; mode=display">L_\theta(x)=\prod_{i=1}^{m}h_\theta(x^i;\theta)^{y^i}*(1-h_\theta(x^i;\theta))^{1-y^i}</script><p>损失函数：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}[y^ilog(h_\theta(x^i;\theta))+(1-y^i)log(1-h_\theta(x^i;\theta))]</script><p>除以样本量$m$并不改变最终求导极值结果，通过除以$m$可以得到<strong>平均损失值</strong>，避免<strong>样本数量对于损失值的影响</strong></p><p>（但是也有不除以样本量的，比如sklearn中的损失函数就不除以样本量）</p><p>（乘上样本量的倒数也并不影响梯度下降的过程┓( ´∀` )┏ ）</p><blockquote><p><strong>Q：为什么要用极大似然函数作为损失函数？</strong></p><p>损失函数一般有四种：平方损失函数，对数损失函数，HingeLoss损失函数，绝对值损失函数。</p><p>将极大似然函数取对数以后等同于对数损失函数。</p><p><strong>在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。</strong></p><p>梯度更新公式：</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\eta\frac{1}{m}\sum_{i=1}^{m}[h_\theta(x^i)-y^i]x^i_j</script><p>这个式子的更新速度只和$x^i_j$和$y^i$相关，和sigmoid函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。 </p><p><strong>Q：为什么不选平方损失函数？</strong></p><p>其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmoid函数本身的梯度是很相关的。</p><script type="math/tex; mode=display">θ_j=θ_j-2(sigmoid(x)*(1-sigmoid(x)))x^i_j</script><p>sigmoid函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。</p><p>实际上也可以用最小二乘，但是最小二乘得到的权重效果比较差。</p><p>如果用最小二乘法，目标函数就是差值的平方和，<strong>是非凸的，不容易求解，很容易陷入到局部最优</strong>。</p><p>如果用极大似然估计，目标函数就是对数似然函数，是关于$(w,b)$的高阶<strong>连续可导凸函数</strong>，可以方便通过一些凸优化算法求解，比如梯度下降法、牛顿法等。</p></blockquote><h2 id="参数求解方法"><a href="#参数求解方法" class="headerlink" title="参数求解方法"></a>参数求解方法</h2><ul><li>梯度下降法</li></ul><p>由于该极大似然函数无法直接求解，我们一般通过对该函数进行<strong>梯度下降</strong>来不断逼近最优解。</p><blockquote><p>梯度下降：随机梯度下降，批梯度下降，small-batch梯度下降</p><p>Q：三种方式的优劣以及如何选择最合适的梯度下降方式</p><ol><li><p>批梯度下降(BGD)：每次迭代使用所有样本来进行梯度的更新，能得到全局最优解。缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。</p></li><li><p>随机梯度下降(SGD)：每次迭代随机使用一个样本来对参数进行更新，优点是每一轮参数的更新速度大大加快，缺点是准确度下降，可能会收敛到局部最优（单个样本不能代表全体样本的趋势）。</p></li><li><p>小批量梯度下降：结合了BGD和SGD的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。</p></li></ol></blockquote><ul><li><p>牛顿法</p><p>(待更新)</p></li><li><p>拟牛顿法</p><p>(待更新)</p></li></ul><blockquote><p>牛顿法与梯度下降法求解参数的区别：</p><p>两种方法不同在于牛顿法中<strong>多了一项二阶导数</strong>，这项二阶导数对参数更新的影响主要体现在<strong>改变参数更新方向上</strong>。如下图所示，红色是牛顿法参数更新的方向，绿色为梯度下降法参数更新方向，因为牛顿法考虑了二阶导数，因而可以<strong>找到更优的参数更新方向</strong>，在每次更新的步幅相同的情况下，可以<strong>比梯度下降法节省很多的迭代次数</strong>。</p><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200130/zdow4EB72J3r.png" alt="mark"></p></blockquote><h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>作用：需要一个单调可微的函数，把分类任务的真实标记与线性回归模型的预测值联系起来。</p><p>对于二分类问题，由线性回归得来的启发是根据特征的加权平均进行预测。很自然地想到设定一个阈值，如果加权平均大于该阈值就判为正类，反之判为负类。但<strong>阶跃函数不可导</strong>，所以<strong>引入Sigmoid函数，将样本的加权平均代入函数得到的值就是样本属于正类的概率，即将输入空间到输出空间作非线性函数映射</strong>。</p><p>Sigmoid函数形式：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>Sigmoid函数是一个S型的函数，函数图像：</p><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200130/hMNRkXsKheJ9.png" alt="mark" style="zoom:67%;"></p><p>当自变量z趋近正无穷时，因变量g(z)趋近于1，而当z趋近负无穷时，g(z)趋近于0。</p><p>它能够<strong>将任何实数映射到(0,1)区间</strong>（开区间，不可等于0或1），使其可用于将任意值函数转换为更适合二分类的函数。 </p><p>因为这个性质，Sigmoid函数也被当作是归一化的一种方法，与MinMaxSclaer同理，是属于数据预处理中的“缩放”功能，可以将数据压缩到[0,1]之内。</p><p>区别在于，MinMaxScaler归一化之后，是可以取到0和1的（最大值归一化后就是1，最小值归一化后就是0），但<strong>Sigmoid函数只是无限趋近于0和1</strong>。</p><h2 id="共线性问题"><a href="#共线性问题" class="headerlink" title="共线性问题"></a>共线性问题</h2><p>对模型中自变量多重共线性较为敏感，例如两个高度相关自变量同时放入模型，可能导致较弱的一个自变量回归符号不符合预期，符号被扭转。</p><p>通常做法为：将所有回归中要用到的变量依次作为因变量、其他变量作为自变量进行回归分析，可以得到各个变量的膨胀系数VIF， VIF越大共线性越严重，通常VIF小于5可以认为共线性不严重，宽泛一点的标准小于10即可。</p><h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><ol><li><p>多项逻辑回归(Softmax Regression)</p><p>（二分类逻辑回归在多标签分类下的一种拓展）</p><p><img src="http://q4ws08qse.bkt.clouddn.com/blog/20200130/4HnDRP6ijvH6.png" alt="mark"></p></li><li><p>one v.s. rest</p><p>k个二分类LR分类器，把标签重新整理为“第i类标签”与“非第i类标签”</p></li></ol><h1 id="单机python实现"><a href="#单机python实现" class="headerlink" title="单机python实现"></a>单机python实现</h1><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression</a> </p><blockquote><p><em>class</em> <code>sklearn.linear_model.LogisticRegression</code>(<em>penalty=’l2’</em>, <em>dual=False</em>, <em>tol=0.0001</em>, <em>C=1.0</em>, <em>fit_intercept=True</em>, <em>intercept_scaling=1</em>, <em>class_weight=None</em>, <em>random_state=None</em>, <em>solver=’lbfgs’</em>, <em>max_iter=100</em>, <em>multi_class=’auto’</em>, <em>verbose=0</em>, <em>warm_start=False</em>, <em>n_jobs=None</em>, <em>l1_ratio=None</em>) </p></blockquote><h2 id="参数列表"><a href="#参数列表" class="headerlink" title="参数列表"></a>参数列表</h2><h3 id="1-基本模型参数"><a href="#1-基本模型参数" class="headerlink" title="1. 基本模型参数"></a>1. 基本模型参数</h3><ul><li><p><strong>fit_intercept</strong>：bool，指定是否将截距项添加到线性回归部分中。默认True。</p></li><li><p><strong>intercept_scaling</strong>：float，默认1。仅在solver=’liblinear’且fit_intercept=True时有用。 在这种情况下原本的向量是[x]就变成[x,intercept_scaling]，即具有等于设定的intercept_scaling值的“合成”特征会被添加到实例矢量。截距会变为intercept_scaling * synthetic_feature_weight(合成特征权重)。synthetic_feature_weight会与其他特征经历l1和l2正则化，为减小正则化对synthetic_feature_weight（并因此对截距）的影响，必须增加intercept_scaling。</p><blockquote><p>因为本身截距项是不需要进行正则化的，当采用fit_intcept时相当于人造一个特征出来，特征恒为1，权重为b。在计算正则化项的时候，该人造特征也被考虑了，因此为了降低这个人造特征的影响，需要提供intercept_scaling。 (O_o)??</p></blockquote></li><li><p><strong>multi_class</strong>：str，’auto’（默认）/‘ovr’/‘multinomial’，表示要预测的分类是二分类或一对多形式的多分类问题，还是多对多形式的多分类问题。</p><ul><li><p><strong>‘auto’</strong>：表示自动选择，会根据数据的分类情况和其他参数确定模型要处理的分类问题的类型。</p><blockquote><p>根据源码得到判定方法如下：</p><p>step 1：if solver = ‘liblinear’: multi_class = ‘ovr’</p><p>step 2：elif n_classes &gt; 2: multi_class = ‘multinomial’</p><p>step 3：else: multi_class = ‘ovr’</p></blockquote></li><li><p><strong>‘ovr’</strong>：表示当前处理的是二分类或一对多形式的多分类问题</p></li><li><p><strong>‘multinomial’</strong>：表示当前处理的是多对多形式的多分类问题</p></li></ul></li><li><p><strong>class_weight</strong>：None（默认）/‘balanced’/dict，标签(label)的权重。</p><ul><li><p><strong>None</strong>：所有的label持有相同的权重， 所有类别的权值为1 </p></li><li><p><strong>‘balanced’</strong>：自动调整与样本中类频率成反比的权重，即<code>n_samples/(n_classes*np.bincount(y))</code></p><blockquote><p><strong>‘balanced’如何计算class_weight？</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_class_weight </span><br><span class="line"></span><br><span class="line">y = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>]  <span class="comment"># 标签值，一共16个样本</span></span><br><span class="line">np.bincount(y)</span><br><span class="line"><span class="comment"># array([8, 6, 2], dtype=int64) 计算每个类别的样本数量，顺序按类别的出现次序</span></span><br><span class="line">class_weight = <span class="string">'balanced'</span></span><br><span class="line">classes = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])  <span class="comment">#标签类别</span></span><br><span class="line">weight = compute_class_weight(class_weight, classes, y)</span><br><span class="line">print(weight) <span class="comment"># [0.66666667 0.88888889 2.66666667]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">print(<span class="number">16</span>/(<span class="number">3</span>*<span class="number">8</span>))  <span class="comment">#输出 0.6666666666666666</span></span><br><span class="line">print(<span class="number">16</span>/(<span class="number">3</span>*<span class="number">6</span>))  <span class="comment">#输出 0.8888888888888888</span></span><br><span class="line">print(<span class="number">16</span>/(<span class="number">3</span>*<span class="number">2</span>))  <span class="comment">#输出 2.6666666666666665</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p><strong>dict类型</strong></p><p>对于二分类问题，可定义class_weight = {0:0.9, 1:0.1}，这样类别0的权重为0.9，类别1的权重为0.1。</p><p>对于多分类问题，定义的权重必须具体到每个标签下的每个类，其中类是key-value中的key，权重是value。</p><blockquote><p><strong>dict类型如何计算class_weight？</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_class_weight </span><br><span class="line">  </span><br><span class="line">y = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>]  <span class="comment">#标签值，一共16个样本</span></span><br><span class="line"></span><br><span class="line">class_weight = &#123;<span class="number">0</span>:<span class="number">1</span>,<span class="number">1</span>:<span class="number">3</span>,<span class="number">2</span>:<span class="number">5</span>&#125;   <span class="comment"># 设置</span></span><br><span class="line">classes = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])  <span class="comment">#标签类别</span></span><br><span class="line">weight = compute_class_weight(class_weight, classes, y)</span><br><span class="line">print(weight)   <span class="comment"># 输出：[1. 3. 5.]，也就是字典中设置的值</span></span><br></pre></td></tr></table></figure></li></ul><blockquote><p><strong>class_weight如何体现在逻辑回归的损失函数上？</strong></p></blockquote><p>  class_weight给每个类别分别设置不同的<strong>惩罚参数C</strong>。</p><p>  惩罚项C会相应的放大或者缩小某一类的损失，如果某一类C越大，这一类的损失也被（相对于其他类来说）放大，那么系统会把本次学习重点放在这一类上，使得系统尽可能的预测对这一类的输入，所以惩罚项C不会影响计算的损失，但反向学习时会相应的放大或缩小损失，间接影响学习的方向。</p><p>  (参考：<a href="https://www.zhihu.com/question/265420166/answer/293896934" target="_blank" rel="noopener">https://www.zhihu.com/question/265420166/answer/293896934</a>)</p><blockquote><p><strong>源码关于class_weight与sample_weight在LR损失函数上的具体计算方式？</strong></p></blockquote>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sample_weight *= class_weight_[le.fit_transform(y_bin)] </span><br><span class="line"><span class="comment"># 将class_weight乘到每个样本的sample_weight上</span></span><br><span class="line"><span class="comment"># sample_weight : shape (n_samples,)</span></span><br><span class="line"><span class="comment"># le即LabelEncoder，将标签标准化为0/1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Logistic loss is the negative of the log of the logistic function</span></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">out = -np.sum(sample_weight * log_logistic(yz)) + <span class="number">.5</span> * alpha * np.dot(w, w)</span><br></pre></td></tr></table></figure><h3 id="2-求解算法参数"><a href="#2-求解算法参数" class="headerlink" title="2. 求解算法参数"></a>2. 求解算法参数</h3><ul><li><p><strong>solver</strong>：str，用于求解模型最优化问题的算法，可选{‘newton-cg’,’lbfgs’,’liblinear’,’sag’,’saga’}，默认’lbfgs’。</p><ul><li><strong>‘liblinear’</strong>：使用坐标轴下降法来迭代优化损失函数。</li><li><strong>‘lbfgs’</strong>：拟牛顿法的一种，利用损失函数二阶导数矩阵（即海森矩阵）来迭代优化损失函数。</li><li><strong>‘newton-cg’</strong>：牛顿法的一种，利用损失函数二阶导数矩阵（即海森矩阵）来迭代优化损失函数。？</li><li><strong>‘sag’</strong>：随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅用一部分的样本来计算梯度，适用于样本量大的情况。</li><li><strong>‘saga’</strong>：线性收敛的随机优化算法的变种。</li></ul><blockquote><ul><li><p>对于数据量大小方面，’liblinear’仅限于处理二分类和一对多（OvR）问题，适用于小型数据集。’sag’和’saga’对于大型数据集来说更快（快速收敛仅在量纲大致相同的数据上得到保证），’sag’每次仅使用了部分样本进行梯度迭代，样本量少时不适合。</p></li><li><p>对于多分类问题来说，’liblinear’只能用于一对多（OvR），其它算法还可处理多对多（MvM），而多对多一般比一对多分类相对更准确一些。</p></li><li><p>对于正则化方法来说，’newton-cg’,’sag’,’lbfgs’这三种算法计算时都需要涉及到损失函数的一阶导或二阶导，因此不能用于没有连续导数的l1正则化，只能用于l2正则化。其他两种算法均可使用l1和l2正则化。</p></li></ul></blockquote><p>（这部分还不是很了解……待补充）</p></li><li><p><strong>dual</strong>：bool，是否使用对偶或原始计算方式。对偶方式仅在solver=’liblinear’与penalty=’l2’连用的情况下有小。如果样本量大于特征的数目，这个参数设置为False会更好。（逻辑回归的对偶形式是什么？……待补充）</p></li></ul><h3 id="3-正则化参数"><a href="#3-正则化参数" class="headerlink" title="3. 正则化参数"></a>3. 正则化参数</h3><p>损失函数</p><script type="math/tex; mode=display">\min_{w, c} \frac{1 - \rho}{2}w^T w + \rho \|w\|_1 + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1)</script><p>其中$C$为正则化参数（$\lambda\ge0$)，$\alpha$为l1正则化的占比（$\alpha\in[0,1]$）。</p><blockquote><p>这里用的是<a href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression" target="_blank" rel="noopener">sklearn官网</a>给出的损失函数形式， sklearn中假设y正负label定义为1和-1，与之前1/0不一样</p><p>损失函数除去正则化和求和部分剩余部分为：$\log(\exp(- y_i (X_i^T w + c)) + 1)$</p><p>当$y_i=+1$时，$\log(\exp(- y_i (X_i^T w + c)) + 1)=\log(\exp(- (X_i^T w + c)) + 1)$</p><p>当$y_i=-1$时，$\log(\exp(- y_i (X_i^T w + c)) + 1)=\log(\exp((X_i^T w + c)) + 1)$</p><p>上式难以继续化简，因此对比之前的损失函数形式，观测结果是否一致</p><p>之前的表达式对应的部分为$-[y^i\log(h_\theta(x^i;\theta))+(1-y^i)\log(1-h_\theta(x^i;\theta))]$</p><p>当$y_i=1$时，$-y^i\log(h_\theta(x^i;\theta))=-\log(\frac{1}{1+\exp(-(X_i^T w + c))})=\log(\exp(-(X_i^T w + c))+1)$</p><p>当$y_i=0$时，$-(1-y^i)\log(1-h_\theta(x^i;\theta))=-\log(1-\frac{1}{\exp(-(X_i^T w + c))+1})=\log(\exp((X_i^T w + c)) + 1)$</p><p>从而证明这两种表达形式是等价的。</p><p>（注意sklearn损失函数里没有除以样本量）</p></blockquote><ul><li><strong>penalty</strong>：str，指定正则化策略 ， {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}，默认’l2’。’elasticnet’同时包含‘l1’和‘l2’正则化。</li><li><strong>C</strong>：float，正则化系数$\lambda$的倒数（乘在损失函数的前面，与乘在正则化部分前效果相同，均用来平衡两个部分的比重），必须是一个大于0的浮点数，默认值1.0，即默认正则项与损失函数的比值是1:1。</li><li><strong>l1_ratio</strong>：float，l1正则化的占比$\rho$，取值范围[0,1]，默认为None。仅当penalty=’elasticnet’时使用，对于0&lt; l1_ratio &lt;1，惩罚是l1和l2正则化的组合。</li></ul><h3 id="4-控制迭代次数参数"><a href="#4-控制迭代次数参数" class="headerlink" title="4. 控制迭代次数参数"></a>4. 控制迭代次数参数</h3><ul><li><strong>max_iter</strong>：int，控制梯度下降的迭代次数（仅适用于solver=’newton-cg’, ‘lbfgs’, ‘sag’）。默认值为100。值过小损失函数可能会没有收敛到最小值，值过大会使得梯度下降迭代次数过多，模型运行时间缓慢。</li><li><strong>tol</strong>：float，让迭代停下的最小值。默认1e-4。数字越大迭代越早停下。</li></ul><h3 id="5-其他参数"><a href="#5-其他参数" class="headerlink" title="5. 其他参数"></a>5. 其他参数</h3><ul><li><strong>random_state</strong>：int(可选)，随机数种子，可选参数（仅适用于solver=’liblinear’, ‘sag’）。默认为无。</li><li><strong>verbose</strong>：int，日志冗长度。对于solver=’liblinear’, ‘lbfgs’，当设置为大于等于1的任何整数时，输出训练的详细过程 。默认为0，不输出训练过程。</li><li><strong>warm_start</strong>：bool，是否进行热启动，默认为False。若设置为True，则以上一次fit的结果作为此次的初始化，如果”solver”参数为”liblinear”时无效。 </li><li><strong>n_jobs</strong>：int，并行数。int类型，默认为1。等于1时用CPU的一个内核运行程序，等于-1时用所有CPU的内核运行程序。 </li></ul><h2 id="属性列表"><a href="#属性列表" class="headerlink" title="属性列表"></a>属性列表</h2><ul><li><strong>coef_</strong>：预测函数中特征对应的系数$w$。</li><li><strong>intercept_</strong>：预测函数中的截距$c$。</li><li><strong>n_iter_</strong>：实际迭代次数。</li></ul><h2 id="接口列表"><a href="#接口列表" class="headerlink" title="接口列表"></a>接口列表</h2><ul><li><strong>fit(x,y[,sample_weight])</strong>：训练模型。</li><li><strong>predict(x)</strong>：用模型进行训练，返回预测值。</li><li><strong>predict_log_proba(x)</strong>：返回一个数组，数组的元素依次是x预测为各个类别的概率的对数值。</li><li><strong>predict_proba(x)</strong>：返回一个数组，数组的元素依次是x预测为各个类别的概率值。</li><li><strong>score(x,y[,sample_weight])</strong>：返回在(x,y)上预测的准确率。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">X, y = load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">clf = LogisticRegression(random_state=<span class="number">0</span>).fit(X, y)</span><br><span class="line">clf.predict(X[:<span class="number">2</span>, :]) <span class="comment"># 预测前两个样本的类别</span></span><br><span class="line">clf.predict_proba(X[:<span class="number">2</span>, :]) <span class="comment"># 预测前两个样本属于各个类的概率</span></span><br><span class="line">clf.score(X, y) <span class="comment"># 返回准确率</span></span><br><span class="line"></span><br><span class="line">clf.coef_ <span class="comment"># 系数</span></span><br><span class="line">clf.intercept_ <span class="comment"># 截距</span></span><br><span class="line">clf.n_iter_ <span class="comment"># 迭代次数</span></span><br></pre></td></tr></table></figure><h1 id="集群pyspark实现"><a href="#集群pyspark实现" class="headerlink" title="集群pyspark实现"></a>集群pyspark实现</h1><p><a href="http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression</a> </p><p><em>class</em> <code>pyspark.ml.classification.LogisticRegression</code>(<em>featuresCol=’features’</em>, <em>labelCol=’label’</em>, <em>predictionCol=’prediction’</em>, <em>maxIter=100</em>, <em>regParam=0.0</em>, <em>elasticNetParam=0.0</em>, <em>tol=1e-06</em>, <em>fitIntercept=True</em>, <em>threshold=0.5</em>, <em>thresholds=None</em>, <em>probabilityCol=’probability’</em>, <em>rawPredictionCol=’rawPrediction’</em>, <em>standardization=True</em>, <em>weightCol=None</em>, <em>aggregationDepth=2</em>, <em>family=’auto’</em>, <em>lowerBoundsOnCoefficients=None</em>, <em>upperBoundsOnCoefficients=None</em>, <em>lowerBoundsOnIntercepts=None</em>, <em>upperBoundsOnIntercepts=None</em>) </p><h2 id="参数列表-1"><a href="#参数列表-1" class="headerlink" title="参数列表"></a>参数列表</h2><h3 id="1-基本模型参数-1"><a href="#1-基本模型参数-1" class="headerlink" title="1. 基本模型参数"></a>1. 基本模型参数</h3><ul><li><p><strong>fitIntercept</strong>：bool，是否包含截距项，默认True。</p></li><li><p><strong>family</strong>：str，表示分类是二分类还是多分类，默认’auto’，还可选’binomial’和’multinomial’。</p><blockquote><p>spark中处理多分类问题的’multinomial’使用的是<strong>softmax回归</strong></p><p>(参考：<a href="https://blog.csdn.net/u013855234/article/details/84343963" target="_blank" rel="noopener">spark 2.x 源码分析 之 Logistic Regression 逻辑回归</a>)</p><p>在多分类问题中，假设有$C$个类，即类别标签$y\in\{1,2,…,C\}$，则给定一个样本$x$，softmax回归预测样本$x$属于类别$c$的后验概率为</p><script type="math/tex; mode=display">P(y=c|x;\theta)=\frac{\exp(\theta^T_cx)}{\sum_{c=1}^{C}\exp(\theta^T_cx)}</script><p>其中$\theta^T_c$是第$c$类的权重向量，则样本$x$属于每个类别的概率可以由向量表示，向量的第$c$个元素就是样本被预测为第$c$类的概率。</p></blockquote></li><li><p><strong>threshold</strong>：float，分类中的阈值，默认为0.5。</p></li><li><p><strong>thresholds</strong>：list，分类中的阈值，默认为0.5。多元分类中的thresholds是为了调整预测每个类别时的概率。数组长度必须和类别数目相等，且值都大于0。若thresholds长度为2（即对于二分类问题），要满足<code>threshold = 1/(1+threholds[0]/threholds[1])</code></p><blockquote><p>这两个阈值看上去很迷惑，因此直接进行测试……</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二分类的情况</span></span><br><span class="line">lr = LogisticRegression().setFamily(<span class="string">"binomial"</span>).setThreshold(<span class="number">0.8</span>).setThresholds([<span class="number">1</span>,<span class="number">6</span>])</span><br><span class="line"><span class="comment"># 会认为Thresholds = [1,6], Threshold = 0.8</span></span><br><span class="line"><span class="comment"># 报错，因为不满足threshold = 1/(1+threholds[0]/threholds[1])</span></span><br><span class="line"></span><br><span class="line">lr = LogisticRegression().setFamily(<span class="string">"binomial"</span>).setThresholds([<span class="number">1</span>,<span class="number">6</span>]).setThreshold(<span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># 会认为Threshold = 0.8, 忽略Thresholds(被覆盖，之前定义无效)</span></span><br><span class="line"><span class="comment"># 不报错，将超过0.8的类概率预测为该类</span></span><br></pre></td></tr></table></figure><p>对于多分类的情况比较简单，无论thresholds和threshold如何设定，仍会按照概率最高类进行预测（迷惑行为）</p><p>（参考：<a href="https://stackoverflow.com/questions/47325607/set-thresholds-in-pyspark-multinomial-logistic-regression" target="_blank" rel="noopener">Set thresholds in PySpark multinomial logistic regression</a>）</p></li><li><p><strong>standardization</strong>：bool，是否在训练模型之前对特征进行标准化，默认True。</p><blockquote><p>这里体现出spark与python的不同，spark会默认对特征进行标准化。</p><p>但如果设置<code>standardization = False</code>，仍会将数据进行标准化以提高收敛速度（又一迷惑行为），从而获得相同效果的目标函数。</p><p>这里的标准化是直接除以变量的标准差，没有减去均值的部分。</p></blockquote><p><a href="https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/classification/LogisticRegression.scala#L683" target="_blank" rel="noopener">源码标准化部分</a></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> standardizationParam = $(standardization)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regParamL1Fun</span> </span>= (index: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">  <span class="comment">// Remove the L1 penalization on the intercept</span></span><br><span class="line">  <span class="keyword">val</span> isIntercept = $(fitIntercept) &amp;&amp; index &gt;= numFeatures * numCoefficientSets</span><br><span class="line">  <span class="keyword">if</span> (isIntercept) &#123;</span><br><span class="line">    <span class="number">0.0</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (standardizationParam) &#123;</span><br><span class="line">      regParamL1</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> featureIndex = index / numCoefficientSets</span><br><span class="line">      <span class="comment">// If `standardization` is false, we still standardize the data</span></span><br><span class="line">      <span class="comment">// to improve the rate of convergence; as a result, we have to</span></span><br><span class="line">      <span class="comment">// perform this reverse standardization by penalizing each component</span></span><br><span class="line">      <span class="comment">// differently to get effectively the same objective function when</span></span><br><span class="line">      <span class="comment">// the training dataset is not standardized.</span></span><br><span class="line">      <span class="keyword">if</span> (featuresStd(featureIndex) != <span class="number">0.0</span>) &#123;</span><br><span class="line">        regParamL1 / featuresStd(featureIndex)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>aggregationDepth</strong>：int，树聚合所建议的深度，默认为2</p></li><li><p><strong>lowerBoundsOnCoefficients(upperBoundsOnCoefficients)</strong>：？</p></li><li><p><strong>lowerBoundsOnIntercepts(upperBoundsOnIntercepts)</strong>：？</p></li></ul><h3 id="2-正则化参数"><a href="#2-正则化参数" class="headerlink" title="2. 正则化参数"></a>2. 正则化参数</h3><p>正则化部分</p><script type="math/tex; mode=display">\lambda[\frac{1 - \rho}{2}w^T w + \rho \|w\|_1], \rho\in[0,1], \lambda\ge0</script><p>其中$\lambda$为regParam，$\rho$为elasticNetParam。</p><ul><li><p><strong>regParam</strong>：float，正则化参数，默认0.0，即不进行正则化。</p></li><li><p><strong>elasticNetParam</strong>：float，正则化范式比，即l1正则化的占比。默认0.0，即只使用l2正则化。</p><blockquote><p>与sklearn的正则化参数$C$不同，这里的$\lambda$是乘在正则化部分，而$C$乘在损失部分</p><p>仅表达方式不同，改变了参数的位置</p><p>以l2正则为例</p><script type="math/tex; mode=display">J(\theta)+\lambda L_2 \Longleftrightarrow CJ(\theta)+L_2</script><p>$\lambda$越大$C$越小，正则项的地位越高，优化时集中优化$L_2$，从而使参数$\theta$中的元素尽量小</p></blockquote></li></ul><h3 id="3-控制迭代次数参数"><a href="#3-控制迭代次数参数" class="headerlink" title="3. 控制迭代次数参数"></a>3. 控制迭代次数参数</h3><ul><li><strong>maxIter</strong>：int，最大迭代次数，默认100。（与sklearn完全一致）</li><li><strong>tol</strong>：float，让迭代停下的最小值，数字越大迭代越早停下，默认1e-6。（sklearn默认1e-4)</li></ul><h3 id="4-设定列名参数"><a href="#4-设定列名参数" class="headerlink" title="4. 设定列名参数"></a>4. 设定列名参数</h3><p>这部分参数仅用于指定列名和设置输出的列名</p><ul><li><p><strong>featuresCol</strong>：str，输入的数据集中的特征列名（一个合并后的列名），默认’features’</p><blockquote><p>spark输入到模型训练的数据需要把多列的特征合并成一列（测试集也一样）</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"></span><br><span class="line">model_train_df = model_train.rdd.map(<span class="keyword">lambda</span> x:(Vectors.dense(x[<span class="number">0</span>:<span class="number">-1</span>], x[<span class="number">-1</span>])).toDF([<span class="string">'features'</span>,<span class="string">'label'</span>]))</span><br><span class="line">model_test_df = model_test.rdd.map(<span class="keyword">lambda</span> x:(Vectors.dense(x[<span class="number">0</span>:<span class="number">-1</span>], x[<span class="number">-1</span>])).toDF([<span class="string">'features'</span>,<span class="string">'label'</span>]))</span><br><span class="line"><span class="comment"># 这里标签列均在最后一列</span></span><br><span class="line"><span class="comment"># 然后就可以在训练模型时令参数featuresCol = 'features'（也可以不用设定，默认值即为'features'）</span></span><br></pre></td></tr></table></figure></li><li><p><strong>labelCol</strong>：str，输入的数据集中的标签列名（同featuresCol），默认’label’</p></li><li><p><strong>predictionCol</strong>：str，输出的模型预测结果中样本预测类的列名，默认’prediction’</p></li><li><p><strong>rawPredictionCol</strong>：str，输出的模型预测结果中原始概率的列名，默认’rawPrediction’</p></li><li><p><strong>probabilityCol</strong>：str，输出的模型预测结果中最终预测概率的列名，默认’probability’</p></li><li><p><strong>weightCol</strong>：str，样本权重列名，默认None，即所有样本的权重均视为等权重。</p></li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression, LogisticRegressionModel</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> BinaryClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入鸢尾花数据集</span></span><br><span class="line">df = sql(<span class="string">"select * from test.sklearn_dataset_iris"</span>)</span><br><span class="line"><span class="comment"># 转换为features和label两列的形式</span></span><br><span class="line">model_df = df.rdd.map(<span class="keyword">lambda</span> x:(Vectors.dense(x[<span class="number">0</span>:<span class="number">-1</span>], x[<span class="number">-1</span>])).toDF([<span class="string">'features'</span>,<span class="string">'label'</span>])</span><br><span class="line"><span class="comment"># 划分训练集、测试集</span></span><br><span class="line">train, test = model_df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], seed = <span class="number">123</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lrModel = lr.fit(train)</span><br><span class="line"><span class="comment"># 查看模型系数和截距</span></span><br><span class="line">pd.DataFrame(&#123;<span class="string">'coefficient'</span>:list(lrModel.coefficientMatrix.toArray()[<span class="number">0</span>])&#125;, index = df.columns[:<span class="number">-1</span>]).sort_values(by = <span class="string">'coefficient'</span>, ascending = <span class="literal">False</span>)</span><br><span class="line">lrModel.interceptVector</span><br><span class="line"><span class="comment"># 在测试集上预测</span></span><br><span class="line">lr_test = lrModel.transform(test)</span><br><span class="line"><span class="comment"># 模型评价</span></span><br><span class="line">evaluator = BinaryClassificationEvaluator()</span><br><span class="line">print(evaluator.evaluate(lr_test, &#123;evaluator.matricName: <span class="string">'areaUnderROC'</span>&#125;))</span><br></pre></td></tr></table></figure><p>模型输出结果（仅取前两行为例）</p><div class="table-container"><table><thead><tr><th>features</th><th>label</th><th>rawPrediction</th><th>probability</th><th>prediction</th></tr></thead><tbody><tr><td>[4.9,3.1,1.5,0.1]</td><td>0</td><td>[60.297,-7.393,-52.905]</td><td>[1,0,0]</td><td>0</td></tr><tr><td>[5.0,3.2,1.2,0.2]</td><td>0</td><td>[64.815,-8.896,-55.919]</td><td>[1,0,0]</td><td>0</td></tr></tbody></table></div><p>该模型为多分类情况，其中rawPrediction为线性回归模型输出结果，probability为经过softmax过后得到的逻辑回归结果。具体来说，以第一行为例，根据rawPrediction输出probability，并以最大值对应的类作为最终预测的类</p><script type="math/tex; mode=display">\frac{e^{60.297}}{e^{60.297}+e^{-7.393}+e^{-52.905}}\approx 1\\\frac{e^{60.297}}{e^{60.297}+e^{-7.393}+e^{-52.905}}\approx 0\\\frac{e^{60.297}}{e^{60.297}+e^{-7.393}+e^{-52.905}}\approx 0</script><h1 id="集群scala实现"><a href="#集群scala实现" class="headerlink" title="集群scala实现"></a>集群scala实现</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkContext</span>, <span class="type">SparkConf</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">LogisticRegression</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.param.<span class="type">ParamMap</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Vector</span>, <span class="type">Vectors</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.hive.<span class="type">HiveContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.<span class="type">VectorAssembler</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.evaluation.<span class="type">BinaryClassificationEvaluator</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// basic variable settings</span></span><br><span class="line"><span class="keyword">val</span> train_tbl = <span class="string">"test.sklearn_dataset_iris_train"</span></span><br><span class="line"><span class="keyword">val</span> test_tbl = <span class="string">"test.sklearn_dataset_iris_test"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> hc = <span class="keyword">new</span> <span class="type">HiveContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="comment">//data processing</span></span><br><span class="line"><span class="keyword">val</span> train_dataset = (hc.sql(<span class="string">s"select * from <span class="subst">$train_tbl</span>"</span>).cache())</span><br><span class="line"><span class="keyword">val</span> test_dataset = (hc.sql(<span class="string">s"select * from <span class="subst">$test_tbl</span>"</span>).cache())</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> featureCols = train_dataset.columns.filter(x=&gt;x.split(<span class="string">"_"</span>)(x.split(<span class="string">"_"</span>).length<span class="number">-1</span>)!=<span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> assembler = (<span class="keyword">new</span> <span class="type">VectorAssembler</span>().setInputCols(featureCols).setOutputCol(<span class="string">"features"</span>))</span><br><span class="line"><span class="keyword">val</span> train_data = assembler.transform(train_dataset)</span><br><span class="line"><span class="keyword">val</span> test_data = assembler.transform(test_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment">// model</span></span><br><span class="line"><span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line">lr.setMaxIter(<span class="number">10</span>).setRegParam(<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">val</span> lr_model = lr.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment">// model evaluation</span></span><br><span class="line"><span class="keyword">val</span> auc_calculator = lr_model.transform(test_data)</span><br><span class="line"><span class="keyword">val</span> evaluator = (<span class="keyword">new</span> <span class="type">BinaryClassificationEvaluator</span>())</span><br><span class="line"><span class="keyword">val</span> auc = evaluator.evaluate(auc_calculator)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MachineLearning </tag>
            
            <tag> Classification </tag>
            
            <tag> LogisticRegression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WOE与IV理论介绍及实现</title>
      <link href="/2020/01/27/woe-yu-iv-li-lun-jie-shao-ji-shi-xian/"/>
      <url>/2020/01/27/woe-yu-iv-li-lun-jie-shao-ji-shi-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="WOE定义"><a href="#WOE定义" class="headerlink" title="WOE定义"></a>WOE定义</h2><p>全称：Weight of Evidence</p><p>前提：计算之前需要是离散化后的连续变量or离散变量。</p><p>对于变量第$i$个取值的$WOE_i$的计算公式为</p><script type="math/tex; mode=display">WOE_i = ln(\frac{py_i} {pn_i})=ln(\frac{ \frac{ \#y_i }{ \#y_T } } { \frac{ \#n_i } { \#n_T }})=ln(\frac{\frac{ \#y_i }{ \#n_i } } {\frac{ \#y_T } { \#n_T } })</script><p>其中 #$y_i $表示在第$i$个取值的样本中（或第$i$个箱内）的正样本个数，#$ y_T $表示所有正样本的个数，$py_i$表示在第$i$个取值的样本中（或第$i$个箱内）正样本占所有正样本的比例。</p><p>从最后一个等号后的表达式可以看出，$WOE_i$表示的是某个取值下正样本和负样本的比值，与所有样本中这个比值的差异。这个差异是用比值再取对数来表示的。$WOE_i$越大，表示差异越大，则这个取值下的样本为正的可能性越大。</p><h2 id="WOE编码作用"><a href="#WOE编码作用" class="headerlink" title="WOE编码作用"></a>WOE编码作用</h2><ol><li>标准化功能。编码过后的自变量其实具备了某种标准化的性质，自变量内部的各个取值之间都可以直接进行比较，且不同自变量之间的各个取值也可以通过$WOE_i$进行直接的比较。</li><li>可以反映出自变量的贡献情况（？）。自变量内部$WOE_i$值的变异（波动）情况，结合模型拟合出的系数，构造出各个自变量的贡献率和相对重要性。一般地，系数越大，$WOE_i$的方差越大，则自变量的贡献率越大。</li></ol><h2 id="IV​"><a href="#IV​" class="headerlink" title="IV​"></a>IV​</h2><p>全程：Information Value</p><p>在$WOE_i$的基础上，$IV$在$WOE_i$的前面乘以一个系数$(py_i-pn_i)$作为各箱$WOE_i$的权重，并进行加权求和，其计算公式如下</p><script type="math/tex; mode=display">IV=\sum_{i=1}^{N}(py_i-pn_i)*WOE_i=\sum_{i=1}^{N}(py_i-pn_i)*ln(\frac{py_i}{pn_i})</script><p>其中$N$为分箱的个数（变量的取值个数），系数$(py_i-pn_i)$为箱内正样本占比与负样本占比的差。该系数不仅保证了每个箱乘积的值为非负数，更重要的是考虑了变量当前箱中样本的数量占整体样本数量的比例，比例越高，该箱对变量整体预测能力的贡献越高。</p><p>$IV$衡量某个特征对目标的影响程度，通过该特征中正负样本的比例与总体正负样本的比例，来对比和计算其关联程度，因此可以代表<strong>该特征上的信息量</strong>以及<strong>该特征对模型的贡献</strong>。</p><p>$IV$是对于整个特征来说的，代表的意义由下表来控制：</p><div class="table-container"><table><thead><tr><th>IV</th><th>特征对预测函数的贡献</th></tr></thead><tbody><tr><td>&lt;0.03</td><td>特征几乎不含有效信息，对模型没有贡献，可以删除</td></tr><tr><td>[0.03, 0.10)</td><td>有效信息很少，对模型的贡献度低</td></tr><tr><td>[0.10, 0.30)</td><td>有效信息一般，对模型的贡献度中等</td></tr><tr><td>[0.30, 0.50)</td><td>有效信息较多，对模型的贡献度较高</td></tr><tr><td>&gt;=0.50</td><td>有效信息非常多，对模型的贡献极高且可疑</td></tr></tbody></table></div><p>因此通常会选择$IV$值在0.1~0.5范围内的特征。</p><h1 id="单机python"><a href="#单机python" class="headerlink" title="单机python"></a>单机python</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CalcWOE</span><span class="params">(df, col, target)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    获得某个变量的分箱操作后每个箱体对应的WOE值，并且基于WOE值计算该变量的IV值</span></span><br><span class="line"><span class="string">    :param df: 包含需要计算WOE的变量和目标变量</span></span><br><span class="line"><span class="string">    :param col: 需要计算WOE、IV的变量，必须是分箱后的变量，或者不需要分箱的离散型变量</span></span><br><span class="line"><span class="string">    :param target: 目标变量，0、1表示好、坏</span></span><br><span class="line"><span class="string">    :return: 返回WOE和IV</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    total = df.groupby([col])[target].count()  <span class="comment"># 每个箱体的总数</span></span><br><span class="line">    total = pd.DataFrame(&#123;<span class="string">'total'</span>: total&#125;)    </span><br><span class="line">    bad = df.groupby([col])[target].sum()      <span class="comment"># 每个箱体的坏样本数</span></span><br><span class="line">    bad = pd.DataFrame(&#123;<span class="string">'bad'</span>: bad&#125;)</span><br><span class="line">    regroup = total.merge(bad, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>, how=<span class="string">'left'</span>)</span><br><span class="line">    regroup.reset_index(level=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    N = sum(regroup[<span class="string">'total'</span>]) <span class="comment"># 总体样本数</span></span><br><span class="line">    B = sum(regroup[<span class="string">'bad'</span>])   <span class="comment"># 总体坏样本数</span></span><br><span class="line">    regroup[<span class="string">'good'</span>] = regroup[<span class="string">'total'</span>] - regroup[<span class="string">'bad'</span>]  <span class="comment"># 每个箱体的好样本数</span></span><br><span class="line">    G = N - B                 <span class="comment"># 总体好样本数</span></span><br><span class="line">    regroup[<span class="string">'bad_pcnt'</span>] = regroup[<span class="string">'bad'</span>].map(<span class="keyword">lambda</span> x: x/B)    <span class="comment"># 每个箱体的坏样本数占总体的坏样本数的比例</span></span><br><span class="line">    regroup[<span class="string">'good_pcnt'</span>] = regroup[<span class="string">'good'</span>].map(<span class="keyword">lambda</span> x: x/G)  <span class="comment"># 每个箱体的好样本数占总体的好样本数的比例</span></span><br><span class="line">    <span class="comment"># WOEi计算公式(不含系数)： WOE(每个箱体) = ln(该箱体的好样本数占总体的好样本数的比例/该箱体的好样本数占总体的好样本数的比例）</span></span><br><span class="line">    regroup[<span class="string">'WOE'</span>] = regroup.apply(<span class="keyword">lambda</span> x: np.log(x.good_pcnt/x.bad_pcnt),axis=<span class="number">1</span>)   </span><br><span class="line">    WOE_dict = regroup[[col,<span class="string">'WOE'</span>]].set_index(col).to_dict(orient=<span class="string">'index'</span>)</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> WOE_dict.items(): <span class="comment"># k代表箱体名，v代表了以WOE为键，箱体的实际WOE值为value的字典</span></span><br><span class="line">        WOE_dict[k] = v[<span class="string">'WOE'</span>]</span><br><span class="line">    <span class="comment"># 计算该变量的IV值：sum((某箱体的好样本数占总体的好样本数的比例 - 该箱体的坏样本数占总体的坏样本数的比例)*WOE(某个箱体))</span></span><br><span class="line">    IV = regroup.apply(<span class="keyword">lambda</span> x: (x.good_pcnt-x.bad_pcnt)*np.log(x.good_pcnt/x.bad_pcnt),axis = <span class="number">1</span>)</span><br><span class="line">    IV = sum(IV)</span><br><span class="line">    <span class="keyword">return</span> &#123;col: &#123;<span class="string">"WOE"</span>: WOE_dict, <span class="string">'IV'</span>:IV&#125;&#125;</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用sklearn的乳腺癌数据集作为例子</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">df = pd.DataFrame(cancer.data, columns = cancer.feature_names)</span><br><span class="line">df[<span class="string">'label'</span>] = pd.DataFrame(cancer.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先进行等频分箱和编码（用到的函数见'分箱'）</span></span><br><span class="line">df_cut = df.copy()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_cut.columns[:<span class="number">-1</span>]:</span><br><span class="line">     cutoff = UnsupervisedSplitBin(df,col,numOfSplit=<span class="number">5</span>,method=<span class="string">'equalFreq'</span>)</span><br><span class="line">     df_cut[col] = df_cut[col].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutoff))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后循环计算每个变量的各箱WOE和IV，输出result</span></span><br><span class="line">result = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_cut.columns[:<span class="number">-1</span>]:</span><br><span class="line">     woe_iv_dict = CalcWOE(df_cut, col, target = <span class="string">'label'</span>)</span><br><span class="line">     result = pd.concat([result, pd.DataFrame(woe_iv_dict).T])</span><br></pre></td></tr></table></figure><h1 id="集群pyspark"><a href="#集群pyspark" class="headerlink" title="集群pyspark"></a>集群pyspark</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_woe_iv</span><span class="params">(tableName, featureCol, labelCol)</span>:</span></span><br><span class="line">     <span class="string">'''</span></span><br><span class="line"><span class="string">     计算spark.sql.DataFrame的WOE和IV</span></span><br><span class="line"><span class="string">     :param tableName: 储存在HDFS上的表名</span></span><br><span class="line"><span class="string">     :param featureCol: 所需要计算的字段名</span></span><br><span class="line"><span class="string">     :param labelCol: 标签列名</span></span><br><span class="line"><span class="string">     :return WOE字典和IV值</span></span><br><span class="line"><span class="string">     '''</span></span><br><span class="line">     df = spark.sql(<span class="string">"select &#123;featureCol&#125;, &#123;labelCol&#125; from &#123;tableName&#125;"</span>.format(featureCol=featureCol, labelCol=labelCol, tableName=tableName))</span><br><span class="line">     <span class="comment"># 使用crosstab函数生成列联表，并对列进行命名</span></span><br><span class="line">     binCount = df.crosstab(featureCol,labelCol).toDF(<span class="string">'feature'</span>,<span class="string">'neg_cnt'</span>,<span class="string">'pos_cnt'</span>)</span><br><span class="line">     <span class="comment"># 注册临时表便于后续调用</span></span><br><span class="line">     binCount.registerTempTable(<span class="string">"binCount"</span>)</span><br><span class="line">     <span class="comment"># 计算主要步骤</span></span><br><span class="line">     woe_df = spark.sql(<span class="string">"""</span></span><br><span class="line"><span class="string">        select</span></span><br><span class="line"><span class="string">          feature,</span></span><br><span class="line"><span class="string">          nvl(log(pos_per/neg_per), 0) as woe_i,</span></span><br><span class="line"><span class="string">          nvl((pos_per-neg_per)*log(pos_per/neg_per), 0) as iv_i</span></span><br><span class="line"><span class="string">        from</span></span><br><span class="line"><span class="string">        (</span></span><br><span class="line"><span class="string">          select</span></span><br><span class="line"><span class="string">            feature,</span></span><br><span class="line"><span class="string">            neg_cnt/(select sum(neg_cnt) from binCount) as neg_per,</span></span><br><span class="line"><span class="string">            pos_cnt/(select sum(pos_cnt) from binCount) as pos_per</span></span><br><span class="line"><span class="string">          from</span></span><br><span class="line"><span class="string">            binCount</span></span><br><span class="line"><span class="string">        ) t</span></span><br><span class="line"><span class="string">     """</span>)</span><br><span class="line">     <span class="comment"># 将计算结果转化为pandas.DataFrame</span></span><br><span class="line">     woe_df_pandas = woe_df.toPandas()</span><br><span class="line">     woe = dict(zip(woe_df_pandas[<span class="string">"feature"</span>].values.reshape(<span class="number">-1</span>,), woe_df_pandas[<span class="string">"woe_i"</span>].values.reshape(<span class="number">-1</span>,),))</span><br><span class="line">     iv = sum(woe_df_pandas[<span class="string">"iv_i"</span>].values)</span><br><span class="line">     <span class="keyword">return</span> woe, iv</span><br></pre></td></tr></table></figure><p>调用并测试运算时间</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    tableName = <span class="string">"test.calc_woe_iv_sample"</span></span><br><span class="line">    featureCol = <span class="string">"age_level"</span></span><br><span class="line">    labelCol = <span class="string">"label"</span></span><br><span class="line">    time_cost = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">        start = time.time()</span><br><span class="line">        woe, iv = cal_woe_iv(tableName, featureCol, labelCol)</span><br><span class="line">        end = time.time()</span><br><span class="line">        time_cost.append(end-start)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'time cost: %.5f sec'</span> % (np.mean(time_cost)))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'woe:'</span>, woe)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'iv:'</span>, iv)</span><br></pre></td></tr></table></figure><p>集群资源配置：</p><blockquote><p>spark.driver.memory=5G<br>spark.driver.maxResultSize=5G<br>num-executors=20<br>executor-cores=6<br>executor-memory=4G</p></blockquote><p>根据样本量的不同，测试计算时间结果（循环30次取平均）</p><div class="table-container"><table><thead><tr><th></th><th>10w</th><th>100w</th><th>1000w</th><th>1e</th></tr></thead><tbody><tr><td>计算时间(s)</td><td>0.872</td><td>1.819</td><td>3.172</td><td>25.793</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MachineLearning </tag>
            
            <tag> FeatureEngineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分箱基本方法介绍及实现</title>
      <link href="/2020/01/20/fen-xiang-ji-ben-fang-fa-jie-shao-ji-shi-xian/"/>
      <url>/2020/01/20/fen-xiang-ji-ben-fang-fa-jie-shao-ji-shi-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>将连续型的数据分为几个数据段，即特征离散化。</p><p>把无限空间中有限的个体映射到有限的空间中去，以此提高算法的时空效率。（百度百科） </p><h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ol><li><p><strong>离散化后的特征对异常数据有很强的鲁棒性，模型更加稳定。</strong>比如年龄&gt;70岁为一个分箱，异常数据如年龄为300岁同样会划分到该箱，不会给模型造成很大的干扰；比如将20岁-30岁划分为一个区间，不会因为年龄增长一岁就变成一个完全不同的人。而对于处于区间相邻处的样本会刚好相反，因此如何划分区间也很重要。</p></li><li><p>对于如逻辑回归的广义线性模型，表达能力受限，单变量离散化为$N$个变量后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。（？）</p></li><li><p>离散化后可以进行特征交叉，进一步<strong>引入非线性，提升模型表达能力</strong>。</p></li><li><p>可以将缺失值作为独立的箱代入变量。</p></li><li><p>可以将所有变量转换到相似的尺度上（不需要进行归一化）。</p></li></ol><h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><h3 id="无监督分箱"><a href="#无监督分箱" class="headerlink" title="无监督分箱"></a>无监督分箱</h3><h4 id="等频分箱"><a href="#等频分箱" class="headerlink" title="等频分箱"></a>等频分箱</h4><p>每个箱包含大致相等的样本数量，可以根据分位数进行划分，如四分位数等。</p><h4 id="等距分箱"><a href="#等距分箱" class="headerlink" title="等距分箱"></a>等距分箱</h4><p>从变量的最小值到最大值之间均等分为$N$等份。若$m$和$M$分别代表最小值和最大值，则每个区间的长度为$w=\frac{M-m}{N}$，区间的边界值为$m+w,m+2w,…,m+(N-1)w$。这里只考虑边界，每个等份的样本数量一般不等。</p><h3 id="有监督分箱"><a href="#有监督分箱" class="headerlink" title="有监督分箱"></a>有监督分箱</h3><h4 id="卡方分箱"><a href="#卡方分箱" class="headerlink" title="卡方分箱"></a>卡方分箱</h4><ul><li><p><strong>初始化</strong></p><ul><li><p>根据连续变量值的大小进行排序。</p></li><li><p>把每一个单独的值视为一个箱体，构建最初的离散化。目的是想从每个单独的箱体开始逐渐合并。</p></li></ul></li><li><p><strong>合并</strong>：在初始化构建完毕后，该步就是不断地进行自底向上的合并，直到满足停止条件。</p><ul><li><p><strong>计算所有相邻分箱的卡方值</strong>。比如有1,2,3,4这4个分箱，绑定相邻的两个分箱，一共有3组：12,23,34，然后分别计算三个绑定组的卡方值。卡方值的计算公式为</p><script type="math/tex; mode=display">\chi^2=\sum_{i=1}^{m}\sum_{j=1}^{k}\frac{(A_{ij}-E_{ij})^2}{E_{ij}}</script><p>其中，$m$表示要合并相邻分箱的数目（$m=2$表示对两个箱进行合并），$k$表示目标变量的类别数（两分类或多分类），$A_{ij}$表示实际频数（即第$i$个分箱第$j$类别的频数），$E_{ij}$表示期望频数，计算公式如下（可根据公式$P(AB)=P(A)P(B)$推导出来）</p><script type="math/tex; mode=display">E_{ij}=\frac{R_i*C_j}{N}</script><p>其中$R_i$和$C_j$分别是实际频数整行和整列的加和，$N$为总样本量。</p></li><li><p><strong>从计算的卡方值中找出最小的一个，并把这两个分箱合并</strong>。比如23是卡方值最小的一个，那么就将2和3合并，经过本轮的计算后分箱就变为1,23,4。</p><p>从合并的方法可以看出，卡方分箱的基本思想是，<strong>如果两个相邻的区间具有非常类似的类分布（即低卡方值，低卡方值表明它们具有类似的类分布），那么这两个区间可以合并，否则应该分开</strong>。</p></li></ul></li><li><p><strong>停止条件</strong>：以上仅是每一轮需要计算的内容，若不设置停止条件，算法会一直运行。一般从以下两个方面设置停止条件：</p><ul><li>卡方停止的阈值</li><li>分箱数目的限制</li></ul><p>即当所有分箱对的卡方值均大于阈值，且分箱数大于分箱数时，计算就会继续，直到不满足。</p><p>以上两个阈值一般根据经验来定义，来作为分箱函数的参数进行设置，一般使用0.90,0.95,0.99的置信度，分箱数一般可以设置为5。</p></li></ul><p><em>例如：</em></p><p>对于某两个箱（分箱1和分箱2），实际频数如下表</p><div class="table-container"><table><thead><tr><th></th><th>类别1</th><th>类别2</th><th>行频数和</th></tr></thead><tbody><tr><td><strong>分箱1</strong></td><td>$A_{11}$</td><td>$A_{12}$</td><td>$R_1$</td></tr><tr><td><strong>分箱2</strong></td><td>$A_{21}$</td><td>$A_{22}$</td><td>$R_2$</td></tr><tr><td><strong>列频数和</strong></td><td>$C_1$</td><td>$C_2$</td><td>$N$</td></tr></tbody></table></div><p>期望频数如下表</p><div class="table-container"><table><thead><tr><th></th><th>类别1</th><th>类别2</th></tr></thead><tbody><tr><td><strong>分箱1</strong></td><td>$E_{11}=\frac{R_1*C_1}{N}$</td><td>$E_{12}=\frac{R_1*C_2}{N}$</td></tr><tr><td><strong>分箱2</strong></td><td>$E_{21}=\frac{R_2*C_1}{N}$</td><td>$E_{22}=\frac{R_2*C_2}{N}$</td></tr></tbody></table></div><p>代入卡方公式求解，过程如下：</p><script type="math/tex; mode=display">\chi^2=\sum_{i=1}^{m}\sum_{j=1}^{k}\frac{(A_{ij}-E_{ij})^2}{E_{ij}}=[\frac{(A_{11}-E_{11})^2}{E_{11}}+\frac{(A_{12}-E_{12})^2}{E_{12}}]+[\frac{(A_{21}-E_{21})^2}{E_{21}}+\frac{(A_{22}-E_{22})^2}{E_{22}}]</script><p>如果计算结果是所有卡方值中最小的，说明这两个分箱具有最相似的类分布，因此把它们合并。</p><p>（参考 <a href="https://cloud.tencent.com/developer/article/1418720" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1418720</a> ）</p><h1 id="单机python实现"><a href="#单机python实现" class="headerlink" title="单机python实现"></a>单机python实现</h1><h2 id="无监督分箱-1"><a href="#无监督分箱-1" class="headerlink" title="无监督分箱"></a>无监督分箱</h2><ul><li>UnsupervisedSplitBin函数：对数值型变量进行分组，分组的依据有等频和等距，最后返回划分点列表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">UnsupervisedSplitBin</span><span class="params">(df,col,numOfSplit=<span class="number">5</span>,method=<span class="string">'equalFreq'</span>)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于对数值型变量进行划分，最后返回划分点组成的列表</span></span><br><span class="line"><span class="string">:param df: 数据集</span></span><br><span class="line"><span class="string">:param col: 需要分箱的变量。仅限数值型变量</span></span><br><span class="line"><span class="string">:param numOfSplit: 需要分箱个数，默认是5</span></span><br><span class="line"><span class="string">:param method: 分箱方法，'equalFreq'：默认是等频，否则是等距</span></span><br><span class="line"><span class="string">:return: 返回划分点组成的列表</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> method == <span class="string">'equalFreq'</span>:</span><br><span class="line"><span class="comment"># 等频分箱</span></span><br><span class="line">frequency_cutoff = [np.percentile(df[col], <span class="number">100</span>/numOfSplit*i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,numOfSplit)]</span><br><span class="line">splitPoint = sorted(list(set(frequency_cutoff)))</span><br><span class="line"><span class="keyword">return</span> splitPoint</span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">'equalDis'</span>:</span><br><span class="line"><span class="comment"># 等距分箱</span></span><br><span class="line">var_max, var_min = max(df[col]), min(df[col])</span><br><span class="line">interval_len = (var_max-var_min)/numOfSplit</span><br><span class="line">splitPoint = [var_min+i*interval_len <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,numOfSplit)]</span><br><span class="line"><span class="keyword">return</span> splitPoint</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="string">'Sorry, no such method'</span></span><br></pre></td></tr></table></figure><h2 id="有监督分箱：卡方分箱"><a href="#有监督分箱：卡方分箱" class="headerlink" title="有监督分箱：卡方分箱"></a>有监督分箱：卡方分箱</h2><ul><li><p>SplitData函数：用于对某变量进行划分，根据划分的组数，返回划分点数值组成的列表</p></li><li><p>Chi2函数：用于计算卡方值，返回卡方值（按照卡方检验的原理进行计算）</p></li><li><p>BinBadRate函数：按某变量进行分组，计算分组后每组的坏样本率，返回的有，字典形式，数据框，总体坏样本率（可选）</p></li><li><p>AssignGroup函数：根据分组后的划分点列表，给某个需分箱的变量的每个取值进行分箱前的匹配，形成对应箱的映射</p></li><li><p>AssignBin函数：将某列的每个取值进行分箱编号</p></li><li><p>ChiMerge函数：卡方分箱的主体函数，其中调用了前面五个基础函数，返回的是最终的满足所有限制条件的划分点列表</p><ul><li><p>其中需要满足：</p><p>（1）最后分裂出的分箱数 &lt;= 预设的最大分箱数</p><p>（2）每个箱体必须同时包含好坏样本</p><p>（3）每个箱体的占比不低于预设值（可选）</p><p>（4）如果有特殊的属性值，则最终的分箱数 = 预设的最大分箱数 - 特殊值个数</p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SplitData</span><span class="params">(df,col,numOfSplit,special_attribute=[])</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于获得数据切分时对应位置的数值</span></span><br><span class="line"><span class="string">:param df: pandas.DataFrame</span></span><br><span class="line"><span class="string">:param col: str 选择数据集中的某列进行操作</span></span><br><span class="line"><span class="string">:param numOfSplit: int 划分的组数</span></span><br><span class="line"><span class="string">:param special_attribute: 用于过滤掉一些特殊的值，不参与数据划分（可选，默认不过滤）</span></span><br><span class="line"><span class="string">:return: 返回划分点位置对应的数值组成的列表</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">df2 = df.copy()</span><br><span class="line"><span class="keyword">if</span> special_attribute != []:</span><br><span class="line">df2 = df2.loc[~df2[col].isin(special_attribute)]  <span class="comment"># 排除有特殊值的样本行</span></span><br><span class="line">N = len(df2) <span class="comment"># 样本总数</span></span><br><span class="line">n = int(N/numOfSplit) <span class="comment"># 每组包含的样本量</span></span><br><span class="line">SplitPointIndex = [i*n <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,numOfSplit)] <span class="comment"># 不包含numOfSplit</span></span><br><span class="line"><span class="comment"># 如总样本N=20，numofsplit为5组，则每组包含4个元素(n=4)</span></span><br><span class="line"><span class="comment"># 则最后得到的SplitPointIndex=[4,8,12,16]，即切分点位置，各组样本为0-3/4-7/8-11/12-15</span></span><br><span class="line">rawValues = sorted(list(df[col])) <span class="comment"># sorted返回一个新的排列后的列表</span></span><br><span class="line">SplitPoint = [rawValues[i] <span class="keyword">for</span> i <span class="keyword">in</span> SplitPointIndex] <span class="comment"># 返回位置索引上对应的数值</span></span><br><span class="line"><span class="comment"># 为了以防万一，去重再排序</span></span><br><span class="line">SplitPoint = sorted(list(set(SplitPoint)))</span><br><span class="line"><span class="keyword">return</span> SplitPoint </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AssignGroup</span><span class="params">(x,bin)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于：根据分组后的划分点列表（bin)，给某个需要分箱的变量进行分箱前的匹配，形成对应箱的映射，以便后期分箱操作，将值划分到不同箱体</span></span><br><span class="line"><span class="string">:param x: 某个变量的某个取值</span></span><br><span class="line"><span class="string">:param bin: 上述变量分组后（通过SplitData函数）对应的划分位置的数值组成的列表</span></span><br><span class="line"><span class="string">:return: x在分箱结果下的映射 </span></span><br><span class="line"><span class="string">'''</span> </span><br><span class="line">N = len(bin)            <span class="comment"># 划分点的长度</span></span><br><span class="line"><span class="keyword">if</span> x&lt;=min(bin):         <span class="comment"># 如果某个取值小于等于最小划分点，则返回最小划分点</span></span><br><span class="line"><span class="keyword">return</span> min(bin)</span><br><span class="line"><span class="keyword">elif</span> x&gt;max(bin):        <span class="comment"># 如果某个取值大于最小划分点，则返回10e10</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">10e10</span></span><br><span class="line"><span class="keyword">else</span>:                   <span class="comment"># 除此之外，返回其他对应的划分点</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(N<span class="number">-1</span>):</span><br><span class="line"><span class="keyword">if</span> bin[i] &lt; x &lt;= bin[i+<span class="number">1</span>]:</span><br><span class="line"><span class="keyword">return</span> bin[i+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BinBadRate</span><span class="params">(df,col,target,grantRateIndicator=False)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于对变量按照取值（每个取值都是唯一的）进行分组，获得每箱的坏样本率，后期基于该值判断是否需要合并操作</span></span><br><span class="line"><span class="string">:param df: pandas.DataFrame 需要计算好坏比率的数据集</span></span><br><span class="line"><span class="string">:param col: str 需要计算好坏比率的特征</span></span><br><span class="line"><span class="string">:param target: str 好坏标签</span></span><br><span class="line"><span class="string">:param grantRateIndicator: bool True返回总体的坏样本率，False不返回（可选，默认不返回）</span></span><br><span class="line"><span class="string">:return: 每箱的坏样本率，以及总体的坏样本率（当grantRateIndicator==True时）</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">total = df.groupby([col])[target].count()</span><br><span class="line">total = pd.DataFrame(&#123;<span class="string">'total'</span>: total&#125;)</span><br><span class="line">bad = df.groupby([col])[target].sum()</span><br><span class="line">bad = pd.DataFrame(&#123;<span class="string">'bad'</span>: bad&#125;)</span><br><span class="line"></span><br><span class="line">regroup = total.merge(bad, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>, how=<span class="string">'left'</span>) <span class="comment"># 每箱的坏样本数，总样本数</span></span><br><span class="line">regroup.reset_index(level=<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">regroup[<span class="string">'bad_rate'</span>] = regroup.apply(<span class="keyword">lambda</span> x: x.bad / x.total, axis=<span class="number">1</span>) <span class="comment"># 加上一列坏样本率</span></span><br><span class="line">dicts = dict(zip(regroup[col],regroup[<span class="string">'bad_rate'</span>])) <span class="comment"># 每箱对应的坏样本率组成的字典</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> grantRateIndicator:</span><br><span class="line"><span class="keyword">return</span> (dicts, regroup)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">N = sum(regroup[<span class="string">'total'</span>])</span><br><span class="line">B = sum(regroup[<span class="string">'bad'</span>])</span><br><span class="line">overallRate = B / N</span><br><span class="line"><span class="keyword">return</span> (dicts, regroup, overallRate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Chi2</span><span class="params">(df,totalCol,badCol)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于获得卡方值</span></span><br><span class="line"><span class="string">:param df: pandas.DataFrame 包含了每个分组下的样本总数和坏样本数</span></span><br><span class="line"><span class="string">:param totalCol: str 列名，元素由各个分组下的样本总数构成</span></span><br><span class="line"><span class="string">:param badCol: str 列名，元素由各个分组下的坏样本数构成</span></span><br><span class="line"><span class="string">:return: 卡方值</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">df2 = df.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算该特征各个分组下的好样本数</span></span><br><span class="line">df2[<span class="string">'good'</span>] = df2.apply(<span class="keyword">lambda</span> x: x[totalCol]-x[badCol], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求出期望值E</span></span><br><span class="line"><span class="comment"># 1.求出总体的坏样本率和好样本率</span></span><br><span class="line">badRate = sum(df2[badCol]) / sum(df2[totalCol])</span><br><span class="line">goodRate = sum(df2[<span class="string">'good'</span>]) / sum(df2[totalCol])</span><br><span class="line"><span class="comment"># 特殊情况：当全部样本只有好或者坏样本时，卡方值为0</span></span><br><span class="line"><span class="keyword">if</span> badRate <span class="keyword">in</span> [<span class="number">0</span>,<span class="number">1</span>]:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.根据总体的好坏样本率算出期望的好坏样本数，计算公式为：</span></span><br><span class="line"><span class="comment"># 期望坏（好）样本个数 ＝ 全部样本个数 * 总体的坏（好）样本率</span></span><br><span class="line">df2[<span class="string">'badExpected'</span>] = df2[totalCol].apply(<span class="keyword">lambda</span> x: x*badRate)</span><br><span class="line">df2[<span class="string">'goodExpected'</span>] = df2[totalCol].apply(<span class="keyword">lambda</span> x: x*goodRate)</span><br><span class="line"></span><br><span class="line">badCombined = zip(df2[<span class="string">'badExpected'</span>], df2[badCol])</span><br><span class="line">goodCombined = zip(df2[<span class="string">'goodExpected'</span>], df2[<span class="string">'good'</span>])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 按照卡方计算的公式计算卡方值：  ∑ (O - E)^2 / E, O代表实际值，E代表期望值     </span></span><br><span class="line">badChi = [(i[<span class="number">0</span>]-i[<span class="number">1</span>])**<span class="number">2</span>/i[<span class="number">1</span>] <span class="keyword">if</span> i[<span class="number">1</span>]!=<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> badCombined]</span><br><span class="line">goodChi = [(i[<span class="number">0</span>]-i[<span class="number">1</span>])**<span class="number">2</span>/i[<span class="number">1</span>] <span class="keyword">if</span> i[<span class="number">1</span>]!=<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> goodCombined]</span><br><span class="line">chi2 = sum(badChi) + sum(goodChi)</span><br><span class="line"><span class="keyword">return</span> chi2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AssignBin</span><span class="params">(x,cutOffPoints,special_attribute=[])</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于对某个列的某个取值进行分箱编号（编码）</span></span><br><span class="line"><span class="string">:param x: 某个变量的某个取值</span></span><br><span class="line"><span class="string">:param cutOffPoints: 上述变量的分组结果，用切分点表示，列表形式</span></span><br><span class="line"><span class="string">:param special_attribute: 不参与分箱的特殊取值（可选）</span></span><br><span class="line"><span class="string">:return: 分箱后的对应的第几个箱，从0开始</span></span><br><span class="line"><span class="string">比如，若cutOffPoints=[10,20,30]，当x=7，返回0；当x=35，返回3</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">numBin = len(cutOffPoints) + <span class="number">1</span> + len(special_attribute)</span><br><span class="line"><span class="keyword">if</span> x <span class="keyword">in</span> special_attribute:</span><br><span class="line">i = special_attribute.index(x)+<span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> (<span class="number">0</span>-i)</span><br><span class="line"><span class="keyword">if</span> x &lt;= cutOffPoints[<span class="number">0</span>]:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">elif</span> x &gt; cutOffPoints[<span class="number">-1</span>]:</span><br><span class="line"><span class="keyword">return</span> (numBin<span class="number">-1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,numBin<span class="number">-1</span>):</span><br><span class="line"><span class="keyword">if</span> cutOffPoints[i] &lt; x &lt;= cutOffPoints[i+<span class="number">1</span>]:</span><br><span class="line"><span class="keyword">return</span> (i+<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ChiMerge</span><span class="params">(df,col,target,max_interval=<span class="number">5</span>,special_attribute=[],minBinPcnt=<span class="number">0</span>)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">该函数用于实际的卡方分箱算法操作，最后返回有实际的划分点组成的列表</span></span><br><span class="line"><span class="string">:param df: pandas.DataFrame 包含目标变量与需要分箱变量的数据集</span></span><br><span class="line"><span class="string">:param col: str 需要分箱的属性</span></span><br><span class="line"><span class="string">:param target: str 目标变量，取值0或1</span></span><br><span class="line"><span class="string">:param max_interval: int 最大分箱数（默认5）。如果原始属性的取值个数低于该参数，不执行这段函数</span></span><br><span class="line"><span class="string">:param special_attribute: list 不参与分箱的属性取值（可选）</span></span><br><span class="line"><span class="string">:param minBinPcnt：最小箱的占比（默认0），如果不满足最小分箱占比继续进行组别合并</span></span><br><span class="line"><span class="string">:return: 分箱结果</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">colLevels = sorted(list(set(df[col])))  <span class="comment"># 某列的不重复值</span></span><br><span class="line">N_distinct = len(colLevels)             <span class="comment"># 某列的不重复值计数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> N_distinct &lt;= max_interval:  <span class="comment">#如果原始属性的取值个数低于max_interval，不执行这段函数（不参与分箱）</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"The number of original levels for '&#123;col&#125;' is &#123;dis_cnt&#125;, which is less than or equal to max intervals"</span>.format(col=col, dis_cnt=N_distinct))</span><br><span class="line"><span class="keyword">return</span> colLevels[:<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> len(special_attribute)&gt;=<span class="number">1</span>:</span><br><span class="line">df2 = df.loc[~df[col].isin(special_attribute)] <span class="comment"># 去掉special_attribute后的df</span></span><br><span class="line">N_distinct = len(list(set(df2[col])))  <span class="comment"># 去掉special_attribute后的非重复值计数</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">df2 = df.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤一: 通过col对数据进行分组，求出每组的总样本数和坏样本数</span></span><br><span class="line"><span class="keyword">if</span> N_distinct &gt; <span class="number">100</span>:</span><br><span class="line">split_x = SplitData(df2,col,<span class="number">100</span>) <span class="comment"># 若非重复值计数超过100组，均将其转化成100组，将多余样本都划分到最后一个箱中</span></span><br><span class="line">df2[<span class="string">'temp_cutoff'</span>] = df2[col].map(<span class="keyword">lambda</span> x: AssignGroup(x,split_x))</span><br><span class="line"><span class="comment"># Assgingroup函数：每一行的数值和切分点做对比，返回原值在切分后的映射，</span></span><br><span class="line"><span class="comment"># 经过map以后，生成该特征的值对象的"分箱"后的值        </span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">df2[<span class="string">'temp_cutoff'</span>] = df2[col] <span class="comment"># 不重复值计数不超过100时，不需要进行上述步骤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过上述过程，我们现在可以将该列进行BadRate计算，用来计算每个箱体的坏样本率 以及总体的坏样本率      </span></span><br><span class="line">(binBadRate, regroup, overallRate) = BinBadRate(df2, <span class="string">'temp_cutoff'</span>, target, grantRateIndicator=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在此，我们将每个单独的属性值分成单独一组</span></span><br><span class="line"><span class="comment"># 对属性值进行去重排序，然后两两组别进行合并，用于后续的卡方值计算</span></span><br><span class="line">colLevels = sorted(list(set(df2[<span class="string">'temp_cutoff'</span>])))</span><br><span class="line">groupIntervals = [[i] <span class="keyword">for</span> i <span class="keyword">in</span> colLevels] <span class="comment"># 把每个箱的值打包成[[],[]]的形式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤二：通过循环的方式，不断的合并相邻的两个组别，直到：</span></span><br><span class="line"><span class="comment"># （1）最后分裂出的分箱数 &lt;= 预设的最大分箱数</span></span><br><span class="line"><span class="comment"># （2）每个箱体必须同时包含好坏样本</span></span><br><span class="line"><span class="comment"># （3）每个箱体的占比不低于预设值（可选）</span></span><br><span class="line"><span class="comment"># （4）如果有特殊的属性值，则最终的分箱数 = 预设的最大分箱数 - 特殊值个数</span></span><br><span class="line">split_intervals = max_interval - len(special_attribute)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每次循环时, 计算合并相邻组别后的卡方值。当组别数大于预设的分箱数时，持续选择最小卡方值的组合并</span></span><br><span class="line"><span class="keyword">while</span> len(groupIntervals)&gt;split_intervals:</span><br><span class="line">chisqList = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(len(groupIntervals)<span class="number">-1</span>):</span><br><span class="line">temp_group = groupIntervals[k] + groupIntervals[k+<span class="number">1</span>]  <span class="comment"># 返回的是，这两个值组成的列表</span></span><br><span class="line"><span class="comment"># 因此，可以通过temp_group，每次只选相邻的两组进行相关操作</span></span><br><span class="line">df2b = regroup.loc[regroup[<span class="string">'temp_cutoff'</span>].isin(temp_group)]</span><br><span class="line"><span class="comment"># 计算相邻两组的卡方值(通过调用Chi2函数)</span></span><br><span class="line">chisq = Chi2(df2b,<span class="string">'total'</span>,<span class="string">'bad'</span>)</span><br><span class="line">chisqList.append(chisq)</span><br><span class="line">best_comnbined = chisqList.index(min(chisqList)) <span class="comment"># 检索最小卡方值所在的索引    </span></span><br><span class="line"><span class="comment"># 把groupIntervals的值改成类似的值改成类似从[[1],[2],[3]]到[[1,2],[3]]</span></span><br><span class="line">groupIntervals[best_comnbined] = groupIntervals[best_comnbined] + groupIntervals[best_comnbined+<span class="number">1</span>]</span><br><span class="line">groupIntervals.remove(groupIntervals[best_comnbined+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述循环结束后，即可获得预设的分箱数，并且可以得到各分箱的划分点</span></span><br><span class="line">groupIntervals = [sorted(i) <span class="keyword">for</span> i <span class="keyword">in</span> groupIntervals]</span><br><span class="line">cutOffPoints = [max(i) <span class="keyword">for</span> i <span class="keyword">in</span> groupIntervals[:<span class="number">-1</span>]] </span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后，我们将某列进行分箱编号</span></span><br><span class="line">groupedvalues = df2[<span class="string">'temp_cutoff'</span>].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutOffPoints))</span><br><span class="line">df2[<span class="string">'temp_Bin'</span>] = groupedvalues</span><br><span class="line"><span class="comment"># AssignBin函数：每一行的数值和切分点做对比，返回原值所在的分箱编号（形成新列）    </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进一步，我们想要保证每个箱体都有好坏样本数</span></span><br><span class="line"><span class="comment"># 检查是否有箱没有好或者坏样本。如果有，需要跟相邻的箱进行合并，直到每箱同时包含好坏样本</span></span><br><span class="line">(binBadRate,regroup) = BinBadRate(df2, <span class="string">'temp_Bin'</span>, target)    <span class="comment"># 返回每箱坏样本率字典，和包含'分箱号、总样本数、坏样本数、坏样本率的数据框'）</span></span><br><span class="line">minBadRate, maxBadRate = min(binBadRate.values()), max(binBadRate.values())</span><br><span class="line"><span class="keyword">while</span> minBadRate ==<span class="number">0</span> <span class="keyword">or</span> maxBadRate == <span class="number">1</span>:</span><br><span class="line"><span class="comment"># 找出全部为好／坏样本的箱</span></span><br><span class="line">indexForBad01 = regroup[regroup[<span class="string">'bad_rate'</span>].isin([<span class="number">0</span>,<span class="number">1</span>])].temp_Bin.tolist()    </span><br><span class="line">bin = indexForBad01[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 如果是最后一箱，则需要和上一个箱进行合并，也就意味着分裂点cutOffPoints中的最后一个划分点需要移除</span></span><br><span class="line"><span class="keyword">if</span> bin == max(regroup.temp_Bin):</span><br><span class="line">cutOffPoints = cutOffPoints[:<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 如果是第一箱，则需要和下一个箱进行合并，也就意味着分裂点cutOffPoints中的第一个需要移除</span></span><br><span class="line"><span class="keyword">elif</span> bin == min(regroup.temp_Bin):</span><br><span class="line">cutOffPoints = cutOffPoints[<span class="number">1</span>:]</span><br><span class="line"><span class="comment"># 如果是中间的某一箱，则需要和前后中的一个箱体进行合并，具体选择哪个箱体，要依据前后箱体哪个卡方值较小</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># 和前一箱进行合并，并且计算卡方值</span></span><br><span class="line">currentIndex = list(regroup.temp_Bin).index(bin)</span><br><span class="line">prevIndex = list(regroup.temp_Bin)[currentIndex - <span class="number">1</span>]</span><br><span class="line">df3 = df2.loc[df2[<span class="string">'temp_Bin'</span>].isin([prevIndex, bin])]</span><br><span class="line">(binBadRate, df2b) = BinBadRate(df3, <span class="string">'temp_Bin'</span>, target)</span><br><span class="line">chisq1 = Chi2(df2b, <span class="string">'total'</span>, <span class="string">'bad'</span>)</span><br><span class="line"><span class="comment"># 和后一箱进行合并，并且计算卡方值</span></span><br><span class="line">laterIndex = list(regroup.temp_Bin)[currentIndex + <span class="number">1</span>]</span><br><span class="line">df3b = df2.loc[df2[<span class="string">'temp_Bin'</span>].isin([laterIndex, bin])]</span><br><span class="line">(binBadRate, df2b) = BinBadRate(df3b, <span class="string">'temp_Bin'</span>, target)</span><br><span class="line">chisq2 = Chi2(df2b, <span class="string">'total'</span>, <span class="string">'bad'</span>)</span><br><span class="line"><span class="keyword">if</span> chisq1 &lt; chisq2:</span><br><span class="line">cutOffPoints.remove(cutOffPoints[currentIndex - <span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">cutOffPoints.remove(cutOffPoints[currentIndex])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完成此项合并后，需要再次计算，在新的分箱准则下，每箱是否同时包含好坏样本，</span></span><br><span class="line"><span class="comment"># 如何仍然出现不能同时包含好坏样本的箱体，继续循坏，直到好坏样本同时出现在每个箱体后，跳出</span></span><br><span class="line">groupedvalues = df2[<span class="string">'temp'</span>].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutOffPoints))</span><br><span class="line">df2[<span class="string">'temp_Bin'</span>] = groupedvalues</span><br><span class="line">(binBadRate, regroup) = BinBadRate(df2, <span class="string">'temp_Bin'</span>, target)</span><br><span class="line">[minBadRate, maxBadRate] = [min(binBadRate.values()), max(binBadRate.values())]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，我们来检查分箱后的最小占比</span></span><br><span class="line"><span class="keyword">if</span> minBinPcnt &gt; <span class="number">0</span>: <span class="comment"># 如果函数调用初期给的minBinPct不是零，则进一步对箱体进行合并</span></span><br><span class="line">groupedvalues = df2[<span class="string">'temp'</span>].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutOffPoints))</span><br><span class="line">df2[<span class="string">'temp_Bin'</span>] = groupedvalues</span><br><span class="line">valueCounts = groupedvalues.value_counts().to_frame()</span><br><span class="line">valueCounts[<span class="string">'pcnt'</span>] = valueCounts[<span class="string">'temp'</span>].apply(<span class="keyword">lambda</span> x: x / sum(valueCounts[<span class="string">'temp'</span>]))</span><br><span class="line">valueCounts = valueCounts.sort_index()</span><br><span class="line">minPcnt = min(valueCounts[<span class="string">'pcnt'</span>]) <span class="comment"># 得到箱体的最小占比</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果箱体最小占比小于给定的分箱占比阈值 且 划分点大于2，进入合并循环中</span></span><br><span class="line"><span class="keyword">while</span> minPcnt &lt; minBinPcnt <span class="keyword">and</span> len(cutOffPoints) &gt; <span class="number">2</span>: </span><br><span class="line"><span class="comment"># 找出占比最小的箱</span></span><br><span class="line">indexForMinPcnt = valueCounts[valueCounts[<span class="string">'pcnt'</span>] == minPcnt].index.tolist()[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 如果占比最小的箱是最后一箱，则需要和上一个箱进行合并，也就意味着分裂点cutOffPoints中的最后一个需要移除</span></span><br><span class="line"><span class="keyword">if</span> indexForMinPcnt == max(valueCounts.index):</span><br><span class="line">cutOffPoints = cutOffPoints[:<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 如果占比最小的箱是第一箱，则需要和下一个箱进行合并，也就意味着分裂点cutOffPoints中的第一个需要移除</span></span><br><span class="line"><span class="keyword">elif</span> indexForMinPcnt == min(valueCounts.index):</span><br><span class="line">cutOffPoints = cutOffPoints[<span class="number">1</span>:]</span><br><span class="line"><span class="comment"># 如果占比最小的箱是中间的某一箱，则需要和前后中的一个箱进行合并，合并依据是较小的卡方值</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># 和前一箱进行合并，并且计算卡方值</span></span><br><span class="line">currentIndex = list(valueCounts.index).index(indexForMinPcnt)</span><br><span class="line">prevIndex = list(valueCounts.index)[currentIndex - <span class="number">1</span>]</span><br><span class="line">df3 = df2.loc[df2[<span class="string">'temp_Bin'</span>].isin([prevIndex, indexForMinPcnt])]</span><br><span class="line">(binBadRate, df2b) = BinBadRate(df3, <span class="string">'temp_Bin'</span>, target)</span><br><span class="line">chisq1 = Chi2(df2b, <span class="string">'total'</span>, <span class="string">'bad'</span>)</span><br><span class="line"><span class="comment"># 和后一箱进行合并，并且计算卡方值</span></span><br><span class="line">laterIndex = list(valueCounts.index)[currentIndex + <span class="number">1</span>]</span><br><span class="line">df3b = df2.loc[df2[<span class="string">'temp_Bin'</span>].isin([laterIndex, indexForMinPcnt])]</span><br><span class="line">(binBadRate, df2b) = BinBadRate(df3b, <span class="string">'temp_Bin'</span>, target)</span><br><span class="line">chisq2 = Chi2(df2b, <span class="string">'total'</span>, <span class="string">'bad'</span>)</span><br><span class="line"><span class="keyword">if</span> chisq1 &lt; chisq2:</span><br><span class="line">cutOffPoints.remove(cutOffPoints[currentIndex - <span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">cutOffPoints.remove(cutOffPoints[currentIndex])        </span><br><span class="line">groupedvalues = df2[<span class="string">'temp'</span>].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutOffPoints))</span><br><span class="line">df2[<span class="string">'temp_Bin'</span>] = groupedvalues</span><br><span class="line">valueCounts = groupedvalues.value_counts().to_frame()</span><br><span class="line">valueCounts[<span class="string">'pcnt'</span>] = valueCounts[<span class="string">'temp'</span>].apply(<span class="keyword">lambda</span> x: x * <span class="number">1.0</span> / sum(valueCounts[<span class="string">'temp'</span>]))</span><br><span class="line">valueCounts = valueCounts.sort_index()</span><br><span class="line">minPcnt = min(valueCounts[<span class="string">'pcnt'</span>])</span><br><span class="line"></span><br><span class="line">cutOffPoints = special_attribute + cutOffPoints</span><br><span class="line"><span class="keyword">return</span> cutOffPoints</span><br></pre></td></tr></table></figure><p>(参考 <a href="https://blog.csdn.net/LuLuYao9494/article/details/92083755" target="_blank" rel="noopener">https://blog.csdn.net/LuLuYao9494/article/details/92083755</a> )</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用sklearn的乳腺癌数据集作为例子</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">df = pd.DataFrame(cancer.data, columns = cancer.feature_names)</span><br><span class="line">df[<span class="string">'label'</span>] = pd.DataFrame(cancer.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置分箱参数</span></span><br><span class="line">bins = <span class="number">5</span> <span class="comment"># 分箱数</span></span><br><span class="line">col = <span class="string">'mean radius'</span> <span class="comment"># 分箱字段名</span></span><br><span class="line">target = <span class="string">'label'</span> <span class="comment"># 标签字段名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等频分箱</span></span><br><span class="line">frequency_cutoff = UnsupervisedSplitBin(df,col,numOfSplit=<span class="number">5</span>,method=<span class="string">'equalFreq'</span>)</span><br><span class="line"><span class="comment"># [11.366, 12.726, 14.058000000000002, 17.067999999999998]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等距分箱</span></span><br><span class="line">distance_cutoff = UnsupervisedSplitBin(df,col,numOfSplit=<span class="number">5</span>,method=<span class="string">'equalDis'</span>)</span><br><span class="line"><span class="comment"># [11.2068, 15.432599999999999, 19.6584, 23.8842]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 卡方分箱</span></span><br><span class="line">chiMerge_cutoff = ChiMerge(df,col,target,max_interval=<span class="number">5</span>,special_attribute=[],minBinPcnt=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># [12.46, 13.38, 15.0, 16.84]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#以等频分箱为例在数据集上进行编码</span></span><br><span class="line">df_cut = df.copy()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df_cut.columns[:<span class="number">-1</span>]:</span><br><span class="line">    <span class="comment"># 得到切分点（获取切分点的方法可替换）</span></span><br><span class="line">    cutoff = UnsupervisedSplitBin(df,col,numOfSplit=<span class="number">5</span>,method=<span class="string">'equalFreq'</span>)</span><br><span class="line">    <span class="comment"># 进行编码</span></span><br><span class="line">    df_cut[col] = df_cut[col].apply(<span class="keyword">lambda</span> x: AssignBin(x, cutoff))</span><br></pre></td></tr></table></figure><h1 id="集群pyspark实现"><a href="#集群pyspark实现" class="headerlink" title="集群pyspark实现"></a>集群pyspark实现</h1><p>pyspark.ml.feature提供等频分箱的API可以直接调用</p><p><em>class</em> <code>pyspark.ml.feature.QuantileDiscretizer</code>(<em>numBuckets=2</em>, <em>inputCol=None</em>, <em>outputCol=None</em>, <em>relativeError=0.001</em>, <em>handleInvalid=’error’</em>)<a href="http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer" target="_blank" rel="noopener"><a href="http://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/feature.html#QuantileDiscretizer" target="_blank" rel="noopener">source\</a></a></p><p>参数：</p><ol><li>numBuckets：分箱数，但若样本数据只有3个取值，但numBuckets=4，则仍只划分为3个箱</li><li>relativeError：用于控制近似的精度，取值范围为[0,1]，当设置为0时会计算精确的分位数（计算代价较高）</li><li>handleInvalid：选择处理空值的方式，有三种选项：’keep’将空值放入专门的箱中，例如如果使用4个箱，则将非空数据放入箱0-3中，将空值放入特殊的箱4中；’skip’：过滤掉含有空值的行；’error’报错。（？实验了一下这三种选项并没有区别？？？结果没有处理缺失值仍输出空值，也没有报错……？？）</li><li>inputCol：输入要分箱的列名，outputCol：输出分箱后新特征的列名</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> QuantileDiscretizer</span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">df = spark.sql(<span class="string">"select * from test.sklearn_dataset_iris"</span>)</span><br><span class="line">col = <span class="string">'sepal length (cm)'</span> <span class="comment"># 对该列进行等频分箱</span></span><br><span class="line"></span><br><span class="line">qd = QuantileDiscretizer(numBuckets=<span class="number">5</span>, inputCol=col, outputCol=col+<span class="string">'_bin'</span>)</span><br><span class="line">qd_model = qd.fit(df)</span><br><span class="line"><span class="keyword">print</span> (qd_model.getSplits()) <span class="comment"># 打印分箱的节点</span></span><br><span class="line">df_new = qd_model.transform(df)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MachineLearning </tag>
            
            <tag> FeatureEngineering </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
