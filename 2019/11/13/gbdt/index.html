<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="xjw924">


    <meta name="subtitle" content="Hi, there~">


    <meta name="description" content="统计|数据分析|机器学习|大数据">



<title>GBDT | 小徐小徐不断学习</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">xjw924</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">xjw924</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">GBDT</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">xjw924</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">November 13, 2019&nbsp;&nbsp;22:03:06</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/MachineLearning/">MachineLearning</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>GBDT是集成学习Boosting家族的成员，是对提升树的改进。</p>
<p>使用的决策树通常为CART回归树（使用回归树的原因是因为：GBDT每次迭代要拟合的是梯度值，是连续值所以要用回归树）</p>
<p>在每一轮的迭代中，首先<strong>计算当前模型在所有样本上的负梯度</strong>，然后以该值为目标，训练一个新的弱分类器，并计算该弱分类器的权重，以累加的形式结合到现有模型中，实现对模型的更新</p>
<p>利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。</p>
<h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><p>优点：它能灵活的处理各种类型的数据；在相对较少的调参时间下，预测的准确度较高，这个是相对SVM来说的。 </p>
<p>缺点：基学习器之前存在串行关系，难以并行训练数据。</p>
<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><p>1.对于分类算法，其损失函数一般有对数损失函数和指数损失函数两种: </p>
<p>(1)如果是指数损失函数，此时GBDT退化为Adaboost算法，损失函数表达式为</p>
<p><img src="file:///C:/WINDOWS/Temp/msohtmlclip1/01/clip_image002.jpg" alt="img"></p>
<p><img src="file:///C:/WINDOWS/Temp/msohtmlclip1/01/clip_image004.jpg" alt="img"></p>
<h1 id="GBDT与Boosting的区别"><a href="#GBDT与Boosting的区别" class="headerlink" title="GBDT与Boosting的区别"></a>GBDT与Boosting的区别</h1><p>GBDT与传统的Boosting区别较大，它的每一次计算都是为了减少上一次的残差，而为了消除残差，我们可以在残差减小的梯度方向上建立模型，所以说，在GBDT每个新的模型的建立是为了使得之前的模型的<strong>残差往梯度下降的方向</strong>，与传统的Boosting中关注正确错误的样本加权有着很大的区别。</p>
<h1 id="GBDT与Boosting-Tree的区别"><a href="#GBDT与Boosting-Tree的区别" class="headerlink" title="GBDT与Boosting Tree的区别"></a>GBDT与Boosting Tree的区别</h1><p>Boosting Tree的适合于损失函数为<strong>平方损失</strong>或者<strong>指数损失</strong>。而Gradient Boosting适合<strong>各类损失函数</strong>（损失函数为平方损失则相当于Boosting Tree拟合残差；损失函数为指数损失则可以近似于Adaboost，但树是回归树）</p>
<h1 id="RF与GBDT之间的区别与联系"><a href="#RF与GBDT之间的区别与联系" class="headerlink" title="RF与GBDT之间的区别与联系"></a>RF与GBDT之间的区别与联系</h1><p>1）相同点：都是<strong>由多棵树组成</strong>，最终的结果都是由多棵树共同决定。 </p>
<p>2）不同点：</p>
<p>典型的Bagging与Boosting的区别：</p>
<p>并行/串行：组成RF的树可以<strong>并行</strong>生成，而GBDT是<strong>串行</strong>生成</p>
<p>方差/偏差：RF是减少模型的<strong>方差</strong>，而GBDT是减少模型的<strong>偏差</strong></p>
<p>RF的结果是<strong>多数表决</strong>的，而GBDT则是<strong>多棵树累加</strong>的结果</p>
<p>分类树/回归树：组成RF的树可以分类树也可以是回归树，而GBDT只由<strong>回归树</strong>组成</p>
<p>异常值：RF对异常值不敏感，因为是多棵树表决，而GBDT对<strong>异常值比较敏感</strong>，因为当前的错误会延续给下一棵树</p>
<h1 id="GBDT常用调参参数"><a href="#GBDT常用调参参数" class="headerlink" title="GBDT常用调参参数"></a>GBDT常用调参参数</h1><p>在scikit-learn中，GradientBoostingClassifier为GBDT的分类，而GradientBoostingRegressor为GBDT的回归类。两者的参数类型完全相同，当然有些参数比如损失函数loss的可选择项并不相同。把重要参数分为两类，第一类是Boosting参数，第二类是树参数。</p>
<h2 id="boosting参数"><a href="#boosting参数" class="headerlink" title="boosting参数"></a>boosting参数</h2><p>n_estimators: </p>
<p>弱学习器的最大迭代次数，或者说弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，容易过拟合，默认是100。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。</p>
<p>learning_rate: </p>
<p>每个弱学习器的权重缩减系数ν，也称作步长，ν的取值范围为0&lt;ν≤1。对于同样的训练集拟合效果，较小的ν意味着需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。<strong>所以这两个参数n_estimators和learning_rate要一起调参</strong>，默认是1。</p>
<p>subsample: </p>
<p>子采样比率，取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是<strong>不放回抽样</strong>。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间，默认是1。</p>
<p>loss: </p>
<p>损失函数。对于分类模型，有对数似然损失函数”deviance”和指数损失函数”exponential”两者输入选择。一般来说，推荐使用默认的”deviance”。它对二元分离和多元分类各自都有比较好的优化。而指数损失函数等价于Adaboost。</p>
<p>对于回归模型，有均方差”ls”, 绝对损失”lad”, Huber损失”huber”和分位数损失“quantile”。默认是均方差”ls”。一般来说，如果数据的噪音点不多，用默认的均方差”ls”比较好。如果是噪音点较多，则推荐用抗噪音的损失函数”huber”。而如果需要对训练集进行分段预测的时候，则采用“quantile”。</p>
<p>alpha：</p>
<p>这个参数只有GradientBoostingRegressor有，当我们使用Huber损失”huber”和分位数损失“quantile”时，需要指定分位数的值。默认是0.9，如果噪音点较多，可以适当降低这个分位数的值。</p>
<h2 id="树参数"><a href="#树参数" class="headerlink" title="树参数"></a>树参数</h2><p>由于GBDT使用了CART回归决策树，因此它的参数基本来源于决策树类，也就是说，和DecisionTreeClassifier和DecisionTreeRegressor的参数基本类似。</p>
<p>max_features: </p>
<p>划分时考虑的最大特征数，可以使用很多种类型的值，</p>
<p>默认是”None”：意味着考虑所有的特征数；</p>
<p>“log2”：意味着划分时最多考虑<img src="file:///C:/WINDOWS/Temp/msohtmlclip1/01/clip_image006.png" alt="img">个特征；</p>
<p>“sqrt”或者”auto”：意味着划分时最多考虑<img src="file:///C:/WINDOWS/Temp/msohtmlclip1/01/clip_image008.png" alt="img">个特征；</p>
<p>整数：代表考虑的特征绝对数；</p>
<p>浮点数：代表考虑特征百分比，即考虑（百分比xN）取整后的特征数，其中N为样本总特征数。</p>
<p>一般来说，如果样本特征数不多，比如小于50，我们用默认的”None”就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。</p>
<p>max_depth: </p>
<p>决策树最大深度，如果不输入的话，默认值是3。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。</p>
<p>min_samples_split: </p>
<p>内部节点再划分所需最小样本数，这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。默认是2。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</p>
<p>min_samples_leaf: </p>
<p>叶子节点最少样本数，这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。默认是1。可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</p>
<p>min_weight_fraction_leaf</p>
<p>和上面min_ samples_ leaf很像，不同的是这里需要的是一个比例而不是绝对数值：终点节点所需的样本数占总样本数的比值。（两者只需定义一个就行）</p>
<p>min_weight_fraction_leaf：</p>
<p>叶子节点最小的样本权重和，这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。默认是0，就是不考虑权重问题。一般来说，如果有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时就要注意这个值了。</p>
<p>max_leaf_nodes: </p>
<p>最大叶子节点数，通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征很多的话，可以加以限制，具体的值可以通过交叉验证得到。</p>
<p>min_impurity_split: </p>
<p>节点划分的最小不纯度，这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点，即为叶子节点 。一般不推荐改动，默认值1e-7。</p>
<p>参数调节的一般方法：</p>
<p>我们要调节的参数有两种：树参数和boosting参数。learning rate没有什么特别的调节方法，因为只要我们训练的树足够多learning rate总是小值来得好。虽然随着决定树的增多GBM并不会明显得过度拟合，高learing rate还是会导致这个问题，但如果一味地减小learning rate、增多树,计算就会非常昂贵而且需要运行很长时间。</p>
<p>可以采取以下方法调参：</p>
<ol>
<li>选择一个相对来说稍微高一点的learning rate。一般默认的值是0.1，不过针对不同的问题，0.05到0.2之间都可以</li>
<li>决定当前learning rate下最优的决定树数量。它的值应该在40-70之间。记得选择一个你的电脑还能快速运行的值，因为之后这些树会用来做很多测试和调参。</li>
<li>接着调节树参数来调整learning rate和树的数量。我们可以选择不同的参数来定义一个决定树， </li>
<li>降低learning rate，同时会增加相应的决定树数量使得模型更加稳健</li>
</ol>
<p>树参数可以按照这些步骤调节：</p>
<p>调节max_depth和 num_samples_split<br>调节min_samples_leaf<br>调节max_features</p>
<p>需要注意下调参顺序，对结果影响最大的参数应该优先调节，就像max_depth和num_samples_split。</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>xjw924</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://xjw924.github.io/2019/11/13/gbdt/">http://xjw924.github.io/2019/11/13/gbdt/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/MachineLearning/"># MachineLearning</a>
                    
                        <a href="/tags/Ensemble/"># Ensemble</a>
                    
                        <a href="/tags/Classification/"># Classification</a>
                    
                        <a href="/tags/GBDT/"># GBDT</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2019/11/14/svm/">SVM</a>
            
            
            <a class="next" rel="next" href="/2019/11/13/decisiontree/">DecisionTree</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© xjw924 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
